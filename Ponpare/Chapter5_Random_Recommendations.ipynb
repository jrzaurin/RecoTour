{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5\n",
    "\n",
    "Before we start building more complex algorithms we need a baseline to compare with. Our aim is to answer the question: do we really need a complex algorithm? \n",
    "\n",
    "Here we will compare against random recommendations. In the next chapter we will recommend the most popular coupons, but before let me introduce the metric we will use to determine whether our recommendations are good. \n",
    "\n",
    "### 1. Evaluation Metric\n",
    "\n",
    "In the kaggle competition they ask us to evaluate our recommendations in terms of [Mean Average Precision](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval) at 10 recommendations (MAP@10). \n",
    "\n",
    "The Average Precision (AP) is measured as (from wikipedia):\n",
    "\n",
    "$$\\text{AP} = \\frac{\\sum_{k=1}^{n} (P(k) \\times rel(k))}{\\text{number of relevant documents}}$$\n",
    "\n",
    "where $k$ is the rank in the sequence of retrieved documents, $n$ is the number of retrieved documents, $P(k)$ is the precision at cut-off $k$ in the list and $rel(k)$ is an indicator function equaling 1 if the item at rank $k$ is a relevant document, zero otherwise. Let's illustrate this with one example. Let's say that a user has interacted with 5 items, that will denote with numbers:\n",
    "\n",
    "```\n",
    "actual_items = [3, 7, 4, 2, 5]\n",
    "```\n",
    "\n",
    "Now let's say that our algorithm, out of all of the items in stock recommends the following 10, ranked based on some score designed to represent the likes of that customer:\n",
    "\n",
    "```\n",
    "recommended_items = [12, 7, 53, 90, 3, 23, 14, 37, 18, 67]\n",
    "```\n",
    "\n",
    "Then the MAP@10 would read as follow: our first recommendation fails (since 12 is not among the actual items). The second recommendation is a \"hit\". In other words, by the time we make two recommendations we got 1 right, so we add $1/2$. Our third recommendation is again, a bad one, as it is the forth. The fifth one however is another hit, so we add $2/5$. From there in advance we don't get any more hits. Therefore, the AP@10 is:\n",
    "\n",
    "$$ \\text{AP@10} = \\frac{0.5 + 0.4}{5} = 0.18$$\n",
    "\n",
    "The MAP@10 is nothing more than the average of all recommendations we make for all the users. In python, AP and MAP are implemented as (credit goes [here](https://github.com/benhamner/Metrics/tree/master/Python/ml_metrics)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted\n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our example is alright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_items = [3, 7, 4, 2, 5]\n",
    "actual_items = [str(i) for i in actual_items]\n",
    "recommended_items = [12, 7, 53, 90, 3, 23, 14, 37, 18, 67]\n",
    "recommended_items = [str(i) for i in recommended_items]\n",
    "\n",
    "apk(actual_items, recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my working directory I have included a module called `recutils` where I place all custome submodules that I will use during for the different examples. There you can find a `average_precision.py` with the code in the previous cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random recommendations\n",
    "\n",
    "One would hope that any algorithm, complex or not, performs better than just random recommendations. I would say that if the results of your algorithmic-based recommendations are similar to those of random recommendation, is almost certain that there is something wrong in your data. Maybe you made a mistake during feature engineering or the features you use don't mean a thing. \n",
    "\n",
    "In any case, let's see what is the MAP@10 for our dataset, when we use random recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from recutils.average_precision import mapk\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\"\n",
    "\n",
    "# load train users dataframe\n",
    "df_user_train_feat = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_user_train_feat.p'))\n",
    "train_users = df_user_train_feat.user_id_hash.unique()\n",
    "\n",
    "# validation coupons\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_coupons_valid_feat.p'))\n",
    "\n",
    "# validation activities\n",
    "df_purchases_valid = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_purchases_valid.p'))\n",
    "df_visits_valid = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_visits_valid.p'))\n",
    "df_visits_valid.rename(index=str, columns={'view_coupon_id_hash': 'coupon_id_hash'}, inplace=True)\n",
    "\n",
    "# subset users that were seeing in training\n",
    "df_vva = df_visits_valid[df_visits_valid.user_id_hash.isin(train_users)]\n",
    "df_pva = df_purchases_valid[df_purchases_valid.user_id_hash.isin(train_users)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we will consider \"hits\" all interactions, whether purchases or visits. In the real world a more thorough analysis on this decision would be required. For example, it is possible that when computing the MAP we want to add a weight to \"purchased hits\" that is higher than that of visits. \n",
    "\n",
    "Also, if you are a data scientist building a recommendation algorithm in your company one would hope that you are familiar with the product that you are building the algorithm for. This knowledge might give you information on what to do with different types of interactions. \n",
    "\n",
    "For example, let's say we are building a recommendation algorithm for an online retail company. A user visits an item page once and spend less than $X$ seconds on the page (for example less than 5 seconds). Very likely this is an indication that the user did not like that item. However, if the user visits the item more than once or spends more than $X$ seconds on the item page is probably an indicator of some interest. All this should be considered by your algorithm. \n",
    "\n",
    "For the excercise here, purchases and visits will be considered equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>[68b8f4ff1151b51f864764cab41a30b5, 977a7c4963a1d8507105746de90ca7c4, 974e494d6b26ad3b7f7ff324553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>[1ae11153f2bfacec6ab5450d01453c4d, 404d7f06930ed5435f8b87accfeb5329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002b08971471e6083dd716f6c3bb6572</td>\n",
       "      <td>[fed386703b0295119cadda40b20efcba, bd336887b48211fdfffefa487a3f9825, b2a128a9175ce0b906f52213686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003a7b4941222b7e507fdc9e95de2cc1</td>\n",
       "      <td>[4bb514d6a036c3caba31d4b62f873cd7, b2a128a9175ce0b906f522136861c253, 08f1cb2beb64eab00858ed31fd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00441c9b51cfe60b82bdf7a20ad79fc8</td>\n",
       "      <td>[d7fb5915505943b2c7a7f5c1c550bb25, 9beb2e8ddc15e52a6218eed3620eac65, 00ee9da4d860c03589461d99298...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash  \\\n",
       "0  000cc06982785a19e2a2fdb40b1c9d59   \n",
       "1  002ae30377cd30f65652e52618e8b2d6   \n",
       "2  002b08971471e6083dd716f6c3bb6572   \n",
       "3  003a7b4941222b7e507fdc9e95de2cc1   \n",
       "4  00441c9b51cfe60b82bdf7a20ad79fc8   \n",
       "\n",
       "                                                                                        coupon_id_hash  \n",
       "0  [68b8f4ff1151b51f864764cab41a30b5, 977a7c4963a1d8507105746de90ca7c4, 974e494d6b26ad3b7f7ff324553...  \n",
       "1                                 [1ae11153f2bfacec6ab5450d01453c4d, 404d7f06930ed5435f8b87accfeb5329]  \n",
       "2  [fed386703b0295119cadda40b20efcba, bd336887b48211fdfffefa487a3f9825, b2a128a9175ce0b906f52213686...  \n",
       "3  [4bb514d6a036c3caba31d4b62f873cd7, b2a128a9175ce0b906f522136861c253, 08f1cb2beb64eab00858ed31fd2...  \n",
       "4  [d7fb5915505943b2c7a7f5c1c550bb25, 9beb2e8ddc15e52a6218eed3620eac65, 00ee9da4d860c03589461d99298...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cols = ['user_id_hash', 'coupon_id_hash']\n",
    "df_interactions_valid = pd.concat([df_pva[id_cols], df_vva[id_cols]], ignore_index=True)\n",
    "df_interactions_valid = (df_interactions_valid.groupby('user_id_hash')\n",
    "    .agg({'coupon_id_hash': 'unique'})\n",
    "    .reset_index())\n",
    "\n",
    "df_interactions_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss an additional consideration. For this particular section it does not matter much, but in moving forward is good to at least mention it. There are some users that during the validation period did not interact with any of the validation coupons. This means that it does not matter how I rank validation coupons for these users, the MAP is always going to be 0. Since during validation (as I tune hyperparameters) I want to have a more \"direct\" view of how different algorithms perform, I will ignore those users. As a result, I am biasing the resulting MAP towards slightly higher numbers. Note that this is ok as long as the comparison between all algorithms is done with the same dataset, as is the case. When I move into testing I will use *all* users in the testing period that were seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fed386703b0295119cadda40b20efcba',\n",
       "       'bd336887b48211fdfffefa487a3f9825',\n",
       "       'b2a128a9175ce0b906f522136861c253',\n",
       "       '61b14e823046233811b066724ded6ec6'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_valid_dict = pd.Series(df_interactions_valid.coupon_id_hash.values,\n",
    "    index=df_interactions_valid.user_id_hash).to_dict()\n",
    "valid_coupon_ids = df_coupons_valid_feat.coupon_id_hash.values\n",
    "\n",
    "#Â let's keep users that during the validation period, interacted with at least one validation coupon\n",
    "keep_users = []\n",
    "for user, coupons in tmp_valid_dict.items():\n",
    "    if np.intersect1d(valid_coupon_ids, coupons).size !=0:\n",
    "        keep_users.append(user)\n",
    "\n",
    "# out of 6924 users seen during validation, 6071 interacted with at least one validation coupon.\n",
    "interactions_valid_dict = {k:v for k,v in tmp_valid_dict.items() if k in keep_users}\n",
    "\n",
    "# for each user this dictionary contains the coupon_hash_id for the validation coupons \n",
    "# that that user interacted with\n",
    "interactions_valid_dict['002b08971471e6083dd716f6c3bb6572']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then recommend at random and see which MAP we obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008160369728764752\n"
     ]
    }
   ],
   "source": [
    "coupon_id_rn = valid_coupon_ids.copy()\n",
    "recomendations_dict = {}\n",
    "for user, _  in interactions_valid_dict.items():\n",
    "    np.random.shuffle(coupon_id_rn)\n",
    "    recomendations_dict[user] = coupon_id_rn\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "for k,_ in recomendations_dict.items():\n",
    "    actual.append(list(interactions_valid_dict[k]))\n",
    "    pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "print(mapk(actual,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep that number in mind. When recommending at random, the MAP $\\sim$ 0.008 (this number changes every run, of course, but in general is pretty bad, as expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jrz)",
   "language": "python",
   "name": "conda_jrz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
