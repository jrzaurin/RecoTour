{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7\n",
    "\n",
    "### 7.1 User-Item similarity recommendations\n",
    "\n",
    "In this chapter we will explore another approach in which we project user and item features into the same parameter space and we recommmend based on a distance metric. More precisely, we will represent each user by the average of coupons they purchased or visit. \n",
    "\n",
    "There is a lot of freedom in terms of how one could combine purchases with visit, and even how one could weight individual coupon contributions. For example, one could weight the coupons based on the amount of items users bought with them.\n",
    "\n",
    "Because this is mostly an illustration of this technique, I will consider unique purchased and viewed coupons. I will then combine them using a weight parameter that I will optimize against the Mean Average Precision (MAP).\n",
    "\n",
    "Let's have a look to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from recutils.average_precision import mapk\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training interactions\n",
    "df_purchases_train = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_purchases_train.p'))\n",
    "df_visits_train = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_visits_train.p'))\n",
    "df_visits_train.rename(index=str, columns={'view_coupon_id_hash': 'coupon_id_hash'}, inplace=True)\n",
    "\n",
    "# train users and coupons features\n",
    "df_coupons_train_feat = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_coupons_train_feat.p'))\n",
    "df_user_train_feat = pd.read_pickle(os.path.join(inp_dir, 'train', 'df_users_train_feat.p'))\n",
    "train_users = df_user_train_feat.user_id_hash.unique()\n",
    "train_coupons = df_coupons_train_feat.coupon_id_hash.unique()\n",
    "\n",
    "# subset activities according to the users seen in training\n",
    "df_vtr = df_visits_train[df_visits_train.user_id_hash.isin(train_users) &\n",
    "    df_visits_train.coupon_id_hash.isin(train_coupons)]\n",
    "df_ptr = df_purchases_train[df_purchases_train.user_id_hash.isin(train_users) &\n",
    "    df_purchases_train.coupon_id_hash.isin(train_coupons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computing the user mean vectors, only the most recent purchase will be considered. I insist, there is a lot of freedom when building a representation of customers and items. Please, feel free to consider any other approach you might think (or know!) it will work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>38beeadfe3f97e640367eddae4a8c1b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00035b86e6884589ec8d28fbf2fe7757</td>\n",
       "      <td>25a27d420caa1c46a8d3c0572d27868a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>4a79cd05ecb2bf8672e1d955f5faa7fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>f0f66195d527a5a9509e139ed367b879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>229ff5cc21c8d26615493be7f3b42841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash\n",
       "0  0000b53e182165208887ba65c079fc21  38beeadfe3f97e640367eddae4a8c1b5\n",
       "1  00035b86e6884589ec8d28fbf2fe7757  25a27d420caa1c46a8d3c0572d27868a\n",
       "2  0005b1068d5f2b8f2a7c978fcfe1ca06  4a79cd05ecb2bf8672e1d955f5faa7fa\n",
       "3  0005b1068d5f2b8f2a7c978fcfe1ca06  f0f66195d527a5a9509e139ed367b879\n",
       "4  000cc06982785a19e2a2fdb40b1c9d59  229ff5cc21c8d26615493be7f3b42841"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most recent purchase\n",
    "df_ptr_most_recent = (df_ptr\n",
    "    .groupby(['user_id_hash','coupon_id_hash'])['days_to_present']\n",
    "    .min()\n",
    "    .reset_index())\n",
    "df_ptr_most_recent.drop('days_to_present', axis=1, inplace=True)\n",
    "\n",
    "df_ptr_most_recent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a representation of users (i.e. projecting users onto the item/coupon parameter space), we will treat separarely coupons that were purchased and viewed. This means that if a coupon was viewed and then purchased, only the purchase interaction will be considered when computing the mean. Also, if someone interacted with that coupon many times, we will only consider it once here, the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>0645faa156f34104e6d8910160868f9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>18097cd25ab6b7e8eb0481b0e3a3cfd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>1b581f2ed53f2f2eafbc1560db640194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>1d04e76c44c231d5d05dc1634d20fe8c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>2ab16b8f5aeead6d31dbdb9bd59c41db</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash\n",
       "0  0000b53e182165208887ba65c079fc21  0645faa156f34104e6d8910160868f9f\n",
       "1  0000b53e182165208887ba65c079fc21  18097cd25ab6b7e8eb0481b0e3a3cfd8\n",
       "2  0000b53e182165208887ba65c079fc21  1b581f2ed53f2f2eafbc1560db640194\n",
       "3  0000b53e182165208887ba65c079fc21  1d04e76c44c231d5d05dc1634d20fe8c\n",
       "4  0000b53e182165208887ba65c079fc21  2ab16b8f5aeead6d31dbdb9bd59c41db"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vtr_visits = df_vtr.copy()\n",
    "df_vtr_visits['activity_hash'] = df_vtr_visits['user_id_hash'] + \"_\" + df_vtr_visits['coupon_id_hash']\n",
    "purchases = df_vtr_visits[~df_vtr_visits.purchaseid_hash.isna()]['activity_hash'].unique()\n",
    "df_vtr_visits = (df_vtr_visits[~df_vtr_visits.activity_hash\n",
    "    .isin(purchases)][['user_id_hash','coupon_id_hash','days_to_present']])\n",
    "\n",
    "# Most recent visit is the view that will be considered\n",
    "df_vtr_most_recent = (df_vtr_visits\n",
    "    .groupby(['user_id_hash','coupon_id_hash'])['days_to_present']\n",
    "    .min()\n",
    "    .reset_index())\n",
    "df_vtr_most_recent.drop('days_to_present', axis=1, inplace=True)\n",
    "\n",
    "df_vtr_most_recent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with coupon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat</th>\n",
       "      <th>usable_date_tue_cat</th>\n",
       "      <th>usable_date_wed_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>dispend_cat</th>\n",
       "      <th>dispperiod_cat</th>\n",
       "      <th>price_rate_cat</th>\n",
       "      <th>catalog_price_cat</th>\n",
       "      <th>discount_price_cat</th>\n",
       "      <th>capsule_text_cat</th>\n",
       "      <th>genre_name_cat</th>\n",
       "      <th>large_area_name_cat</th>\n",
       "      <th>ken_name_cat</th>\n",
       "      <th>small_area_name_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>38beeadfe3f97e640367eddae4a8c1b5</td>\n",
       "      <td>62</td>\n",
       "      <td>7900</td>\n",
       "      <td>2980</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00035b86e6884589ec8d28fbf2fe7757</td>\n",
       "      <td>25a27d420caa1c46a8d3c0572d27868a</td>\n",
       "      <td>52</td>\n",
       "      <td>3110</td>\n",
       "      <td>1490</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>4a79cd05ecb2bf8672e1d955f5faa7fa</td>\n",
       "      <td>90</td>\n",
       "      <td>1060</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>f0f66195d527a5a9509e139ed367b879</td>\n",
       "      <td>72</td>\n",
       "      <td>72500</td>\n",
       "      <td>19800</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>229ff5cc21c8d26615493be7f3b42841</td>\n",
       "      <td>79</td>\n",
       "      <td>1950</td>\n",
       "      <td>400</td>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash  \\\n",
       "0  0000b53e182165208887ba65c079fc21  38beeadfe3f97e640367eddae4a8c1b5   \n",
       "1  00035b86e6884589ec8d28fbf2fe7757  25a27d420caa1c46a8d3c0572d27868a   \n",
       "2  0005b1068d5f2b8f2a7c978fcfe1ca06  4a79cd05ecb2bf8672e1d955f5faa7fa   \n",
       "3  0005b1068d5f2b8f2a7c978fcfe1ca06  f0f66195d527a5a9509e139ed367b879   \n",
       "4  000cc06982785a19e2a2fdb40b1c9d59  229ff5cc21c8d26615493be7f3b42841   \n",
       "\n",
       "   price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "0          62           7900            2980           3          179   \n",
       "1          52           3110            1490           4          165   \n",
       "2          90           1060             100          14           64   \n",
       "3          72          72500           19800           5           73   \n",
       "4          79           1950             400           7          131   \n",
       "\n",
       "   usable_date_mon_cat  usable_date_tue_cat  usable_date_wed_cat  ...  \\\n",
       "0                    1                    1                    1  ...   \n",
       "1                    1                    1                    1  ...   \n",
       "2                    3                    3                    3  ...   \n",
       "3                    3                    3                    3  ...   \n",
       "4                    3                    3                    3  ...   \n",
       "\n",
       "   dispend_cat  dispperiod_cat  price_rate_cat  catalog_price_cat  \\\n",
       "0            6               1               2                  1   \n",
       "1            5               2               1                  0   \n",
       "2            1               3               2                  0   \n",
       "3            3               3               2                  2   \n",
       "4            2               3               2                  0   \n",
       "\n",
       "   discount_price_cat  capsule_text_cat genre_name_cat large_area_name_cat  \\\n",
       "0                   1                 0              0                   1   \n",
       "1                   0                 0              0                   3   \n",
       "2                   0                 8              8                   0   \n",
       "3                   2                 7              7                   0   \n",
       "4                   0                 9              9                   0   \n",
       "\n",
       "   ken_name_cat  small_area_name_cat  \n",
       "0             9                   11  \n",
       "1             6                    8  \n",
       "2             2                    2  \n",
       "3             2                    2  \n",
       "4             2                    5  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with coupon features\n",
    "df_ptr_most_recent = (df_ptr_most_recent\n",
    "    .merge(df_coupons_train_feat, on='coupon_id_hash',how='left'))\n",
    "df_vtr_most_recent = (df_vtr_most_recent\n",
    "    .merge(df_coupons_train_feat, on='coupon_id_hash',how='left'))\n",
    "df_ptr_most_recent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data manipulation before we compute the User Mean Vectors (hereafter UMV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation coupons features\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_coupons_valid_feat.p'))\n",
    "\n",
    "# for convenience, we will flag each dataset (I realised that this could be coded better...)\n",
    "df_ptr_most_recent['flag_cat'] = 0\n",
    "df_vtr_most_recent['flag_cat'] = 1\n",
    "df_coupons_valid_feat['flag_cat'] = 2\n",
    "flag_cols = ['flag_cat_0','flag_cat_1','flag_cat_2']\n",
    "\n",
    "# categorical and non categorical columns\n",
    "cat_cols = [c for c in df_ptr_most_recent.columns if '_cat' in c]\n",
    "non_cat_cols = [c for c in df_ptr_most_recent.columns if c not in cat_cols]\n",
    "non_cat_cols_valid = [c for c in non_cat_cols if c != 'user_id_hash']\n",
    "\n",
    "# again, the one hot encoding needs to be done with all the features \n",
    "# (and hence datasets) at once to ensure all datasets will end up with \n",
    "# the same number of features\n",
    "tmp_df = pd.concat([df_ptr_most_recent[cat_cols],\n",
    "    df_vtr_most_recent[cat_cols],\n",
    "    df_coupons_valid_feat[cat_cols]],\n",
    "    ignore_index=True)\n",
    "df_dummy_feats = pd.get_dummies(tmp_df.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat_0</th>\n",
       "      <th>usable_date_mon_cat_1</th>\n",
       "      <th>usable_date_mon_cat_2</th>\n",
       "      <th>...</th>\n",
       "      <th>small_area_name_cat_45</th>\n",
       "      <th>small_area_name_cat_46</th>\n",
       "      <th>small_area_name_cat_47</th>\n",
       "      <th>small_area_name_cat_48</th>\n",
       "      <th>small_area_name_cat_49</th>\n",
       "      <th>small_area_name_cat_50</th>\n",
       "      <th>small_area_name_cat_51</th>\n",
       "      <th>small_area_name_cat_52</th>\n",
       "      <th>small_area_name_cat_53</th>\n",
       "      <th>small_area_name_cat_54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>38beeadfe3f97e640367eddae4a8c1b5</td>\n",
       "      <td>62</td>\n",
       "      <td>7900</td>\n",
       "      <td>2980</td>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>00035b86e6884589ec8d28fbf2fe7757</td>\n",
       "      <td>25a27d420caa1c46a8d3c0572d27868a</td>\n",
       "      <td>52</td>\n",
       "      <td>3110</td>\n",
       "      <td>1490</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>4a79cd05ecb2bf8672e1d955f5faa7fa</td>\n",
       "      <td>90</td>\n",
       "      <td>1060</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>f0f66195d527a5a9509e139ed367b879</td>\n",
       "      <td>72</td>\n",
       "      <td>72500</td>\n",
       "      <td>19800</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>229ff5cc21c8d26615493be7f3b42841</td>\n",
       "      <td>79</td>\n",
       "      <td>1950</td>\n",
       "      <td>400</td>\n",
       "      <td>7</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash  \\\n",
       "0  0000b53e182165208887ba65c079fc21  38beeadfe3f97e640367eddae4a8c1b5   \n",
       "1  00035b86e6884589ec8d28fbf2fe7757  25a27d420caa1c46a8d3c0572d27868a   \n",
       "2  0005b1068d5f2b8f2a7c978fcfe1ca06  4a79cd05ecb2bf8672e1d955f5faa7fa   \n",
       "3  0005b1068d5f2b8f2a7c978fcfe1ca06  f0f66195d527a5a9509e139ed367b879   \n",
       "4  000cc06982785a19e2a2fdb40b1c9d59  229ff5cc21c8d26615493be7f3b42841   \n",
       "\n",
       "   price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "0          62           7900            2980           3          179   \n",
       "1          52           3110            1490           4          165   \n",
       "2          90           1060             100          14           64   \n",
       "3          72          72500           19800           5           73   \n",
       "4          79           1950             400           7          131   \n",
       "\n",
       "   usable_date_mon_cat_0  usable_date_mon_cat_1  usable_date_mon_cat_2  ...  \\\n",
       "0                      0                      1                      0  ...   \n",
       "1                      0                      1                      0  ...   \n",
       "2                      0                      0                      0  ...   \n",
       "3                      0                      0                      0  ...   \n",
       "4                      0                      0                      0  ...   \n",
       "\n",
       "   small_area_name_cat_45  small_area_name_cat_46  small_area_name_cat_47  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_48  small_area_name_cat_49  small_area_name_cat_50  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_51  small_area_name_cat_52  small_area_name_cat_53  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_54  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoded feat for purchases and visits during training\n",
    "# (there is a better way to do this that I will show in another notebook)\n",
    "tmp_df_ptr_oh = (df_dummy_feats[df_dummy_feats.flag_cat_0 != 0]\n",
    "    .drop(flag_cols, axis=1)\n",
    "    .reset_index(drop=True))\n",
    "tmp_df_vtr_oh = (df_dummy_feats[df_dummy_feats.flag_cat_1 != 0]\n",
    "    .drop(flag_cols, axis=1)\n",
    "    .reset_index(drop=True))\n",
    "# One hot encoded feat for validation\n",
    "tmp_df_valid_oh = (df_dummy_feats[df_dummy_feats.flag_cat_2 != 0]\n",
    "    .drop(flag_cols, axis=1)\n",
    "    .reset_index(drop=True))\n",
    "\n",
    "df_ptr_most_recent_oh = pd.concat([df_ptr_most_recent[non_cat_cols],\n",
    "    tmp_df_ptr_oh], axis=1)\n",
    "df_vtr_most_recent_oh = pd.concat([df_vtr_most_recent[non_cat_cols],\n",
    "    tmp_df_vtr_oh], axis=1)\n",
    "df_coupons_valid_feat_oh = pd.concat([df_coupons_valid_feat[non_cat_cols_valid],\n",
    "    tmp_df_valid_oh], axis=1)\n",
    "\n",
    "# let's have a look to one of these dataframes\n",
    "df_ptr_most_recent_oh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the dimensions are consistent and then compute the UMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat_0</th>\n",
       "      <th>usable_date_mon_cat_1</th>\n",
       "      <th>usable_date_mon_cat_2</th>\n",
       "      <th>usable_date_mon_cat_3</th>\n",
       "      <th>...</th>\n",
       "      <th>small_area_name_cat_45</th>\n",
       "      <th>small_area_name_cat_46</th>\n",
       "      <th>small_area_name_cat_47</th>\n",
       "      <th>small_area_name_cat_48</th>\n",
       "      <th>small_area_name_cat_49</th>\n",
       "      <th>small_area_name_cat_50</th>\n",
       "      <th>small_area_name_cat_51</th>\n",
       "      <th>small_area_name_cat_52</th>\n",
       "      <th>small_area_name_cat_53</th>\n",
       "      <th>small_area_name_cat_54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>282b5bda1758e147589ca517e02195c3</td>\n",
       "      <td>50</td>\n",
       "      <td>2980</td>\n",
       "      <td>1490</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0f43ef71c25d409c250f5a5042806342</td>\n",
       "      <td>50</td>\n",
       "      <td>7810</td>\n",
       "      <td>3905</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>28ff0fb4b561a2fd6a360fe28f465e07</td>\n",
       "      <td>51</td>\n",
       "      <td>7200</td>\n",
       "      <td>3480</td>\n",
       "      <td>7</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>864f351e66cd3aeece5d06987fc2ed4b</td>\n",
       "      <td>50</td>\n",
       "      <td>5649</td>\n",
       "      <td>2790</td>\n",
       "      <td>7</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>279ba64539609d30114b68874cd0fb42</td>\n",
       "      <td>55</td>\n",
       "      <td>4400</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     coupon_id_hash  price_rate  catalog_price  \\\n",
       "0  282b5bda1758e147589ca517e02195c3          50           2980   \n",
       "1  0f43ef71c25d409c250f5a5042806342          50           7810   \n",
       "2  28ff0fb4b561a2fd6a360fe28f465e07          51           7200   \n",
       "3  864f351e66cd3aeece5d06987fc2ed4b          50           5649   \n",
       "4  279ba64539609d30114b68874cd0fb42          55           4400   \n",
       "\n",
       "   discount_price  dispperiod  validperiod  usable_date_mon_cat_0  \\\n",
       "0            1490           5          154                      0   \n",
       "1            3905           7           99                      0   \n",
       "2            3480           7          178                      0   \n",
       "3            2790           7          101                      0   \n",
       "4            1980           7          134                      0   \n",
       "\n",
       "   usable_date_mon_cat_1  usable_date_mon_cat_2  usable_date_mon_cat_3  ...  \\\n",
       "0                      1                      0                      0  ...   \n",
       "1                      1                      0                      0  ...   \n",
       "2                      1                      0                      0  ...   \n",
       "3                      0                      1                      0  ...   \n",
       "4                      1                      0                      0  ...   \n",
       "\n",
       "   small_area_name_cat_45  small_area_name_cat_46  small_area_name_cat_47  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_48  small_area_name_cat_49  small_area_name_cat_50  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_51  small_area_name_cat_52  small_area_name_cat_53  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "\n",
       "   small_area_name_cat_54  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coupons_valid_feat_oh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat_0</th>\n",
       "      <th>usable_date_mon_cat_1</th>\n",
       "      <th>usable_date_mon_cat_2</th>\n",
       "      <th>usable_date_mon_cat_3</th>\n",
       "      <th>...</th>\n",
       "      <th>small_area_name_cat_45</th>\n",
       "      <th>small_area_name_cat_46</th>\n",
       "      <th>small_area_name_cat_47</th>\n",
       "      <th>small_area_name_cat_48</th>\n",
       "      <th>small_area_name_cat_49</th>\n",
       "      <th>small_area_name_cat_50</th>\n",
       "      <th>small_area_name_cat_51</th>\n",
       "      <th>small_area_name_cat_52</th>\n",
       "      <th>small_area_name_cat_53</th>\n",
       "      <th>small_area_name_cat_54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000b53e182165208887ba65c079fc21</td>\n",
       "      <td>57.918367</td>\n",
       "      <td>11393.918367</td>\n",
       "      <td>4151.591837</td>\n",
       "      <td>3.836735</td>\n",
       "      <td>130.040816</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0005b1068d5f2b8f2a7c978fcfe1ca06</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000cc06982785a19e2a2fdb40b1c9d59</td>\n",
       "      <td>56.184000</td>\n",
       "      <td>6095.608000</td>\n",
       "      <td>2647.560000</td>\n",
       "      <td>3.608000</td>\n",
       "      <td>120.560000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0013518e41c416cd6a181d277dd8ca0b</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>10351.111111</td>\n",
       "      <td>4682.222222</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>99.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>001acdee812a18acfd7509172bed5700</td>\n",
       "      <td>62.098592</td>\n",
       "      <td>10024.859155</td>\n",
       "      <td>3256.000000</td>\n",
       "      <td>3.957746</td>\n",
       "      <td>105.943662</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash  price_rate  catalog_price  \\\n",
       "0  0000b53e182165208887ba65c079fc21   57.918367   11393.918367   \n",
       "1  0005b1068d5f2b8f2a7c978fcfe1ca06   80.000000     500.000000   \n",
       "2  000cc06982785a19e2a2fdb40b1c9d59   56.184000    6095.608000   \n",
       "3  0013518e41c416cd6a181d277dd8ca0b   58.000000   10351.111111   \n",
       "4  001acdee812a18acfd7509172bed5700   62.098592   10024.859155   \n",
       "\n",
       "   discount_price  dispperiod  validperiod  usable_date_mon_cat_0  \\\n",
       "0     4151.591837    3.836735   130.040816               0.081633   \n",
       "1      100.000000   14.000000    36.000000               0.000000   \n",
       "2     2647.560000    3.608000   120.560000               0.072000   \n",
       "3     4682.222222    3.666667    99.888889               0.000000   \n",
       "4     3256.000000    3.957746   105.943662               0.014085   \n",
       "\n",
       "   usable_date_mon_cat_1  usable_date_mon_cat_2  usable_date_mon_cat_3  ...  \\\n",
       "0               0.612245               0.020408               0.285714  ...   \n",
       "1               0.000000               0.000000               1.000000  ...   \n",
       "2               0.448000               0.008000               0.472000  ...   \n",
       "3               0.888889               0.000000               0.111111  ...   \n",
       "4               0.309859               0.000000               0.676056  ...   \n",
       "\n",
       "   small_area_name_cat_45  small_area_name_cat_46  small_area_name_cat_47  \\\n",
       "0                0.000000                     0.0                     0.0   \n",
       "1                0.000000                     0.0                     0.0   \n",
       "2                0.008000                     0.0                     0.0   \n",
       "3                0.000000                     0.0                     0.0   \n",
       "4                0.014085                     0.0                     0.0   \n",
       "\n",
       "   small_area_name_cat_48  small_area_name_cat_49  small_area_name_cat_50  \\\n",
       "0                     0.0                     0.0                0.020408   \n",
       "1                     0.0                     0.0                0.000000   \n",
       "2                     0.0                     0.0                0.000000   \n",
       "3                     0.0                     0.0                0.000000   \n",
       "4                     0.0                     0.0                0.000000   \n",
       "\n",
       "   small_area_name_cat_51  small_area_name_cat_52  small_area_name_cat_53  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     0.0                     0.0                     0.0   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   small_area_name_cat_54  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User mean vectors\n",
    "user_mean_purchase_vector = (df_ptr_most_recent_oh.groupby('user_id_hash')\n",
    "    .mean()\n",
    "    .reset_index())\n",
    "user_mean_visit_vector = (df_vtr_most_recent_oh.groupby('user_id_hash')\n",
    "    .mean()\n",
    "    .reset_index())\n",
    "user_mean_visit_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load the dictionary with all the `user:[items]` interactions during validation. Remember, out of the 6924 users seen during validation, 6071 of them interacted with at least one validation coupon. These are the users that we are considering for this excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_valid_dict = pickle.load(open(\"../datasets/Ponpare/data_processed/valid/interactions_valid_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a final consideration before we moved into the more interesting part of this notebook. Remember that UMV have been created based on the features of the coupons they interacted with during training. This means that if there is a user among these 6071 users that did never interacted with any of the coupons **in the coupon training dataset**, that user will not have a corresponding vector. This will through an error later in the code when we try to compute the similarity between users and items. Therefore we would need to remove these users, if there are such cases. Let's have a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['25e2b645bfcd0980b2a5d0a4833f237a']\n"
     ]
    }
   ],
   "source": [
    "user_mean_purchase_vector_valid = (user_mean_purchase_vector[user_mean_purchase_vector\n",
    "    .user_id_hash\n",
    "    .isin(interactions_valid_dict.keys())]\n",
    "    .reset_index(drop=True))\n",
    "user_mean_visit_vector_valid = (user_mean_visit_vector[user_mean_visit_vector\n",
    "    .user_id_hash\n",
    "    .isin(interactions_valid_dict.keys())]\n",
    "    .reset_index(drop=True))\n",
    "users_valid = pd.concat([user_mean_purchase_vector_valid,\n",
    "    user_mean_visit_vector_valid])['user_id_hash'].unique()\n",
    "\n",
    "lost_users = [usr for usr in interactions_valid_dict.keys() if usr not in users_valid]\n",
    "\n",
    "print(lost_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we lose one user that visited just one coupon and that coupon not in train_coupons dataset. Not a big deal. \n",
    "\n",
    "Overall: 6070 users and 358 coupons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del interactions_valid_dict[lost_users[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is when things are going to get a bit interesting (we'll see if there is a price in the end). We have the UMV for both purchases and visits. A priori, one would think that purchases are more important that visits, so we would like to weight them more in the mean, but, how much more?\n",
    "\n",
    "With that in mind we are going to use two python libraries designed for parameter tuning and optimisation called [hyperopt](https://github.com/hyperopt/hyperopt) and [scikit-optimize](https://scikit-optimize.github.io/). Each has its prons and cons. I normally use `hyperopt`, but I don't think is maintained anymore. For example, `hyperopt` uses `networkx 1.11` while the latest version is `2.1`. Therefore, if you are using some package that requires a later version of `networkx`, you will need to work in different environments (as I do). `Skopt` does not have that problem, but usually I find it slower and normally yielding slightly worse results. \n",
    "\n",
    "The way they work is fairly similar. You define an optimisation function and you pass it a given method of the library that will try to minimise it using some clever algorithm. In case of `hyperopt` is called [Tree-structured Parzen Estimator Approach (TPE)](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf), and so far has worked very well for me. For `skopt` there are a number of algorithms. Just have a look to the link above. Here we will use `gbrt_minimize`, a sequential optimization using gradient boosted trees.\n",
    "\n",
    "Enough with the talking, let's have a look to the code. I will first code a function that, given a weight for the features derived using visits, it will return the MAP@10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "from skopt import gbrt_minimize\n",
    "\n",
    "def mapk_similarity_rec(alpha, at_random=False):\n",
    "    \"\"\"\n",
    "    function to compute the MAP using a user-item similarity method\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    alpha: visits weight for the weighted mean: weighted mean = purchases + (alpha*visits)\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    map@10\n",
    "    \"\"\"\n",
    "\n",
    "    mpv = user_mean_purchase_vector_valid.copy()\n",
    "    feat_cols = [c for c in mpv.columns if 'id_hash' not in c]\n",
    "    mvv = user_mean_visit_vector_valid.copy()\n",
    "    \n",
    "    # Weight features coming from visits using alpha\n",
    "    mvv[feat_cols] = alpha*mvv[feat_cols]\n",
    "\n",
    "    # Combine the two\n",
    "    user_vector= (pd.concat([mpv, mvv])\n",
    "        .groupby('user_id_hash')\n",
    "        .sum()\n",
    "        .reset_index())\n",
    "\n",
    "    user_ids = user_vector.user_id_hash.values\n",
    "    item_ids = df_coupons_valid_feat_oh.coupon_id_hash.values\n",
    "\n",
    "    # ensure the same column order\n",
    "    user_cols = ['user_id_hash'] + [c for c in user_vector.columns if 'id_hash' not in c]\n",
    "    item_cols = ['coupon_id_hash'] + [c for c in user_vector.columns if 'id_hash' not in c]\n",
    "    user_feat = user_vector[user_cols[1:]].values\n",
    "    item_feat = df_coupons_valid_feat_oh[item_cols[1:]].values\n",
    "\n",
    "    # Compute distances between users and items and rank them based on proximity\n",
    "    user_item_sim = euclidean_distances(user_feat, item_feat)\n",
    "    top_n_idx = np.apply_along_axis(np.argsort, 1, user_item_sim)\n",
    "\n",
    "    recomendations_dict = {}\n",
    "    for user,idx in zip(user_ids,top_n_idx):\n",
    "        recomendations_dict[user] = [item_ids[i] for i in idx]\n",
    "\n",
    "    actual = []\n",
    "    pred = []\n",
    "    for k,_ in recomendations_dict.items():\n",
    "        actual.append(list(interactions_valid_dict[k]))\n",
    "        pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "    return mapk(actual, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now code the true optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_objective(params, method=\"hyperopt\"):\n",
    "    \n",
    "    # params input needs to be a dictionary for hyperopt and a tuple for skopt\n",
    "    if method is \"hyperopt\":\n",
    "        sim_objective.i+=1\n",
    "        alpha = params['alpha']\n",
    "    elif method is \"skopt\":\n",
    "        alpha = params[0]\n",
    "\n",
    "    score = mapk_similarity_rec(alpha)\n",
    "    \n",
    "    # Remember this function will be minimize, so should output -score or 1-score to maximize the score    \n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective functions **MUST depend ONLY** on `params` (or whatever you want to call the parameter space input, whether a dictionary for `hyperopt` of a list of tuples for `skopt`), therefore, if we want to use an objective function with more parameters we need to turn it into a partial function of just `params`. This can easily be done with `lambda` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_objective = lambda params: sim_objective(params, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go! Let's 1st try hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.68it/s, best loss: 0.9882249899914203]\n"
     ]
    }
   ],
   "source": [
    "hp_params = {'alpha': hp.uniform('alpha', 0.01, 1.)}\n",
    "method = \"hyperopt\"\n",
    "sim_objective.i=0\n",
    "hp_best = fmin(fn=partial_objective,\n",
    "    space=hp_params,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what is the best value of alpha and what is the MAP@10 for that value (one could save all iterations, we will see how in a later notebook. You could also have a look [here](https://github.com/nadbordrozd/text-top-model/blob/master/ttm/tune_params.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.044104857119314146}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011706886992395348"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk_similarity_rec(hp_best['alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = [(0.01, 1, 'uniform')]\n",
    "method = \"skopt\"\n",
    "sk_best = gbrt_minimize(partial_objective,\n",
    "    sk_params,\n",
    "    n_calls=100,\n",
    "    random_state=0,\n",
    "    verbose=False,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04264725225194222]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best alpha\n",
    "sk_best.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011707592003181166"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best MAP@10\n",
    "1-sk_best.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this work just to find out that the MAP@10 is significantly worse than that obtained with \"most popular\" recommendations ($\\sim$0.018). As in previous exercises, let's just think for a second on why this could be. The amount of possibilities to combine the different features when calculating the mean vectors is quite significant. For example, here I used all the features and there is a lot of redundancy. One might want to use just a subset of them. Also, we might want to consider all interactions (rather than just the most recent) and weight according to recency. In summary, having a lot of \"freedom\" can be a burden sometimes.\n",
    "\n",
    "For this technique to work (in my experience this has never been a winning technique) one needs **a lot** of exploration to find the right set up when combining features to build the user and item representations. In addition, there is no guarantee that such set up will be stable if, or as the business changes. For example, if there is a large, sudden increase of user base or stock. \n",
    "\n",
    "Ok, at this stage we have explored Most-Common and Distance-Based recommendations, let's start using more advanced algorithms and see if we can obtain better metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_recotour)",
   "language": "python",
   "name": "conda_recotour"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
