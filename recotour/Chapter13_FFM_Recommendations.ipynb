{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13\n",
    "\n",
    "### 13.1 Field Aware Factorization Machines\n",
    "\n",
    "This Chapter is just the natural continuation of the previous one. Let's remind ourselves a bit where we are. We want to predict the CTR, or perhaps the interest of a user in an item. To that aim we can use FMs defined as: \n",
    "\n",
    "$$\\phi_\\text{FM}(\\boldsymbol{w}, \\boldsymbol{x}) = \\boldsymbol{w}_{0} + \\sum_{i=1}^{n} w_i x_i + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n} (\\boldsymbol{w}_i \\cdot \\boldsymbol{w}_j) x_i x_j$$\n",
    "\n",
    "where the feature interactions are learned through inner products between the latent vectors ($\\boldsymbol{w}$) associated to each feature. The computation complexity of that expression is $O(\\overline{n}k)$, where $\\overline{n}$ is the average number of non zero elements per instance and $k$ is the number of latent factors. \n",
    "\n",
    "Although this technique captures feature interaction, there is no notion of \"field\". Let's consider the same example shown in the previous chapter\n",
    "\n",
    "|  |Publisher (P)| Advertiser (A)| Gender (G)| \n",
    "|----|-------|--------|--|\n",
    "| YES| ESPN  | Nike   |M |\n",
    "\n",
    "\n",
    "Using FMs, the outcome for this instance (`YES` in this case) would be predicted as:\n",
    "\n",
    "$$\\phi_{FM} = \n",
    "\\boldsymbol{w}_0 + \n",
    "\\boldsymbol{w}_\\text{ESPN} x_\\text{ESPN} + \n",
    "\\boldsymbol{w}_\\text{Nike} x_\\text{Nike} + \n",
    "\\boldsymbol{w}_\\text{M} x_\\text{M} + \n",
    "(\\boldsymbol{w}_\\text{ESPN}\\cdot\\boldsymbol{w}_\\text{Nike}) x_\\text{ESPN}x_\\text{Nike} + \n",
    "(\\boldsymbol{w}_\\text{Nike}\\cdot\\boldsymbol{w}_\\text{M}) x_\\text{Nike}x_\\text{M} + \n",
    "(\\boldsymbol{w}_\\text{ESPN}\\cdot\\boldsymbol{w}_\\text{M}) x_\\text{ESPN}x_\\text{M}\n",
    "$$\n",
    "\n",
    "In this expression, there is no notion that ESPN and Nike are values of the features Publisher and Advertiser respectively. Field Aware Factorization Machines address this \"limitation\" by introducing field information. More precisely:\n",
    "\n",
    "$$\\phi_\\text{FFM}(\\boldsymbol{w}, \\boldsymbol{x}) = \n",
    "\\boldsymbol{w}_{0} + \n",
    "\\sum_{i=1}^{n} w_i x_i + \n",
    "\\sum_{i=1}^{n}\\sum_{j=i+1}^{n} (\\boldsymbol{w}_{_i, f_j} \\cdot \\boldsymbol{w}_{j, f_i}) x_i x_j$$\n",
    "\n",
    "The complexity to compute that expression is $O(\\overline{n}^2 k)$ (i.e. slower than FMs). \n",
    "\n",
    "When using FMs there is one latent vector per feature learned through the interaction with another features. In FFMs, each feature has several latent vectors depending on the field of other features it interacts with. Let's go back to our example:\n",
    "\n",
    "$$\\phi_{FFM} = \n",
    "\\boldsymbol{w}_0 + \n",
    "\\boldsymbol{w}_\\text{ESPN} x_\\text{ESPN} + \n",
    "\\boldsymbol{w}_\\text{Nike} x_\\text{Nike} + \n",
    "\\boldsymbol{w}_\\text{M} x_\\text{M} + \n",
    "(\\boldsymbol{w}_\\text{ESPN,A}\\cdot\\boldsymbol{w}_\\text{Nike,P}) x_\\text{ESPN}x_\\text{Nike} + \n",
    "(\\boldsymbol{w}_\\text{Nike,G}\\cdot\\boldsymbol{w}_\\text{M,A}) x_\\text{Nike}x_\\text{M} + \n",
    "(\\boldsymbol{w}_\\text{ESPN,G}\\cdot\\boldsymbol{w}_\\text{M,P}) x_\\text{ESPN}x_\\text{M}\n",
    "$$\n",
    "\n",
    "We can see that the for the Publisher feature value ESPN, two latent vectors are learned $\\boldsymbol{w}_\\text{ESPN,A}$ and $\\boldsymbol{w}_\\text{ESPN,G}$ depending on whether the interaction occurs with the feature Advertiser or Gender. Because in FFMs each latent vector only needs to learn the effect with a specific field, usually $k_{FFM} << k_{FM}$. \n",
    "\n",
    "Let's see how all this looks in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import xlearn as xl\n",
    "import pickle\n",
    "\n",
    "from recutils.average_precision import mapk\n",
    "from time import time\n",
    "from recutils.datasets import dump_libffm_file\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COUPONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18622, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COUPONS\n",
    "df_coupons_train_feat = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_coupons_train_feat.p'))\n",
    "drop_cols = [c for c in df_coupons_train_feat.columns\n",
    "    if ((not c.endswith('_cat')) or ('method2' in c)) and (c!='coupon_id_hash')]\n",
    "df_coupons_train_cat_feat = df_coupons_train_feat.drop(drop_cols, axis=1)\n",
    "coupon_categorical_cols = [c for c in df_coupons_train_cat_feat.columns if c!=\"coupon_id_hash\"]\n",
    "df_coupons_train_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22624, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USERS\n",
    "df_users_train_feat = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_users_train_feat.p'))\n",
    "user_categorical_cols = [c for c in df_users_train_feat.columns if c.endswith('_cat')]\n",
    "user_numerical_cols = [c for c in df_users_train_feat.columns\n",
    "    if ((c not in user_categorical_cols) and (c!='user_id_hash'))]\n",
    "\n",
    "# Normalizing numerical features\n",
    "user_numerical_df = df_users_train_feat[user_numerical_cols]\n",
    "user_numerical_df_norm = (user_numerical_df-user_numerical_df.min())/(user_numerical_df.max()-user_numerical_df.min())\n",
    "df_users_train_feat.drop(user_numerical_cols, axis=1, inplace=True)\n",
    "df_users_train_feat = pd.concat([user_numerical_df_norm, df_users_train_feat], axis=1)\n",
    "df_users_train_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATION DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interest dataframe\n",
    "df_interest = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_interest.p'))\n",
    "df_train = pd.merge(df_interest, df_users_train_feat, on='user_id_hash')\n",
    "df_train = pd.merge(df_train, df_coupons_train_cat_feat, on = 'coupon_id_hash')\n",
    "\n",
    "# for the time being we ignore recency\n",
    "df_train.drop(['user_id_hash','coupon_id_hash','recency_factor'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want/need to ensure some order\n",
    "all_cols = [c for c in df_train.columns.tolist() if c != 'interest']\n",
    "cat_cols = [c for c in all_cols if c.endswith('_cat')]\n",
    "num_cols = [c for c in all_cols if c not in cat_cols]\n",
    "target = 'interest'\n",
    "col_order=[target]+num_cols+cat_cols\n",
    "df_train = df_train[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the validation interactions and coupon info\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, 'valid', 'df_coupons_valid_feat.p'))\n",
    "df_coupons_valid_cat_feat = df_coupons_valid_feat.drop(drop_cols, axis=1)\n",
    "\n",
    "interactions_valid_dict = pickle.load(open(inp_dir + \"valid/interactions_valid_dict.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jrz/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Build validation data\n",
    "left = pd.DataFrame({'user_id_hash':list(interactions_valid_dict.keys())})\n",
    "left['key'] = 0\n",
    "right = df_coupons_valid_feat[['coupon_id_hash']]\n",
    "right['key'] = 0\n",
    "df_valid = (pd.merge(left, right, on='key', how='outer')\n",
    "    .drop('key', axis=1))\n",
    "df_valid = pd.merge(df_valid, df_users_train_feat, on='user_id_hash')\n",
    "df_valid = pd.merge(df_valid, df_coupons_valid_cat_feat, on = 'coupon_id_hash')\n",
    "df_valid['interest'] = 0.1\n",
    "df_preds = df_valid[['user_id_hash','coupon_id_hash']]\n",
    "df_valid.drop(['user_id_hash','coupon_id_hash'], axis=1, inplace=True)\n",
    "df_valid = df_valid[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â All needs to go to libffm format\n",
    "XLEARN_DIR = inp_dir+\"xlearn_data\"\n",
    "train_data_file = os.path.join(XLEARN_DIR,\"xltrain_ffm.txt\")\n",
    "valid_data_file = os.path.join(XLEARN_DIR,\"xlvalid_ffm.txt\")\n",
    "xlmodel_fname = os.path.join(XLEARN_DIR,\"xlffm_model.out\")\n",
    "xlpreds_fname = os.path.join(XLEARN_DIR,\"xlffm_preds.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LibFFM Format\n",
    "\n",
    "If we remember from the previous Chapter when feeding the data to the xlearn's `create_fm` method, these have to be in `libsvm` format. In our example:\n",
    "\n",
    "    Yes P-ESPN:1 A-Nike:1 G-Male:1\n",
    "\n",
    "Luckily for us, `sklearn` comes with two convenient utilities in the `datasets` module: `dump_svmlight_file` and `load_svmlight_file`. When using the `crete_ffm` method, we need to encode the \"field\". There are a number of ways of doing it, please read Section 3.3 of their [paper](https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf). For example, for categorical features we do: \n",
    "\n",
    "    Yes P:P-ESPN:1 A:A-Nike:1 G:G-Male:1\n",
    "    \n",
    "For numerical features, let's consider the following example (extracted from their paper):\n",
    "\n",
    "| Accepted | AR | Hidx | Cite| \n",
    "|----|-------|--------|--|\n",
    "| YES| 45.47  | 2   |3 |\n",
    "\n",
    "This instance would be represented as:\n",
    "\n",
    "    Yes AR:45:1 Hidx:2:1 Cite:3:1\n",
    "\n",
    "Fortunately, there are lots of clever people around and thanks to this Kaggle [kernel](https://www.kaggle.com/scirpus/libffm-generator-lb-280) by [Scirpus](https://www.kaggle.com/scirpus) we have a function that does the job. It is included in the `recutils.datasets` module in this repo.\n",
    "\n",
    "This is how I use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdict = {}\n",
    "for x in num_cols:\n",
    "    catdict[x] = 0\n",
    "for x in cat_cols:\n",
    "    catdict[x] = 1\n",
    "\n",
    "currentcode = len(num_cols)\n",
    "catcodes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 100000\n",
      "Row 200000\n",
      "Row 300000\n",
      "Row 400000\n",
      "Row 500000\n",
      "Row 600000\n",
      "Row 700000\n",
      "Row 800000\n",
      "Row 900000\n",
      "Row 1000000\n",
      "Row 1100000\n",
      "Row 1200000\n",
      "Row 1300000\n",
      "Row 1400000\n",
      "Row 1500000\n",
      "8.224 min\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "currentcode_tr, catcodes_tr =  dump_libffm_file(df_train,\n",
    "    target, catdict, currentcode, catcodes, train_data_file, verbose=True)\n",
    "print(\"{} min\".format(round((time()-start)/60., 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 100000\n",
      "Row 200000\n",
      "Row 300000\n",
      "Row 400000\n",
      "Row 500000\n",
      "Row 600000\n",
      "Row 700000\n",
      "Row 800000\n",
      "Row 900000\n",
      "Row 1000000\n",
      "Row 1100000\n",
      "Row 1200000\n",
      "Row 1300000\n",
      "Row 1400000\n",
      "Row 1500000\n",
      "Row 1600000\n",
      "Row 1700000\n",
      "Row 1800000\n",
      "Row 1900000\n",
      "Row 2000000\n",
      "Row 2100000\n",
      "11.476 min\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "currentcode_va, catcodes_va =  dump_libffm_file(df_valid,\n",
    "    target, catdict, currentcode_tr, catcodes_tr, valid_data_file, verbose=True)\n",
    "print(\"{} min\".format(round((time()-start)/60., 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 Experiments\n",
    "\n",
    "### 13.2.1 Experiment 1: defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start with the optimization let's try the defaults\n",
    "params = {'epoch': 20, 'task': 'reg', 'metric': 'rmse'}\n",
    "xl_model = xl.create_ffm()\n",
    "xl_model.setTrain(train_data_file)\n",
    "xl_model.setTest(valid_data_file)\n",
    "xl_model.fit(params, xlmodel_fname)\n",
    "xl_model.predict(xlmodel_fname, xlpreds_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026023183621136616\n"
     ]
    }
   ],
   "source": [
    "preds = np.loadtxt(xlpreds_fname)\n",
    "df_preds['interest'] = preds\n",
    "\n",
    "df_ranked = df_preds.sort_values(['user_id_hash', 'interest'],\n",
    "    ascending=[False, False])\n",
    "df_ranked = (df_ranked\n",
    "    .groupby('user_id_hash')['coupon_id_hash']\n",
    "    .apply(list)\n",
    "    .reset_index())\n",
    "recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "    index=df_ranked.user_id_hash).to_dict()\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "for k,_ in recomendations_dict.items():\n",
    "    actual.append(list(interactions_valid_dict[k]))\n",
    "    pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "print(mapk(actual,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.026 out of the box! That is encouraging. Let's see if we can push it to higher values with some optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2.2 Experiment 2: with optimization\n",
    "\n",
    "My initial idea was to use the `df_train` dataset and split it into training and evaluation for optimization purposes. This way, I would be able to set the `early_stopping` parameter in `xlearn`. I would then train and evaluate with these datasets and predict with the original validation data (`df_valid`) that is just the cartesian product of the validation coupons and the users that were seen during both training and validation.\n",
    "\n",
    "However, in the many manual runs, I never found that the algorithm *\"early-stopped\"*. Therefore, I decided to just use the existing training and validation data files (train_data_file and valid_data_file) and don't use early stopping. Nonetheless, below I also include the code that one would use if you want to use early stopping. \n",
    "\n",
    "Let's have a look to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE TWO CELLS BELOW IF YOU EVENTUALLY WANT TO USE EARLY STOPPING\n",
    "\n",
    "# #Â Train and validation to used during optimization (they will both come from df_train)\n",
    "# train_data_file_opt = os.path.join(XLEARN_DIR,\"xltrain_ffm_opt.txt\")\n",
    "# valid_data_file_opt = os.path.join(XLEARN_DIR,\"xlvalid_ffm_opt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_opt, df_valid_opt = train_test_split(df_train, test_size=0.3, random_state=1981)\n",
    "\n",
    "# catdict = {}\n",
    "# for x in num_cols:\n",
    "#     catdict[x] = 0\n",
    "# for x in cat_cols:\n",
    "#     catdict[x] = 1\n",
    "\n",
    "# currentcode = len(num_cols)\n",
    "# catcodes = {}\n",
    "\n",
    "# currentcode_tr_opt, catcodes_tr_opt =  dump_libffm_file(df_train_opt,\n",
    "#     target, catdict, currentcode, catcodes, train_data_file_opt, verbose=True)\n",
    "\n",
    "# currentcode_va_opt, catcodes_va_opt =  dump_libffm_file(df_valid_opt,\n",
    "#     target, catdict, currentcode_tr_opt, catcodes_tr_opt, valid_data_file_opt, verbose=True)\n",
    "\n",
    "# currentcode_va, catcodes_va =  dump_libffm_file(df_valid,\n",
    "#     target, catdict, currentcode_va_opt, catcodes_va_opt, valid_data_file, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temporal files for model and predictions output during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal outputs of the model during optimization\n",
    "xlmodel_fname_tmp = os.path.join(XLEARN_DIR,\"xlffm_model_tmp.out\")\n",
    "xlpreds_fname_tmp = os.path.join(XLEARN_DIR,\"xlffm_preds_tmp.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xl_objective(params):\n",
    "\n",
    "    start = time()\n",
    "    xl_objective.i+=1\n",
    "\n",
    "    params['task'] = 'reg'\n",
    "    params['metric'] = 'rmse'\n",
    "    \n",
    "    # uncomment this line if you are using early stopping and define your window\n",
    "    # params['stop_window'] = 3\n",
    "\n",
    "    # remember hyperopt casts as floats\n",
    "    params['epoch'] = int(params['epoch'])\n",
    "    params['k'] = int(params['k'])\n",
    "\n",
    "    xl_model.fit(params, tmp_model_fname)\n",
    "    xl_model.predict(tmp_model_fname, tmp_preds_fname)\n",
    "\n",
    "    # We optimize using the recommendations success metric: MAP\n",
    "    #Â Therefore, we add the predictions to the df_pred dataframe, \n",
    "    # we rank and calculate the MAP\n",
    "    predictions = np.loadtxt(preds_fname)\n",
    "    df_preds['interest'] = predictions\n",
    "\n",
    "    df_ranked = df_preds.sort_values(['user_id_hash', 'interest'],\n",
    "        ascending=[False, False])\n",
    "    df_ranked = (df_ranked\n",
    "        .groupby('user_id_hash')['coupon_id_hash']\n",
    "        .apply(list)\n",
    "        .reset_index())\n",
    "    recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "        index=df_ranked.user_id_hash).to_dict()\n",
    "\n",
    "    actual = []\n",
    "    pred = []\n",
    "    for k,_ in recomendations_dict.items():\n",
    "        actual.append(list(interactions_valid_dict[k]))\n",
    "        pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "    score = mapk(actual,pred)\n",
    "    end = round((time() - start)/60.,2)\n",
    "\n",
    "    print(\"INFO: iteration {} was completed in {} min. Score {:.3f}\".format(xl_objective.i, end, score))\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the parameter space. These values are mostly based on the values I see in their [documentation](http://xlearn-doc.readthedocs.io/en/latest/python_api.html#). Nonetheless, this process takes ages for the size of the dataset, so we will limit our exploration to \"thin\" ranges. Also note that I have not run some cells in the notebook. As I mentioned, it takes a long time, so I use `screen` in the terminal and left the process running for some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_parameter_space = {\n",
    "    'lr': hp.uniform('lr', 0.1, 0.4),\n",
    "    'lambda': hp.uniform('lambda', 0.00002, 0.0001),\n",
    "    'init': hp.uniform('init', 0.4, 0.8),\n",
    "    'epoch': hp.quniform('epoch', 5, 20, 2),\n",
    "    'k': hp.quniform('k', 4, 8, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model and load the corresponding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_model = xl.create_ffm()\n",
    "xl_model.setTrain(train_data_file)\n",
    "xl_model.setTest(valid_data_file)\n",
    "\n",
    "# # IF YOU WERE USING EARLY STOP THESE CELL WOULD LOOK LIKE THIS:\n",
    "# xl_model = xl.create_ffm()\n",
    "# xl_model.setTrain(train_data_file_opt)\n",
    "# xl_model.setValidate(valid_data_file_opt)\n",
    "# xl_model.setTest(valid_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And optimize (go for a coffee, a run, a swim, a night out...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "xl_objective.i = 0\n",
    "best_ffm = fmin(\n",
    "    fn=xl_objective,\n",
    "    space=xl_parameter_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=7,\n",
    "    trials=trials\n",
    "    )\n",
    "pickle.dump(best_ffm, open(os.path.join(XLEARN_DIR,'best_ffm.p'), \"wb\"))\n",
    "pickle.dump(trials.best_trial, open(os.path.join(XLEARN_DIR,'best_trial_ffm.p'), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and I never managed to get anything better than **MAP@10=0.028**, which is not bad, for this parameters. Also note that **I only run 7 iterations**. As I mentioned in the previous Chapter (and below) either I am doing something wrong or there is a problem with the package, since each iteration accumulates memory at a 3GB+ per iteration. I guess that if this problem is fixed and I can run more iteration maybe we can get to values of 0.03 or higher, similar to those obtained with `lightGBM`.\n",
    "\n",
    "Anyway, best aparameters obtained out of these 7 iterations where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 20.0,\n",
       " 'init': 0.5727517342785235,\n",
       " 'k': 5.0,\n",
       " 'lambda': 3.899154394317734e-05,\n",
       " 'lr': 0.1598910860257523}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ffm = pickle.load(open(os.path.join(XLEARN_DIR,'best_ffm.p'), \"rb\"))\n",
    "best_ffm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 VEREDICT\n",
    "\n",
    "As I mentioned in the previous Chapter `xlearn` is not production ready. There are a number of aspects that need refinement. Here are a few of the problems I have faced, from least to most relevant:\n",
    "\n",
    "1. Too much verbosity even when is `setQuiet`.\n",
    "2. The sklearn API is bit \"odd\". I normally obtained all `nan` when the process worked well with native methods.\n",
    "3. Still with `nan`, sometimes, after a run when all seemed to be ok, I obtained a `test loss: nan` message, yet the `MAP` was still decent (MAP@10$\\geq$0.025). Maybe is because the `rmse` as meassure by the package was negligible(?).\n",
    "4. As soon as there is a `\"file does not exists\"` error the program terminates and expels you out from interactive tools like the `ipython` console. Not a deal breaker, but annoying.\n",
    "5. Small changes in parameters lead to large changes in the predicted `rmse` and `MAP`. I personally do not feel confident when these things happen. However, might also have to do with the data, although this behaviour was never seen when using `lightGBM`.\n",
    "6. It is hard to access to the model results. For example, I can't find the details of the folds (even the score) when using `cv`\n",
    "7. You will have noticed when using `hyperopt` I only run 7 iterations. This is because every iteration adds around $\\sim$3.5GB of RAM. I am using a c5.4xlarge with 30GB, so 7 is the maximum number I can run before I see the nice `killed` message. I am not sure whether this is the expected behaviour or there is some kind of memory leak. I tried removing the model in each iteration, as well as the `xlffm_model_tmp.out` file in case the information accumulates in the file and blows up when loaded (`xl_model.predict(tmp_model_fname, tmp_preds_fname)`) but nothing helped and the memory is not released. Maybe a workaround for this issue is using `skopt` and the `x0` initialization parameter. We could run steps of 7 iterations and start the next one with the best parameters from the previous one. To be honest, only writting it sounds a bit painful, so I will leave it to you if you want to give it a go.\n",
    "\n",
    "For all of the above, I can only conclude that while it has been \"fun\" to play with the package for a while, I would probably turn to other packages when it comes to factorization methods, if I decided to go with them to production. `ALS` in the `Spark MLlib` has been a good option for me in the past. I recently came accross the [spotlight](https://maciejkula.github.io/spotlight/) package, by the creator of `lightFM`, that also seems a potential option. However, is based on `Pytorch` which, by the time of writting, is not production ready either. In their site they say version 1.0 ready for research and production will be out soon.\n",
    "\n",
    "Let's now move onto our final example. A Deep Learning based recommendation algorithm. The Ponpare dataset is not really well suited for these types of algorithms (I discuss further in the next chapter), but let's simply illustrate an example and I will use a more suited dataset in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
