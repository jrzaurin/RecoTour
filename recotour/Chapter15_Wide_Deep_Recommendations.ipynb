{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 15\n",
    "\n",
    "### 15.1 Wide and Deep Regression:\n",
    "\n",
    "Having gone through Chapter 14, this Chapter will be mostly code, running a series of experiments with a brief discussion on the results. \n",
    "\n",
    "let's start as always loading the required libraries and defining some paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from recutils.wide_deep import WideDeepLoader, WideDeep\n",
    "from recutils.average_precision import mapk\n",
    "\n",
    "WD_DIR = \"../datasets/Ponpare/data_processed/wide_deep\"\n",
    "wd_dataset_fname = \"wd_dataset.p\"\n",
    "wd_interactions_fname = \"interactions_dict.p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `WideDeepLoader` and `WideDeep` classes are well explained (I think...) in this [repo](https://github.com/jrzaurin/Wide-and-Deep-PyTorch) that I wrote a while ago. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_dataset = pickle.load(open(os.path.join(WD_DIR,wd_dataset_fname), \"rb\"))\n",
    "wd_interactions = pickle.load(open(os.path.join(WD_DIR,wd_interactions_fname), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model inputs\n",
    "wide_dim = wd_dataset['train_dataset']['wide'].shape[1]\n",
    "deep_column_idx = wd_dataset['deep_column_idx']\n",
    "continuous_cols = wd_dataset['continuous_cols']\n",
    "embeddings_input= wd_dataset['embeddings_input']\n",
    "encoding_dict   = wd_dataset['encoding_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And prepare the datasets to be loaded to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactions during \"testing period\"\n",
    "df_all_interactions = wd_interactions['all_valid_interactions']\n",
    "\n",
    "# datasets\n",
    "train_dataset = wd_dataset['train_dataset']\n",
    "widedeep_dataset_tr = WideDeepLoader(train_dataset)\n",
    "\n",
    "valid_dataset = wd_dataset['valid_dataset']\n",
    "widedeep_dataset_val = WideDeepLoader(valid_dataset)\n",
    "\n",
    "test_dataset = wd_dataset['test_dataset']\n",
    "widedeep_dataset_te = WideDeepLoader(test_dataset, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ever decided to go to production with a similar solution to the one presented here (DL-based), **a proper optimization is required**. If you dive deep into the code, you will realize that it is not an easy (and quick) excercise. For the time being, let's manually define 5 settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually define some model set_ups for the experiment\n",
    "set_ups = {}\n",
    "set_ups['set_up_1'] = {}\n",
    "set_ups['set_up_1']['batch_size'] = 4096\n",
    "set_ups['set_up_1']['lr'] = 0.01\n",
    "set_ups['set_up_1']['hidden_layers'] = [50, 25]\n",
    "set_ups['set_up_1']['dropout'] = [0.5, 0.2]\n",
    "set_ups['set_up_1']['n_epochs'] = 3\n",
    "\n",
    "set_ups['set_up_2'] = {}\n",
    "set_ups['set_up_2']['batch_size'] = 4096\n",
    "set_ups['set_up_2']['lr'] = 0.01\n",
    "set_ups['set_up_2']['hidden_layers'] = [100, 50]\n",
    "set_ups['set_up_2']['dropout'] = [0.5, 0.5]\n",
    "set_ups['set_up_2']['n_epochs'] = 6\n",
    "\n",
    "set_ups['set_up_3'] = {}\n",
    "set_ups['set_up_3']['batch_size'] = 8192\n",
    "set_ups['set_up_3']['lr'] = 0.05\n",
    "set_ups['set_up_3']['hidden_layers'] = [100, 100, 100]\n",
    "set_ups['set_up_3']['dropout'] = [0.5, 0.5, 0.5]\n",
    "set_ups['set_up_3']['n_epochs'] = 10\n",
    "\n",
    "set_ups['set_up_4'] = {}\n",
    "set_ups['set_up_4']['batch_size'] = 8192\n",
    "set_ups['set_up_4']['lr'] = 0.05\n",
    "set_ups['set_up_4']['hidden_layers'] = [100, 50, 25]\n",
    "set_ups['set_up_4']['dropout'] = [0.5, 0.2, 0]\n",
    "set_ups['set_up_4']['n_epochs'] = 10\n",
    "\n",
    "set_ups['set_up_5'] = {}\n",
    "set_ups['set_up_5']['batch_size'] = 9216\n",
    "set_ups['set_up_5']['lr'] = 0.05\n",
    "set_ups['set_up_5']['hidden_layers'] = [100, 50]\n",
    "set_ups['set_up_5']['dropout'] = [0.5, 0.2]\n",
    "set_ups['set_up_5']['n_epochs'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high skewness of the interest-distribution to low values batch sizes need to be large, so the algorithm learns something everytime it sees a batch. Nonetheless, feel free to add any set up and see how it goes. \n",
    "\n",
    "Without further ado, let's run the experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: set_up_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 286/286 [00:13<00:00, 21.94it/s, loss=0.0668]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 30.57it/s, loss=0.0751]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 286/286 [00:13<00:00, 21.87it/s, loss=0.0682]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 30.30it/s, loss=0.061] \n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 286/286 [00:13<00:00, 21.86it/s, loss=0.0651]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 30.65it/s, loss=0.0752]\n",
      "  0%|          | 0/531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 531/531 [00:12<00:00, 42.17it/s]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precission: 0.012845159103252813\n",
      "INFO: set_up_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 286/286 [00:14<00:00, 20.38it/s, loss=0.0648]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 26.21it/s, loss=0.0717]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 286/286 [00:14<00:00, 20.27it/s, loss=0.0658]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 26.24it/s, loss=0.068] \n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 286/286 [00:13<00:00, 20.45it/s, loss=0.0661]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 26.45it/s, loss=0.0647]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 286/286 [00:14<00:00, 20.24it/s, loss=0.0608]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 26.58it/s, loss=0.0631]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 286/286 [00:14<00:00, 20.32it/s, loss=0.0633]\n",
      "valid: 100%|██████████| 96/96 [00:04<00:00, 22.88it/s, loss=0.0633]\n",
      "  0%|          | 0/286 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 286/286 [00:14<00:00, 20.11it/s, loss=0.0581]\n",
      "valid: 100%|██████████| 96/96 [00:03<00:00, 26.46it/s, loss=0.0733]\n",
      "  0%|          | 0/531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 531/531 [00:15<00:00, 35.34it/s]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precission: 0.013351588304874222\n",
      "INFO: set_up_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 143/143 [00:12<00:00, 11.19it/s, loss=0.0754]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.23it/s, loss=0.075] \n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 143/143 [00:12<00:00, 11.29it/s, loss=0.0743]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.45it/s, loss=0.0688]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 143/143 [00:12<00:00, 11.17it/s, loss=0.0705]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.29it/s, loss=0.0722]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 143/143 [00:12<00:00, 11.25it/s, loss=0.0722]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.23it/s, loss=0.0743]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 143/143 [00:12<00:00, 11.16it/s, loss=0.0698]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.24it/s, loss=0.0706]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 143/143 [00:12<00:00, 11.10it/s, loss=0.0712]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.30it/s, loss=0.0711]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 143/143 [00:12<00:00, 11.22it/s, loss=0.0691]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.40it/s, loss=0.0714]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 143/143 [00:12<00:00, 11.19it/s, loss=0.0734]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.25it/s, loss=0.0706]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 143/143 [00:13<00:00, 10.83it/s, loss=0.0716]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 12.78it/s, loss=0.0753]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 143/143 [00:12<00:00, 11.17it/s, loss=0.0718]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.30it/s, loss=0.0746]\n",
      "  0%|          | 0/266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 266/266 [00:15<00:00, 17.16it/s]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precission: 0.01670946541345236\n",
      "INFO: set_up_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 143/143 [00:12<00:00, 11.33it/s, loss=0.0711]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.39it/s, loss=0.0739]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 143/143 [00:12<00:00, 11.32it/s, loss=0.0663]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.54it/s, loss=0.0691]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 143/143 [00:12<00:00, 11.33it/s, loss=0.0674]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.38it/s, loss=0.0673]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 143/143 [00:12<00:00, 11.34it/s, loss=0.065] \n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.63it/s, loss=0.0653]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 143/143 [00:12<00:00, 11.36it/s, loss=0.0658]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.44it/s, loss=0.0667]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6: 100%|██████████| 143/143 [00:12<00:00, 11.45it/s, loss=0.0635]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.41it/s, loss=0.0655]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7: 100%|██████████| 143/143 [00:12<00:00, 11.28it/s, loss=0.0636]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.54it/s, loss=0.0632]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8: 100%|██████████| 143/143 [00:12<00:00, 11.21it/s, loss=0.066] \n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.15it/s, loss=0.0682]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9: 100%|██████████| 143/143 [00:13<00:00, 10.59it/s, loss=0.0644]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.06it/s, loss=0.0665]\n",
      "  0%|          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10: 100%|██████████| 143/143 [00:12<00:00, 11.12it/s, loss=0.0644]\n",
      "valid: 100%|██████████| 48/48 [00:03<00:00, 13.27it/s, loss=0.0681]\n",
      "  0%|          | 0/266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 266/266 [00:15<00:00, 17.63it/s]\n",
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precission: 0.011362966813219183\n",
      "INFO: set_up_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 127/127 [00:12<00:00,  9.97it/s, loss=0.0751]\n",
      "valid: 100%|██████████| 43/43 [00:03<00:00, 11.76it/s, loss=0.0717]\n",
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2: 100%|██████████| 127/127 [00:12<00:00,  9.83it/s, loss=0.0741]\n",
      "valid: 100%|██████████| 43/43 [00:03<00:00, 11.76it/s, loss=0.0709]\n",
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3: 100%|██████████| 127/127 [00:12<00:00, 10.05it/s, loss=0.073] \n",
      "valid: 100%|██████████| 43/43 [00:03<00:00, 11.92it/s, loss=0.0701]\n",
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4: 100%|██████████| 127/127 [00:12<00:00,  9.98it/s, loss=0.0715]\n",
      "valid: 100%|██████████| 43/43 [00:03<00:00, 11.74it/s, loss=0.0684]\n",
      "  0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%|██████████| 127/127 [00:12<00:00, 10.03it/s, loss=0.0703]\n",
      "valid: 100%|██████████| 43/43 [00:03<00:00, 11.75it/s, loss=0.0747]\n",
      "  0%|          | 0/236 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 236/236 [00:15<00:00, 15.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precission: 0.016635405045086905\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for set_up_name, params in set_ups.items():\n",
    "    print(\"INFO: {}\".format(set_up_name))\n",
    "\n",
    "    batch_size = params['batch_size']\n",
    "    hidden_layers = params['hidden_layers']\n",
    "    dropout = params['dropout']\n",
    "    n_epochs = params['n_epochs']\n",
    "    lr = params['lr']\n",
    "\n",
    "    train_loader = DataLoader(dataset=widedeep_dataset_tr,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "\n",
    "    eval_loader = DataLoader(dataset=widedeep_dataset_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "\n",
    "    test_loader = DataLoader(dataset=widedeep_dataset_te,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4)\n",
    "\n",
    "    model = WideDeep(\n",
    "        wide_dim,\n",
    "        embeddings_input,\n",
    "        continuous_cols,\n",
    "        deep_column_idx,\n",
    "        hidden_layers,\n",
    "        dropout,\n",
    "        encoding_dict\n",
    "        )\n",
    "    model.cuda()\n",
    "\n",
    "    criterion = F.mse_loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Adding schedulers. These need to be (obviously) define after the optimizer. \n",
    "    # Therefore I can include them as part of the set ups\n",
    "    if set_up_name is 'set_up_1':\n",
    "        lr_scheduler = None\n",
    "    elif set_up_name is 'set_up_2':\n",
    "        lr_scheduler = StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "    elif set_up_name is 'set_up_3':\n",
    "        lr_scheduler = MultiStepLR(optimizer, milestones=[3,8], gamma=0.1)\n",
    "    elif set_up_name is 'set_up_4':\n",
    "        lr_scheduler = MultiStepLR(optimizer, milestones=[3,8], gamma=0.1)\n",
    "    elif set_up_name is 'set_up_5':\n",
    "        lr_scheduler = MultiStepLR(optimizer, milestones=[2,4], gamma=0.1)\n",
    "\n",
    "    model.fit(\n",
    "        train_loader,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        n_epochs=n_epochs,\n",
    "        eval_loader=eval_loader,\n",
    "        lr_scheduler=lr_scheduler\n",
    "        )\n",
    "    preds = model.predict(test_loader)\n",
    "\n",
    "    df_all_interactions['interest'] = preds\n",
    "    df_ranked = df_all_interactions.sort_values(['user_id_hash', 'interest'], ascending=[False, False])\n",
    "    df_ranked = (df_ranked\n",
    "        .groupby('user_id_hash')['coupon_id_hash']\n",
    "        .apply(list)\n",
    "        .reset_index())\n",
    "    recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "        index=df_ranked.user_id_hash).to_dict()\n",
    "    true_valid_interactions = wd_interactions['true_valid_interactions']\n",
    "\n",
    "    actual = []\n",
    "    pred = []\n",
    "    for k,_ in recomendations_dict.items():\n",
    "        actual.append(list(true_valid_interactions[k]))\n",
    "        pred.append(list(recomendations_dict[k]))\n",
    "    print(\"Mean Average Precission: {}\".format(mapk(actual,pred)))\n",
    "    results[set_up_name] = mapk(actual,pred)\n",
    "    del(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this work, all this deep learning (well, not that much) and this model does not perform better than \"most popular\" recommendations. \n",
    "\n",
    "Obviously, there are a couple of things to consider. First, surely there are more experiments to run and set ups to include to find a more optimal solution. The most straightforward update would be to include user and item embeddings (see experiments 2 and 3 in the `py_scripts` directory). I can anticipate that the results are not much better. \n",
    "\n",
    "In addition, you will see that the loss changes values constantly as we go through the epoch. In other words, the learning is not very stable. This might be the result of the set up and/or how we decided to prepare the data, i.e. what we pass through the deep and wide models. However, to me this further illustrates that the Ponpare dataset is not particularly well suited for these type of models. Most likely this is a combination of all things: inadequate set up, suboptimal data preprocessing and the nature of the dataset. Nonetheless, I hope you found some of the code here useful for the problems you might want to solve. \n",
    "\n",
    "This is the final technique I wanted to show for now. In the future I will include both other techniques and datsets. It is now time to choose one of the techniques from previous Chapters and perform a final test on the original (so far \"untouched\") test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
