{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 \n",
    "\n",
    "### 10.1 Non negative matrix factorization (NMF)\n",
    "\n",
    "If you have worked or are working with recommendation algorithms, I'd say you are familiar with matrix factorization. Just in case let's go quickly through some formulation before jumping into the code. \n",
    "\n",
    "Given a ratings (or scores) matrix $R$ with dimensions $M \\times N$ we aim to find two matrix $C$ and $U$ with dimensions $M \\times K$ and $N \\times K$ respectively such that\n",
    "\n",
    "$$R \\approx C \\times U^T = \\hat{R}$$\n",
    "\n",
    "$K$ are the latent factors (or latent dimensions) which we will choose at our convenience. Then the rating of item $i$ by user $j$ can be computed as the dot product \n",
    "\n",
    "$$ \\hat{r}_{ij} = c_i u_j^T = \\sum_{k=1}^k{c_{ik}u_{kj}}$$\n",
    "\n",
    "\n",
    "In our case, $R$, $C$ and $U$ are our interest, coupons and user matrices respectively. Since we have no measure of negative interest, all matrices will be non-negative and hence non-negative matrix factorization. You can find a nice tutorial in python [here](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/).\n",
    "\n",
    "Once we have computed $\\hat{R}$ we will be in a position where we can recommend existing coupons to customers based on past interactions. **However** let's emphasise once more that this is **NOT** the problem we are solving here. Here we have a batch of new, unseen coupons and we need to recommend them to existing customers. This is what I will do:\n",
    "\n",
    "1. Compute $\\hat{R}$, $C$ and $U$\n",
    "2. Compute similarity between new and old coupons based on features (price, category, etc), and assign the latent factors of the old coupons to the most similar new coupons. \n",
    "3. Build a dataset horizontally stacking user and item latent factors.\n",
    "4. Use a regressor to predict interest and rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import lightgbm as lgb\n",
    "\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix, load_npz\n",
    "from recutils.average_precision import mapk\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "inp_dir = \"../datasets/Ponpare/data_processed/\"\n",
    "train_dir = \"train\"\n",
    "valid_dir = \"valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation coupons\n",
    "df_coupons_train_feat = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_coupons_train_feat.p'))\n",
    "df_coupons_valid_feat = pd.read_pickle(os.path.join(inp_dir, valid_dir, 'df_coupons_valid_feat.p'))\n",
    "\n",
    "# train and validation coupon ids\n",
    "coupons_train_ids = df_coupons_train_feat.coupon_id_hash.values\n",
    "coupons_valid_ids = df_coupons_valid_feat.coupon_id_hash.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['coupon_id_hash']\n",
    "cat_cols = [c for c in df_coupons_train_feat.columns if c.endswith('_cat')]\n",
    "num_cols = [c for c in df_coupons_train_feat.columns if\n",
    "    (c not in cat_cols) and (c not in id_cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous Chapters, let's calculate the similarity between new and old coupons. \n",
    "\n",
    "**Note**. In the `recutils` module there is a submodule simply called `utils` that contains the `coupon_similarity_function` method. All the code below is wrapped up in that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a train/test flag\n",
    "df_coupons_train_feat['flag'] = 0\n",
    "df_coupons_valid_feat['flag'] = 1\n",
    "\n",
    "tmp_df = pd.concat(\n",
    "    [df_coupons_train_feat,df_coupons_valid_feat],\n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical columns\n",
    "tmp_df_num = tmp_df[num_cols]\n",
    "tmp_df_norm = (tmp_df_num-tmp_df_num.min())/(tmp_df_num.max()-tmp_df_num.min())\n",
    "tmp_df[num_cols] = tmp_df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot categorical\n",
    "tmp_df[cat_cols] = tmp_df[cat_cols].astype('category')\n",
    "tmp_df_dummy = pd.get_dummies(tmp_df, columns=cat_cols)\n",
    "\n",
    "coupons_train_feat = tmp_df_dummy[tmp_df_dummy.flag==0]\n",
    "coupons_valid_feat = tmp_df_dummy[tmp_df_dummy.flag==1]\n",
    "coupons_train_feat = (coupons_train_feat\n",
    "    .drop(['flag','coupon_id_hash'], axis=1)\n",
    "    .values)\n",
    "coupons_valid_feat = (coupons_valid_feat\n",
    "    .drop(['flag','coupon_id_hash'], axis=1)\n",
    "    .values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mtx = pairwise_distances(coupons_valid_feat, coupons_train_feat, metric='cosine')\n",
    "valid_to_train_top_n_idx = np.apply_along_axis(np.argsort, 1, dist_mtx)\n",
    "valid_to_train_most_similar = dict(zip(coupons_valid_ids,\n",
    "    coupons_train_ids[valid_to_train_top_n_idx[:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31e98da3c0c1df31559848688d25eb01'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_to_train_most_similar['f1540e7a08cce1a8d5a5ebd8233e1db0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat</th>\n",
       "      <th>usable_date_tue_cat</th>\n",
       "      <th>usable_date_wed_cat</th>\n",
       "      <th>usable_date_thu_cat</th>\n",
       "      <th>usable_date_fri_cat</th>\n",
       "      <th>usable_date_sat_cat</th>\n",
       "      <th>usable_date_sun_cat</th>\n",
       "      <th>usable_date_holiday_cat</th>\n",
       "      <th>usable_date_before_holiday_cat</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>validperiod_method1_cat</th>\n",
       "      <th>validperiod_method2_cat</th>\n",
       "      <th>validfrom_method1_cat</th>\n",
       "      <th>validfrom_method2_cat</th>\n",
       "      <th>validend_method1_cat</th>\n",
       "      <th>validend_method2_cat</th>\n",
       "      <th>dispfrom_cat</th>\n",
       "      <th>dispend_cat</th>\n",
       "      <th>dispperiod_cat</th>\n",
       "      <th>price_rate_cat</th>\n",
       "      <th>catalog_price_cat</th>\n",
       "      <th>discount_price_cat</th>\n",
       "      <th>capsule_text_cat</th>\n",
       "      <th>genre_name_cat</th>\n",
       "      <th>large_area_name_cat</th>\n",
       "      <th>ken_name_cat</th>\n",
       "      <th>small_area_name_cat</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17075</th>\n",
       "      <td>54</td>\n",
       "      <td>2150</td>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>31e98da3c0c1df31559848688d25eb01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "17075          54           2150             980           3           90   \n",
       "\n",
       "       usable_date_mon_cat  usable_date_tue_cat  usable_date_wed_cat  \\\n",
       "17075                    3                    3                    3   \n",
       "\n",
       "       usable_date_thu_cat  usable_date_fri_cat  usable_date_sat_cat  \\\n",
       "17075                    3                    3                    3   \n",
       "\n",
       "       usable_date_sun_cat  usable_date_holiday_cat  \\\n",
       "17075                    3                        3   \n",
       "\n",
       "       usable_date_before_holiday_cat                    coupon_id_hash  \\\n",
       "17075                               3  31e98da3c0c1df31559848688d25eb01   \n",
       "\n",
       "      validperiod_method1_cat validperiod_method2_cat  validfrom_method1_cat  \\\n",
       "17075                       4                       1                      7   \n",
       "\n",
       "       validfrom_method2_cat  validend_method1_cat  validend_method2_cat  \\\n",
       "17075                      2                     7                     0   \n",
       "\n",
       "       dispfrom_cat  dispend_cat dispperiod_cat price_rate_cat  \\\n",
       "17075             1            4              1              1   \n",
       "\n",
       "      catalog_price_cat discount_price_cat  capsule_text_cat  genre_name_cat  \\\n",
       "17075                 0                  0                 6               6   \n",
       "\n",
       "       large_area_name_cat  ken_name_cat  small_area_name_cat  flag  \n",
       "17075                    0             2                    5     0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coupons_train_feat[df_coupons_train_feat.coupon_id_hash == '31e98da3c0c1df31559848688d25eb01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_rate</th>\n",
       "      <th>catalog_price</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>dispperiod</th>\n",
       "      <th>validperiod</th>\n",
       "      <th>usable_date_mon_cat</th>\n",
       "      <th>usable_date_tue_cat</th>\n",
       "      <th>usable_date_wed_cat</th>\n",
       "      <th>usable_date_thu_cat</th>\n",
       "      <th>usable_date_fri_cat</th>\n",
       "      <th>usable_date_sat_cat</th>\n",
       "      <th>usable_date_sun_cat</th>\n",
       "      <th>usable_date_holiday_cat</th>\n",
       "      <th>usable_date_before_holiday_cat</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>validperiod_method1_cat</th>\n",
       "      <th>validperiod_method2_cat</th>\n",
       "      <th>validfrom_method1_cat</th>\n",
       "      <th>validfrom_method2_cat</th>\n",
       "      <th>validend_method1_cat</th>\n",
       "      <th>validend_method2_cat</th>\n",
       "      <th>dispfrom_cat</th>\n",
       "      <th>dispend_cat</th>\n",
       "      <th>dispperiod_cat</th>\n",
       "      <th>price_rate_cat</th>\n",
       "      <th>catalog_price_cat</th>\n",
       "      <th>discount_price_cat</th>\n",
       "      <th>capsule_text_cat</th>\n",
       "      <th>genre_name_cat</th>\n",
       "      <th>large_area_name_cat</th>\n",
       "      <th>ken_name_cat</th>\n",
       "      <th>small_area_name_cat</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>55</td>\n",
       "      <td>2200</td>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>f1540e7a08cce1a8d5a5ebd8233e1db0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_rate  catalog_price  discount_price  dispperiod  validperiod  \\\n",
       "210          55           2200             980           3           99   \n",
       "\n",
       "     usable_date_mon_cat  usable_date_tue_cat  usable_date_wed_cat  \\\n",
       "210                    3                    3                    3   \n",
       "\n",
       "     usable_date_thu_cat  usable_date_fri_cat  usable_date_sat_cat  \\\n",
       "210                    3                    3                    3   \n",
       "\n",
       "     usable_date_sun_cat  usable_date_holiday_cat  \\\n",
       "210                    3                        3   \n",
       "\n",
       "     usable_date_before_holiday_cat                    coupon_id_hash  \\\n",
       "210                               3  f1540e7a08cce1a8d5a5ebd8233e1db0   \n",
       "\n",
       "    validperiod_method1_cat validperiod_method2_cat  validfrom_method1_cat  \\\n",
       "210                       4                       1                      7   \n",
       "\n",
       "     validfrom_method2_cat  validend_method1_cat  validend_method2_cat  \\\n",
       "210                      2                     7                     0   \n",
       "\n",
       "     dispfrom_cat  dispend_cat dispperiod_cat price_rate_cat  \\\n",
       "210             1            4              1              1   \n",
       "\n",
       "    catalog_price_cat discount_price_cat  capsule_text_cat  genre_name_cat  \\\n",
       "210                 0                  0                 6               6   \n",
       "\n",
       "     large_area_name_cat  ken_name_cat  small_area_name_cat  flag  \n",
       "210                    0             2                    5     1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coupons_valid_feat[df_coupons_valid_feat.coupon_id_hash == \"f1540e7a08cce1a8d5a5ebd8233e1db0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, very similar. \n",
    "\n",
    "Let's now load the interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22623x18622 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1560464 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the activity matrix and dict of indexes\n",
    "interactions_mtx = load_npz(os.path.join(inp_dir, train_dir, \"interactions_mtx.npz\"))\n",
    "items_idx_dict = pickle.load(open(os.path.join(inp_dir, train_dir, \"items_idx_dict.p\"),'rb'))\n",
    "users_idx_dict = pickle.load(open(os.path.join(inp_dir, train_dir, \"users_idx_dict.p\"),'rb'))\n",
    "interactions_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None negative matrix factorization with default values and n_comp (50 to start with) components/factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp = 50\n",
    "nmf_model = NMF(n_components=ncomp, init='random', random_state=1981)\n",
    "user_factors = nmf_model.fit_transform(interactions_mtx)\n",
    "item_factors = nmf_model.components_.T\n",
    "# pickle.dump(nmf_model, open(\"../datasets/Ponpare/data_processed/models/nmf_model.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that we have our item and user projections onto our latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22623, 50)\n",
      "(18622, 50)\n"
     ]
    }
   ],
   "source": [
    "print(user_factors.shape)\n",
    "print(item_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure every user/item points to the right latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure every user/item points to the right factors\n",
    "user_factors_dict = {}\n",
    "for k,v in users_idx_dict.items():\n",
    "    user_factors_dict[k] = user_factors[users_idx_dict[k]]\n",
    "\n",
    "item_factors_dict = {}\n",
    "for k,v in items_idx_dict.items():\n",
    "    item_factors_dict[k] = item_factors[items_idx_dict[k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now only thing left to do is to train a regressor, more precisely, our favourite lightGBM. Let's build the training/testing datasets and build the model. By the way, now there are no categorical features, and our life is just a bit esier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interest = pd.read_pickle(os.path.join(inp_dir, train_dir, 'df_interest.p'))\n",
    "df_user_factors = (pd.DataFrame.from_dict(user_factors_dict, orient=\"index\")\n",
    "    .reset_index())\n",
    "df_user_factors.columns = ['user_id_hash'] + ['user_factor_'+str(i) for i in range(ncomp)]\n",
    "df_item_factors = (pd.DataFrame.from_dict(item_factors_dict, orient=\"index\")\n",
    "    .reset_index())\n",
    "df_item_factors.columns = ['coupon_id_hash'] + ['item_factor_'+str(i) for i in range(ncomp)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1560464, 103)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>interest</th>\n",
       "      <th>item_factor_0</th>\n",
       "      <th>item_factor_1</th>\n",
       "      <th>item_factor_2</th>\n",
       "      <th>item_factor_3</th>\n",
       "      <th>item_factor_4</th>\n",
       "      <th>item_factor_5</th>\n",
       "      <th>item_factor_6</th>\n",
       "      <th>item_factor_7</th>\n",
       "      <th>item_factor_8</th>\n",
       "      <th>item_factor_9</th>\n",
       "      <th>item_factor_10</th>\n",
       "      <th>item_factor_11</th>\n",
       "      <th>item_factor_12</th>\n",
       "      <th>item_factor_13</th>\n",
       "      <th>item_factor_14</th>\n",
       "      <th>item_factor_15</th>\n",
       "      <th>item_factor_16</th>\n",
       "      <th>item_factor_17</th>\n",
       "      <th>item_factor_18</th>\n",
       "      <th>item_factor_19</th>\n",
       "      <th>item_factor_20</th>\n",
       "      <th>item_factor_21</th>\n",
       "      <th>item_factor_22</th>\n",
       "      <th>item_factor_23</th>\n",
       "      <th>item_factor_24</th>\n",
       "      <th>item_factor_25</th>\n",
       "      <th>item_factor_26</th>\n",
       "      <th>item_factor_27</th>\n",
       "      <th>item_factor_28</th>\n",
       "      <th>item_factor_29</th>\n",
       "      <th>item_factor_30</th>\n",
       "      <th>item_factor_31</th>\n",
       "      <th>item_factor_32</th>\n",
       "      <th>item_factor_33</th>\n",
       "      <th>item_factor_34</th>\n",
       "      <th>item_factor_35</th>\n",
       "      <th>item_factor_36</th>\n",
       "      <th>item_factor_37</th>\n",
       "      <th>item_factor_38</th>\n",
       "      <th>item_factor_39</th>\n",
       "      <th>item_factor_40</th>\n",
       "      <th>item_factor_41</th>\n",
       "      <th>item_factor_42</th>\n",
       "      <th>item_factor_43</th>\n",
       "      <th>item_factor_44</th>\n",
       "      <th>item_factor_45</th>\n",
       "      <th>item_factor_46</th>\n",
       "      <th>...</th>\n",
       "      <th>user_factor_0</th>\n",
       "      <th>user_factor_1</th>\n",
       "      <th>user_factor_2</th>\n",
       "      <th>user_factor_3</th>\n",
       "      <th>user_factor_4</th>\n",
       "      <th>user_factor_5</th>\n",
       "      <th>user_factor_6</th>\n",
       "      <th>user_factor_7</th>\n",
       "      <th>user_factor_8</th>\n",
       "      <th>user_factor_9</th>\n",
       "      <th>user_factor_10</th>\n",
       "      <th>user_factor_11</th>\n",
       "      <th>user_factor_12</th>\n",
       "      <th>user_factor_13</th>\n",
       "      <th>user_factor_14</th>\n",
       "      <th>user_factor_15</th>\n",
       "      <th>user_factor_16</th>\n",
       "      <th>user_factor_17</th>\n",
       "      <th>user_factor_18</th>\n",
       "      <th>user_factor_19</th>\n",
       "      <th>user_factor_20</th>\n",
       "      <th>user_factor_21</th>\n",
       "      <th>user_factor_22</th>\n",
       "      <th>user_factor_23</th>\n",
       "      <th>user_factor_24</th>\n",
       "      <th>user_factor_25</th>\n",
       "      <th>user_factor_26</th>\n",
       "      <th>user_factor_27</th>\n",
       "      <th>user_factor_28</th>\n",
       "      <th>user_factor_29</th>\n",
       "      <th>user_factor_30</th>\n",
       "      <th>user_factor_31</th>\n",
       "      <th>user_factor_32</th>\n",
       "      <th>user_factor_33</th>\n",
       "      <th>user_factor_34</th>\n",
       "      <th>user_factor_35</th>\n",
       "      <th>user_factor_36</th>\n",
       "      <th>user_factor_37</th>\n",
       "      <th>user_factor_38</th>\n",
       "      <th>user_factor_39</th>\n",
       "      <th>user_factor_40</th>\n",
       "      <th>user_factor_41</th>\n",
       "      <th>user_factor_42</th>\n",
       "      <th>user_factor_43</th>\n",
       "      <th>user_factor_44</th>\n",
       "      <th>user_factor_45</th>\n",
       "      <th>user_factor_46</th>\n",
       "      <th>user_factor_47</th>\n",
       "      <th>user_factor_48</th>\n",
       "      <th>user_factor_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a971028976de1a048c6b711b7889d17</td>\n",
       "      <td>48948527d6a8e075090393f3d95e31bf</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036788</td>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.029339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a971028976de1a048c6b711b7889d17</td>\n",
       "      <td>a262c7ff56a5cd3de3c5c40443f3018c</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>21.018275</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a971028976de1a048c6b711b7889d17</td>\n",
       "      <td>7fc6567f470af5356ae97097dbe18486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.082221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a971028976de1a048c6b711b7889d17</td>\n",
       "      <td>db295c37a59baca890641e5faf0f2f7b</td>\n",
       "      <td>0.107283</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039814</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043538</td>\n",
       "      <td>0.021911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.124153</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.011877</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a971028976de1a048c6b711b7889d17</td>\n",
       "      <td>1dfb7cc88be25a8f7b435cd988859ebf</td>\n",
       "      <td>0.107283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007658</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash  \\\n",
       "0  7a971028976de1a048c6b711b7889d17  48948527d6a8e075090393f3d95e31bf   \n",
       "1  7a971028976de1a048c6b711b7889d17  a262c7ff56a5cd3de3c5c40443f3018c   \n",
       "2  7a971028976de1a048c6b711b7889d17  7fc6567f470af5356ae97097dbe18486   \n",
       "3  7a971028976de1a048c6b711b7889d17  db295c37a59baca890641e5faf0f2f7b   \n",
       "4  7a971028976de1a048c6b711b7889d17  1dfb7cc88be25a8f7b435cd988859ebf   \n",
       "\n",
       "   interest  item_factor_0  item_factor_1  item_factor_2  item_factor_3  \\\n",
       "0  0.450000       0.002203       0.000000       0.000000       0.002933   \n",
       "1  1.000000       0.000000       0.000000       0.000000       0.000000   \n",
       "2  1.000000       0.000000       0.000000       0.000000       0.000000   \n",
       "3  0.107283       0.012354       0.010444       0.009600       0.000000   \n",
       "4  0.107283       0.000000       0.000000       0.012573       0.000000   \n",
       "\n",
       "   item_factor_4  item_factor_5  item_factor_6  item_factor_7  item_factor_8  \\\n",
       "0       0.000000       0.000000       0.000000       0.000000            0.0   \n",
       "1       0.000000       0.009887       0.000000       0.004451            0.0   \n",
       "2       0.000000       7.082221       0.000000       0.000000            0.0   \n",
       "3       0.013905       0.000000       0.000000       0.004099            0.0   \n",
       "4       0.007583       0.000000       0.126861       0.000000            0.0   \n",
       "\n",
       "   item_factor_9  item_factor_10  item_factor_11  item_factor_12  \\\n",
       "0       0.000000        0.000000        0.000000        0.000000   \n",
       "1       0.014536        0.000000        0.000000        0.000000   \n",
       "2       0.000000        0.000000        0.000000        0.000000   \n",
       "3       0.000000        0.039814        0.059949        0.000000   \n",
       "4       0.000000        0.072697        0.000000        0.025464   \n",
       "\n",
       "   item_factor_13  item_factor_14  item_factor_15  item_factor_16  \\\n",
       "0        0.000000             0.0        0.000000        0.000000   \n",
       "1        0.004243             0.0        0.000000        0.000000   \n",
       "2        0.000000             0.0        0.000000        0.000000   \n",
       "3        0.000000             0.0        0.043538        0.021911   \n",
       "4        0.000000             0.0        0.000000        0.004041   \n",
       "\n",
       "   item_factor_17  item_factor_18  item_factor_19  item_factor_20  \\\n",
       "0             0.0        0.000000        0.000000        0.000000   \n",
       "1             0.0        0.011751       21.018275        0.000612   \n",
       "2             0.0        0.000000        0.000000        0.000000   \n",
       "3             0.0        0.000000        0.000000        0.000000   \n",
       "4             0.0        0.000000        0.000000        0.000000   \n",
       "\n",
       "   item_factor_21  item_factor_22  item_factor_23  item_factor_24  \\\n",
       "0        0.020744        0.000000        0.036788        0.015414   \n",
       "1        0.000000        0.002987        0.000000        0.000000   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.000000        0.000000        0.000000        0.000000   \n",
       "4        0.000000        0.000000        0.000000        0.000654   \n",
       "\n",
       "   item_factor_25  item_factor_26  item_factor_27  item_factor_28  \\\n",
       "0        0.008512        0.000000        0.000171        0.015847   \n",
       "1        0.000000        0.000000        0.000000        0.000000   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.023068        0.124153        0.138026        0.044227   \n",
       "4        0.032683        0.000000        0.000000        0.000000   \n",
       "\n",
       "   item_factor_29  item_factor_30  item_factor_31  item_factor_32  \\\n",
       "0        0.000000        0.009768        0.000000        0.003239   \n",
       "1        0.000000        0.000000        0.000000        0.000029   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.000000        0.000000        0.007606        0.000000   \n",
       "4        0.010861        0.000000        0.000000        0.000000   \n",
       "\n",
       "   item_factor_33  item_factor_34  item_factor_35  item_factor_36  \\\n",
       "0        0.002925        0.000000        0.000000        0.022358   \n",
       "1        0.000000        0.000000        0.017780        0.002519   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.067632        0.070299        0.011877        0.002830   \n",
       "4        0.157980        0.000000        0.000000        0.000000   \n",
       "\n",
       "   item_factor_37  item_factor_38  item_factor_39  item_factor_40  \\\n",
       "0             0.0             0.0        0.000000        0.001181   \n",
       "1             0.0             0.0        0.000000        0.001527   \n",
       "2             0.0             0.0        0.000000        0.000000   \n",
       "3             0.0             0.0        0.000000        0.000000   \n",
       "4             0.0             0.0        0.016541        0.000000   \n",
       "\n",
       "   item_factor_41  item_factor_42  item_factor_43  item_factor_44  \\\n",
       "0             0.0             0.0             0.0        0.062034   \n",
       "1             0.0             0.0             0.0        0.000000   \n",
       "2             0.0             0.0             0.0        0.000000   \n",
       "3             0.0             0.0             0.0        0.028807   \n",
       "4             0.0             0.0             0.0        0.007658   \n",
       "\n",
       "   item_factor_45  item_factor_46       ...        user_factor_0  \\\n",
       "0        0.000428        0.029339       ...             0.021197   \n",
       "1        0.000000        0.000000       ...             0.021197   \n",
       "2        0.000000        0.000000       ...             0.021197   \n",
       "3        0.000000        0.000000       ...             0.021197   \n",
       "4        0.001791        0.000000       ...             0.021197   \n",
       "\n",
       "   user_factor_1  user_factor_2  user_factor_3  user_factor_4  user_factor_5  \\\n",
       "0            0.0       0.035426            0.0            0.0       0.140428   \n",
       "1            0.0       0.035426            0.0            0.0       0.140428   \n",
       "2            0.0       0.035426            0.0            0.0       0.140428   \n",
       "3            0.0       0.035426            0.0            0.0       0.140428   \n",
       "4            0.0       0.035426            0.0            0.0       0.140428   \n",
       "\n",
       "   user_factor_6  user_factor_7  user_factor_8  user_factor_9  user_factor_10  \\\n",
       "0            0.0            0.0            0.0            0.0             0.0   \n",
       "1            0.0            0.0            0.0            0.0             0.0   \n",
       "2            0.0            0.0            0.0            0.0             0.0   \n",
       "3            0.0            0.0            0.0            0.0             0.0   \n",
       "4            0.0            0.0            0.0            0.0             0.0   \n",
       "\n",
       "   user_factor_11  user_factor_12  user_factor_13  user_factor_14  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_15  user_factor_16  user_factor_17  user_factor_18  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_19  user_factor_20  user_factor_21  user_factor_22  \\\n",
       "0        0.047493             0.0             0.0             0.0   \n",
       "1        0.047493             0.0             0.0             0.0   \n",
       "2        0.047493             0.0             0.0             0.0   \n",
       "3        0.047493             0.0             0.0             0.0   \n",
       "4        0.047493             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_23  user_factor_24  user_factor_25  user_factor_26  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_27  user_factor_28  user_factor_29  user_factor_30  \\\n",
       "0             0.0        0.137815             0.0             0.0   \n",
       "1             0.0        0.137815             0.0             0.0   \n",
       "2             0.0        0.137815             0.0             0.0   \n",
       "3             0.0        0.137815             0.0             0.0   \n",
       "4             0.0        0.137815             0.0             0.0   \n",
       "\n",
       "   user_factor_31  user_factor_32  user_factor_33  user_factor_34  \\\n",
       "0             0.0        0.010867        0.003565             0.0   \n",
       "1             0.0        0.010867        0.003565             0.0   \n",
       "2             0.0        0.010867        0.003565             0.0   \n",
       "3             0.0        0.010867        0.003565             0.0   \n",
       "4             0.0        0.010867        0.003565             0.0   \n",
       "\n",
       "   user_factor_35  user_factor_36  user_factor_37  user_factor_38  \\\n",
       "0        0.000003        0.092271             0.0             0.0   \n",
       "1        0.000003        0.092271             0.0             0.0   \n",
       "2        0.000003        0.092271             0.0             0.0   \n",
       "3        0.000003        0.092271             0.0             0.0   \n",
       "4        0.000003        0.092271             0.0             0.0   \n",
       "\n",
       "   user_factor_39  user_factor_40  user_factor_41  user_factor_42  \\\n",
       "0             0.0        0.002384             0.0             0.0   \n",
       "1             0.0        0.002384             0.0             0.0   \n",
       "2             0.0        0.002384             0.0             0.0   \n",
       "3             0.0        0.002384             0.0             0.0   \n",
       "4             0.0        0.002384             0.0             0.0   \n",
       "\n",
       "   user_factor_43  user_factor_44  user_factor_45  user_factor_46  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_47  user_factor_48  user_factor_49  \n",
       "0             0.0        0.000115             0.0  \n",
       "1             0.0        0.000115             0.0  \n",
       "2             0.0        0.000115             0.0  \n",
       "3             0.0        0.000115             0.0  \n",
       "4             0.0        0.000115             0.0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "df_train = pd.merge(df_interest[['user_id_hash','coupon_id_hash','interest']],\n",
    "    df_item_factors, on='coupon_id_hash')\n",
    "df_train = pd.merge(df_train, df_user_factors, on='user_id_hash')\n",
    "X = df_train.iloc[:,3:].values\n",
    "y = df_train.interest.values\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fe28f9f9055fde46855b1520a40e3c08'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VALIDATION\n",
    "interactions_valid_dict = pickle.load(\n",
    "    open(\"../datasets/Ponpare/data_processed/valid/interactions_valid_dict.p\",\"rb\"))\n",
    "\n",
    "# remember that one user that visited one coupon and that coupon is not in the training set of coupons.\n",
    "# and in consequence not in the interactions matrix\n",
    "interactions_valid_dict.pop(\"25e2b645bfcd0980b2a5d0a4833f237a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>coupon_id_hash</th>\n",
       "      <th>mapped_coupons</th>\n",
       "      <th>item_factor_0</th>\n",
       "      <th>item_factor_1</th>\n",
       "      <th>item_factor_2</th>\n",
       "      <th>item_factor_3</th>\n",
       "      <th>item_factor_4</th>\n",
       "      <th>item_factor_5</th>\n",
       "      <th>item_factor_6</th>\n",
       "      <th>item_factor_7</th>\n",
       "      <th>item_factor_8</th>\n",
       "      <th>item_factor_9</th>\n",
       "      <th>item_factor_10</th>\n",
       "      <th>item_factor_11</th>\n",
       "      <th>item_factor_12</th>\n",
       "      <th>item_factor_13</th>\n",
       "      <th>item_factor_14</th>\n",
       "      <th>item_factor_15</th>\n",
       "      <th>item_factor_16</th>\n",
       "      <th>item_factor_17</th>\n",
       "      <th>item_factor_18</th>\n",
       "      <th>item_factor_19</th>\n",
       "      <th>item_factor_20</th>\n",
       "      <th>item_factor_21</th>\n",
       "      <th>item_factor_22</th>\n",
       "      <th>item_factor_23</th>\n",
       "      <th>item_factor_24</th>\n",
       "      <th>item_factor_25</th>\n",
       "      <th>item_factor_26</th>\n",
       "      <th>item_factor_27</th>\n",
       "      <th>item_factor_28</th>\n",
       "      <th>item_factor_29</th>\n",
       "      <th>item_factor_30</th>\n",
       "      <th>item_factor_31</th>\n",
       "      <th>item_factor_32</th>\n",
       "      <th>item_factor_33</th>\n",
       "      <th>item_factor_34</th>\n",
       "      <th>item_factor_35</th>\n",
       "      <th>item_factor_36</th>\n",
       "      <th>item_factor_37</th>\n",
       "      <th>item_factor_38</th>\n",
       "      <th>item_factor_39</th>\n",
       "      <th>item_factor_40</th>\n",
       "      <th>item_factor_41</th>\n",
       "      <th>item_factor_42</th>\n",
       "      <th>item_factor_43</th>\n",
       "      <th>item_factor_44</th>\n",
       "      <th>item_factor_45</th>\n",
       "      <th>item_factor_46</th>\n",
       "      <th>...</th>\n",
       "      <th>user_factor_0</th>\n",
       "      <th>user_factor_1</th>\n",
       "      <th>user_factor_2</th>\n",
       "      <th>user_factor_3</th>\n",
       "      <th>user_factor_4</th>\n",
       "      <th>user_factor_5</th>\n",
       "      <th>user_factor_6</th>\n",
       "      <th>user_factor_7</th>\n",
       "      <th>user_factor_8</th>\n",
       "      <th>user_factor_9</th>\n",
       "      <th>user_factor_10</th>\n",
       "      <th>user_factor_11</th>\n",
       "      <th>user_factor_12</th>\n",
       "      <th>user_factor_13</th>\n",
       "      <th>user_factor_14</th>\n",
       "      <th>user_factor_15</th>\n",
       "      <th>user_factor_16</th>\n",
       "      <th>user_factor_17</th>\n",
       "      <th>user_factor_18</th>\n",
       "      <th>user_factor_19</th>\n",
       "      <th>user_factor_20</th>\n",
       "      <th>user_factor_21</th>\n",
       "      <th>user_factor_22</th>\n",
       "      <th>user_factor_23</th>\n",
       "      <th>user_factor_24</th>\n",
       "      <th>user_factor_25</th>\n",
       "      <th>user_factor_26</th>\n",
       "      <th>user_factor_27</th>\n",
       "      <th>user_factor_28</th>\n",
       "      <th>user_factor_29</th>\n",
       "      <th>user_factor_30</th>\n",
       "      <th>user_factor_31</th>\n",
       "      <th>user_factor_32</th>\n",
       "      <th>user_factor_33</th>\n",
       "      <th>user_factor_34</th>\n",
       "      <th>user_factor_35</th>\n",
       "      <th>user_factor_36</th>\n",
       "      <th>user_factor_37</th>\n",
       "      <th>user_factor_38</th>\n",
       "      <th>user_factor_39</th>\n",
       "      <th>user_factor_40</th>\n",
       "      <th>user_factor_41</th>\n",
       "      <th>user_factor_42</th>\n",
       "      <th>user_factor_43</th>\n",
       "      <th>user_factor_44</th>\n",
       "      <th>user_factor_45</th>\n",
       "      <th>user_factor_46</th>\n",
       "      <th>user_factor_47</th>\n",
       "      <th>user_factor_48</th>\n",
       "      <th>user_factor_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>282b5bda1758e147589ca517e02195c3</td>\n",
       "      <td>ec178b741b164c55ea87b4589318ef87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.049214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>0f43ef71c25d409c250f5a5042806342</td>\n",
       "      <td>3a80034f0ec74c42ed9fa7933a4e2945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>28ff0fb4b561a2fd6a360fe28f465e07</td>\n",
       "      <td>1d4bbd6a9bcb8b8349dce28ae25b1c34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>864f351e66cd3aeece5d06987fc2ed4b</td>\n",
       "      <td>5d4f76bd6de8e64bc5fd65670b4527cf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ae30377cd30f65652e52618e8b2d6</td>\n",
       "      <td>279ba64539609d30114b68874cd0fb42</td>\n",
       "      <td>0d65be97c9daa9363aa4f996facd3725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       user_id_hash                    coupon_id_hash  \\\n",
       "0  002ae30377cd30f65652e52618e8b2d6  282b5bda1758e147589ca517e02195c3   \n",
       "1  002ae30377cd30f65652e52618e8b2d6  0f43ef71c25d409c250f5a5042806342   \n",
       "2  002ae30377cd30f65652e52618e8b2d6  28ff0fb4b561a2fd6a360fe28f465e07   \n",
       "3  002ae30377cd30f65652e52618e8b2d6  864f351e66cd3aeece5d06987fc2ed4b   \n",
       "4  002ae30377cd30f65652e52618e8b2d6  279ba64539609d30114b68874cd0fb42   \n",
       "\n",
       "                     mapped_coupons  item_factor_0  item_factor_1  \\\n",
       "0  ec178b741b164c55ea87b4589318ef87            0.0            0.0   \n",
       "1  3a80034f0ec74c42ed9fa7933a4e2945            0.0            0.0   \n",
       "2  1d4bbd6a9bcb8b8349dce28ae25b1c34            0.0            0.0   \n",
       "3  5d4f76bd6de8e64bc5fd65670b4527cf            0.0            0.0   \n",
       "4  0d65be97c9daa9363aa4f996facd3725            0.0            0.0   \n",
       "\n",
       "   item_factor_2  item_factor_3  item_factor_4  item_factor_5  item_factor_6  \\\n",
       "0       0.000000       0.000471        0.00000            0.0       0.000000   \n",
       "1       0.000000       0.000000        0.00000            0.0       0.099698   \n",
       "2       0.000000       0.000000        0.01213            0.0       0.047793   \n",
       "3       0.002574       0.000000        0.09186            0.0       0.000000   \n",
       "4       0.032641       0.000000        0.00000            0.0       0.042150   \n",
       "\n",
       "   item_factor_7  item_factor_8  item_factor_9  item_factor_10  \\\n",
       "0            0.0       0.000000            0.0        0.000000   \n",
       "1            0.0       0.000000            0.0        0.160438   \n",
       "2            0.0       0.000000            0.0        0.000000   \n",
       "3            0.0       0.005344            0.0        0.010375   \n",
       "4            0.0       0.014830            0.0        0.066713   \n",
       "\n",
       "   item_factor_11  item_factor_12  item_factor_13  item_factor_14  \\\n",
       "0        0.004240        0.000000        0.001528        0.049214   \n",
       "1        0.000000        0.000000        0.000000        0.004920   \n",
       "2        0.004743        0.000000        0.000000        0.000000   \n",
       "3        0.000000        0.000000        0.000000        0.000000   \n",
       "4        0.000000        0.043134        0.000000        0.004645   \n",
       "\n",
       "   item_factor_15  item_factor_16  item_factor_17  item_factor_18  \\\n",
       "0        0.000000             0.0        0.000000             0.0   \n",
       "1        0.000000             0.0        0.030002             0.0   \n",
       "2        0.000000             0.0        0.004402             0.0   \n",
       "3        0.002895             0.0        0.045026             0.0   \n",
       "4        0.000000             0.0        0.000000             0.0   \n",
       "\n",
       "   item_factor_19  item_factor_20  item_factor_21  item_factor_22  \\\n",
       "0             0.0             0.0        0.002479             0.0   \n",
       "1             0.0             0.0        0.029892             0.0   \n",
       "2             0.0             0.0        0.034334             0.0   \n",
       "3             0.0             0.0        0.000000             0.0   \n",
       "4             0.0             0.0        0.000000             0.0   \n",
       "\n",
       "   item_factor_23  item_factor_24  item_factor_25  item_factor_26  \\\n",
       "0             0.0             0.0        0.019263             0.0   \n",
       "1             0.0             0.0        0.000000             0.0   \n",
       "2             0.0             0.0        0.001826             0.0   \n",
       "3             0.0             0.0        0.000000             0.0   \n",
       "4             0.0             0.0        0.011284             0.0   \n",
       "\n",
       "   item_factor_27  item_factor_28  item_factor_29  item_factor_30  \\\n",
       "0        0.000639             0.0        0.000000             0.0   \n",
       "1        0.000000             0.0        0.082048             0.0   \n",
       "2        0.000000             0.0        0.042891             0.0   \n",
       "3        0.019893             0.0        0.010034             0.0   \n",
       "4        0.000000             0.0        0.006607             0.0   \n",
       "\n",
       "   item_factor_31  item_factor_32  item_factor_33  item_factor_34  \\\n",
       "0        0.003750             0.0        0.000000        0.003346   \n",
       "1        0.000000             0.0        0.000000        0.000000   \n",
       "2        0.000000             0.0        0.000000        0.000000   \n",
       "3        0.016285             0.0        0.000000        0.000000   \n",
       "4        0.000000             0.0        0.217567        0.000000   \n",
       "\n",
       "   item_factor_35  item_factor_36  item_factor_37  item_factor_38  \\\n",
       "0        0.003730             0.0             0.0        0.000000   \n",
       "1        0.000000             0.0             0.0        0.009478   \n",
       "2        0.000000             0.0             0.0        0.000000   \n",
       "3        0.014651             0.0             0.0        0.000000   \n",
       "4        0.000000             0.0             0.0        0.006989   \n",
       "\n",
       "   item_factor_39  item_factor_40  item_factor_41  item_factor_42  \\\n",
       "0             0.0        0.000000             0.0        0.000403   \n",
       "1             0.0        0.016193             0.0        0.000000   \n",
       "2             0.0        0.000000             0.0        0.006935   \n",
       "3             0.0        0.000000             0.0        0.000000   \n",
       "4             0.0        0.020393             0.0        0.004030   \n",
       "\n",
       "   item_factor_43  item_factor_44  item_factor_45  item_factor_46  \\\n",
       "0        0.050700         0.00000             0.0             0.0   \n",
       "1        0.000000         0.00000             0.0             0.0   \n",
       "2        0.003588         0.00000             0.0             0.0   \n",
       "3        0.000000         0.00000             0.0             0.0   \n",
       "4        0.000000         0.00549             0.0             0.0   \n",
       "\n",
       "        ...        user_factor_0  user_factor_1  user_factor_2  user_factor_3  \\\n",
       "0       ...             0.216339            0.0       0.099827            0.0   \n",
       "1       ...             0.216339            0.0       0.099827            0.0   \n",
       "2       ...             0.216339            0.0       0.099827            0.0   \n",
       "3       ...             0.216339            0.0       0.099827            0.0   \n",
       "4       ...             0.216339            0.0       0.099827            0.0   \n",
       "\n",
       "   user_factor_4  user_factor_5  user_factor_6  user_factor_7  user_factor_8  \\\n",
       "0       0.107872            0.0        0.02954            0.0            0.0   \n",
       "1       0.107872            0.0        0.02954            0.0            0.0   \n",
       "2       0.107872            0.0        0.02954            0.0            0.0   \n",
       "3       0.107872            0.0        0.02954            0.0            0.0   \n",
       "4       0.107872            0.0        0.02954            0.0            0.0   \n",
       "\n",
       "   user_factor_9  user_factor_10  user_factor_11  user_factor_12  \\\n",
       "0            0.0        0.007376        0.025764             0.0   \n",
       "1            0.0        0.007376        0.025764             0.0   \n",
       "2            0.0        0.007376        0.025764             0.0   \n",
       "3            0.0        0.007376        0.025764             0.0   \n",
       "4            0.0        0.007376        0.025764             0.0   \n",
       "\n",
       "   user_factor_13  user_factor_14  user_factor_15  user_factor_16  \\\n",
       "0             0.0             0.0        0.000486        0.000334   \n",
       "1             0.0             0.0        0.000486        0.000334   \n",
       "2             0.0             0.0        0.000486        0.000334   \n",
       "3             0.0             0.0        0.000486        0.000334   \n",
       "4             0.0             0.0        0.000486        0.000334   \n",
       "\n",
       "   user_factor_17  user_factor_18  user_factor_19  user_factor_20  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_21  user_factor_22  user_factor_23  user_factor_24  \\\n",
       "0        0.006297             0.0             0.0             0.0   \n",
       "1        0.006297             0.0             0.0             0.0   \n",
       "2        0.006297             0.0             0.0             0.0   \n",
       "3        0.006297             0.0             0.0             0.0   \n",
       "4        0.006297             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_25  user_factor_26  user_factor_27  user_factor_28  \\\n",
       "0        0.001352        0.001981             0.0             0.0   \n",
       "1        0.001352        0.001981             0.0             0.0   \n",
       "2        0.001352        0.001981             0.0             0.0   \n",
       "3        0.001352        0.001981             0.0             0.0   \n",
       "4        0.001352        0.001981             0.0             0.0   \n",
       "\n",
       "   user_factor_29  user_factor_30  user_factor_31  user_factor_32  \\\n",
       "0        0.004619             0.0        0.010192        0.001414   \n",
       "1        0.004619             0.0        0.010192        0.001414   \n",
       "2        0.004619             0.0        0.010192        0.001414   \n",
       "3        0.004619             0.0        0.010192        0.001414   \n",
       "4        0.004619             0.0        0.010192        0.001414   \n",
       "\n",
       "   user_factor_33  user_factor_34  user_factor_35  user_factor_36  \\\n",
       "0        0.000171             0.0             0.0             0.0   \n",
       "1        0.000171             0.0             0.0             0.0   \n",
       "2        0.000171             0.0             0.0             0.0   \n",
       "3        0.000171             0.0             0.0             0.0   \n",
       "4        0.000171             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_37  user_factor_38  user_factor_39  user_factor_40  \\\n",
       "0        0.000364             0.0             0.0             0.0   \n",
       "1        0.000364             0.0             0.0             0.0   \n",
       "2        0.000364             0.0             0.0             0.0   \n",
       "3        0.000364             0.0             0.0             0.0   \n",
       "4        0.000364             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_41  user_factor_42  user_factor_43  user_factor_44  \\\n",
       "0        0.000247             0.0             0.0             0.0   \n",
       "1        0.000247             0.0             0.0             0.0   \n",
       "2        0.000247             0.0             0.0             0.0   \n",
       "3        0.000247             0.0             0.0             0.0   \n",
       "4        0.000247             0.0             0.0             0.0   \n",
       "\n",
       "   user_factor_45  user_factor_46  user_factor_47  user_factor_48  \\\n",
       "0             0.0        0.012614             0.0             0.0   \n",
       "1             0.0        0.012614             0.0             0.0   \n",
       "2             0.0        0.012614             0.0             0.0   \n",
       "3             0.0        0.012614             0.0             0.0   \n",
       "4             0.0        0.012614             0.0             0.0   \n",
       "\n",
       "   user_factor_49  \n",
       "0        0.021166  \n",
       "1        0.021166  \n",
       "2        0.021166  \n",
       "3        0.021166  \n",
       "4        0.021166  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = pd.DataFrame({'user_id_hash':list(interactions_valid_dict.keys())})\n",
    "left['key'] = 0\n",
    "right = df_coupons_valid_feat[['coupon_id_hash']]\n",
    "right['key'] = 0\n",
    "df_valid = (pd.merge(left, right, on='key', how='outer')\n",
    "    .drop('key', axis=1))\n",
    "df_valid['mapped_coupons'] = (df_valid.coupon_id_hash\n",
    "    .apply(lambda x: valid_to_train_most_similar[x]))\n",
    "df_valid = pd.merge(df_valid, df_item_factors,\n",
    "    left_on='mapped_coupons', right_on='coupon_id_hash')\n",
    "df_valid = pd.merge(df_valid, df_user_factors,\n",
    "    on='user_id_hash')\n",
    "df_valid.drop('coupon_id_hash_y', axis=1, inplace=True)\n",
    "df_valid.rename(index=str, columns={'coupon_id_hash_x': 'coupon_id_hash'}, inplace=True)\n",
    "df_preds = df_valid[['user_id_hash', 'coupon_id_hash']]\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid.iloc[:, 3:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the two matrices, `X` and `X_valid`, we have two options: keep it simple or run with full optimization. \n",
    "\n",
    "#### SIMPLE SOLUTION\n",
    "\n",
    "I will run a single fit with a large number of estimators and \"aggressive\" early stopping (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.273456\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's rmse: 0.271579\n",
      "[3]\tvalid_0's rmse: 0.269902\n",
      "[4]\tvalid_0's rmse: 0.268547\n",
      "[5]\tvalid_0's rmse: 0.267429\n",
      "[6]\tvalid_0's rmse: 0.266278\n",
      "[7]\tvalid_0's rmse: 0.265348\n",
      "[8]\tvalid_0's rmse: 0.264341\n",
      "[9]\tvalid_0's rmse: 0.263683\n",
      "[10]\tvalid_0's rmse: 0.263036\n",
      "[11]\tvalid_0's rmse: 0.262435\n",
      "[12]\tvalid_0's rmse: 0.261834\n",
      "[13]\tvalid_0's rmse: 0.261268\n",
      "[14]\tvalid_0's rmse: 0.260704\n",
      "[15]\tvalid_0's rmse: 0.260081\n",
      "[16]\tvalid_0's rmse: 0.259663\n",
      "[17]\tvalid_0's rmse: 0.259175\n",
      "[18]\tvalid_0's rmse: 0.258766\n",
      "[19]\tvalid_0's rmse: 0.258466\n",
      "[20]\tvalid_0's rmse: 0.258074\n",
      "[21]\tvalid_0's rmse: 0.257747\n",
      "[22]\tvalid_0's rmse: 0.257403\n",
      "[23]\tvalid_0's rmse: 0.256945\n",
      "[24]\tvalid_0's rmse: 0.25666\n",
      "[25]\tvalid_0's rmse: 0.256395\n",
      "[26]\tvalid_0's rmse: 0.256037\n",
      "[27]\tvalid_0's rmse: 0.255718\n",
      "[28]\tvalid_0's rmse: 0.255353\n",
      "[29]\tvalid_0's rmse: 0.255057\n",
      "[30]\tvalid_0's rmse: 0.254847\n",
      "[31]\tvalid_0's rmse: 0.254597\n",
      "[32]\tvalid_0's rmse: 0.254345\n",
      "[33]\tvalid_0's rmse: 0.254097\n",
      "[34]\tvalid_0's rmse: 0.253818\n",
      "[35]\tvalid_0's rmse: 0.253564\n",
      "[36]\tvalid_0's rmse: 0.253253\n",
      "[37]\tvalid_0's rmse: 0.252954\n",
      "[38]\tvalid_0's rmse: 0.252704\n",
      "[39]\tvalid_0's rmse: 0.252514\n",
      "[40]\tvalid_0's rmse: 0.25232\n",
      "[41]\tvalid_0's rmse: 0.252103\n",
      "[42]\tvalid_0's rmse: 0.251869\n",
      "[43]\tvalid_0's rmse: 0.251695\n",
      "[44]\tvalid_0's rmse: 0.251551\n",
      "[45]\tvalid_0's rmse: 0.25132\n",
      "[46]\tvalid_0's rmse: 0.251015\n",
      "[47]\tvalid_0's rmse: 0.250805\n",
      "[48]\tvalid_0's rmse: 0.250684\n",
      "[49]\tvalid_0's rmse: 0.250526\n",
      "[50]\tvalid_0's rmse: 0.250356\n",
      "[51]\tvalid_0's rmse: 0.250177\n",
      "[52]\tvalid_0's rmse: 0.249995\n",
      "[53]\tvalid_0's rmse: 0.249786\n",
      "[54]\tvalid_0's rmse: 0.249605\n",
      "[55]\tvalid_0's rmse: 0.249384\n",
      "[56]\tvalid_0's rmse: 0.249208\n",
      "[57]\tvalid_0's rmse: 0.249024\n",
      "[58]\tvalid_0's rmse: 0.248878\n",
      "[59]\tvalid_0's rmse: 0.24869\n",
      "[60]\tvalid_0's rmse: 0.24852\n",
      "[61]\tvalid_0's rmse: 0.248327\n",
      "[62]\tvalid_0's rmse: 0.248188\n",
      "[63]\tvalid_0's rmse: 0.248056\n",
      "[64]\tvalid_0's rmse: 0.247845\n",
      "[65]\tvalid_0's rmse: 0.247693\n",
      "[66]\tvalid_0's rmse: 0.247549\n",
      "[67]\tvalid_0's rmse: 0.247395\n",
      "[68]\tvalid_0's rmse: 0.247254\n",
      "[69]\tvalid_0's rmse: 0.247123\n",
      "[70]\tvalid_0's rmse: 0.246967\n",
      "[71]\tvalid_0's rmse: 0.246856\n",
      "[72]\tvalid_0's rmse: 0.246742\n",
      "[73]\tvalid_0's rmse: 0.246597\n",
      "[74]\tvalid_0's rmse: 0.246472\n",
      "[75]\tvalid_0's rmse: 0.246372\n",
      "[76]\tvalid_0's rmse: 0.246252\n",
      "[77]\tvalid_0's rmse: 0.246144\n",
      "[78]\tvalid_0's rmse: 0.246019\n",
      "[79]\tvalid_0's rmse: 0.245882\n",
      "[80]\tvalid_0's rmse: 0.245782\n",
      "[81]\tvalid_0's rmse: 0.245655\n",
      "[82]\tvalid_0's rmse: 0.245557\n",
      "[83]\tvalid_0's rmse: 0.24541\n",
      "[84]\tvalid_0's rmse: 0.245256\n",
      "[85]\tvalid_0's rmse: 0.245145\n",
      "[86]\tvalid_0's rmse: 0.245067\n",
      "[87]\tvalid_0's rmse: 0.244957\n",
      "[88]\tvalid_0's rmse: 0.244846\n",
      "[89]\tvalid_0's rmse: 0.244754\n",
      "[90]\tvalid_0's rmse: 0.244634\n",
      "[91]\tvalid_0's rmse: 0.244535\n",
      "[92]\tvalid_0's rmse: 0.244421\n",
      "[93]\tvalid_0's rmse: 0.244298\n",
      "[94]\tvalid_0's rmse: 0.2442\n",
      "[95]\tvalid_0's rmse: 0.244086\n",
      "[96]\tvalid_0's rmse: 0.243956\n",
      "[97]\tvalid_0's rmse: 0.243792\n",
      "[98]\tvalid_0's rmse: 0.243713\n",
      "[99]\tvalid_0's rmse: 0.243611\n",
      "[100]\tvalid_0's rmse: 0.243516\n",
      "[101]\tvalid_0's rmse: 0.243423\n",
      "[102]\tvalid_0's rmse: 0.243337\n",
      "[103]\tvalid_0's rmse: 0.243236\n",
      "[104]\tvalid_0's rmse: 0.243151\n",
      "[105]\tvalid_0's rmse: 0.243067\n",
      "[106]\tvalid_0's rmse: 0.242938\n",
      "[107]\tvalid_0's rmse: 0.242871\n",
      "[108]\tvalid_0's rmse: 0.242753\n",
      "[109]\tvalid_0's rmse: 0.242628\n",
      "[110]\tvalid_0's rmse: 0.24253\n",
      "[111]\tvalid_0's rmse: 0.242425\n",
      "[112]\tvalid_0's rmse: 0.242343\n",
      "[113]\tvalid_0's rmse: 0.242237\n",
      "[114]\tvalid_0's rmse: 0.242145\n",
      "[115]\tvalid_0's rmse: 0.242077\n",
      "[116]\tvalid_0's rmse: 0.241988\n",
      "[117]\tvalid_0's rmse: 0.241936\n",
      "[118]\tvalid_0's rmse: 0.241835\n",
      "[119]\tvalid_0's rmse: 0.241771\n",
      "[120]\tvalid_0's rmse: 0.241689\n",
      "[121]\tvalid_0's rmse: 0.241594\n",
      "[122]\tvalid_0's rmse: 0.241512\n",
      "[123]\tvalid_0's rmse: 0.241416\n",
      "[124]\tvalid_0's rmse: 0.241331\n",
      "[125]\tvalid_0's rmse: 0.241261\n",
      "[126]\tvalid_0's rmse: 0.241191\n",
      "[127]\tvalid_0's rmse: 0.241097\n",
      "[128]\tvalid_0's rmse: 0.24101\n",
      "[129]\tvalid_0's rmse: 0.240924\n",
      "[130]\tvalid_0's rmse: 0.240862\n",
      "[131]\tvalid_0's rmse: 0.240771\n",
      "[132]\tvalid_0's rmse: 0.24072\n",
      "[133]\tvalid_0's rmse: 0.24064\n",
      "[134]\tvalid_0's rmse: 0.240575\n",
      "[135]\tvalid_0's rmse: 0.24051\n",
      "[136]\tvalid_0's rmse: 0.240442\n",
      "[137]\tvalid_0's rmse: 0.240378\n",
      "[138]\tvalid_0's rmse: 0.240287\n",
      "[139]\tvalid_0's rmse: 0.240206\n",
      "[140]\tvalid_0's rmse: 0.240157\n",
      "[141]\tvalid_0's rmse: 0.24009\n",
      "[142]\tvalid_0's rmse: 0.240002\n",
      "[143]\tvalid_0's rmse: 0.239933\n",
      "[144]\tvalid_0's rmse: 0.239889\n",
      "[145]\tvalid_0's rmse: 0.239802\n",
      "[146]\tvalid_0's rmse: 0.239723\n",
      "[147]\tvalid_0's rmse: 0.239672\n",
      "[148]\tvalid_0's rmse: 0.239616\n",
      "[149]\tvalid_0's rmse: 0.239551\n",
      "[150]\tvalid_0's rmse: 0.239508\n",
      "[151]\tvalid_0's rmse: 0.239454\n",
      "[152]\tvalid_0's rmse: 0.2394\n",
      "[153]\tvalid_0's rmse: 0.239346\n",
      "[154]\tvalid_0's rmse: 0.239281\n",
      "[155]\tvalid_0's rmse: 0.239231\n",
      "[156]\tvalid_0's rmse: 0.239167\n",
      "[157]\tvalid_0's rmse: 0.239112\n",
      "[158]\tvalid_0's rmse: 0.239063\n",
      "[159]\tvalid_0's rmse: 0.238998\n",
      "[160]\tvalid_0's rmse: 0.238943\n",
      "[161]\tvalid_0's rmse: 0.238905\n",
      "[162]\tvalid_0's rmse: 0.238872\n",
      "[163]\tvalid_0's rmse: 0.238827\n",
      "[164]\tvalid_0's rmse: 0.238791\n",
      "[165]\tvalid_0's rmse: 0.238761\n",
      "[166]\tvalid_0's rmse: 0.238706\n",
      "[167]\tvalid_0's rmse: 0.238655\n",
      "[168]\tvalid_0's rmse: 0.238604\n",
      "[169]\tvalid_0's rmse: 0.238524\n",
      "[170]\tvalid_0's rmse: 0.238467\n",
      "[171]\tvalid_0's rmse: 0.2384\n",
      "[172]\tvalid_0's rmse: 0.238331\n",
      "[173]\tvalid_0's rmse: 0.238271\n",
      "[174]\tvalid_0's rmse: 0.238199\n",
      "[175]\tvalid_0's rmse: 0.238164\n",
      "[176]\tvalid_0's rmse: 0.238127\n",
      "[177]\tvalid_0's rmse: 0.238077\n",
      "[178]\tvalid_0's rmse: 0.238022\n",
      "[179]\tvalid_0's rmse: 0.237985\n",
      "[180]\tvalid_0's rmse: 0.237953\n",
      "[181]\tvalid_0's rmse: 0.237902\n",
      "[182]\tvalid_0's rmse: 0.237853\n",
      "[183]\tvalid_0's rmse: 0.237819\n",
      "[184]\tvalid_0's rmse: 0.237763\n",
      "[185]\tvalid_0's rmse: 0.23769\n",
      "[186]\tvalid_0's rmse: 0.237659\n",
      "[187]\tvalid_0's rmse: 0.237619\n",
      "[188]\tvalid_0's rmse: 0.237573\n",
      "[189]\tvalid_0's rmse: 0.237527\n",
      "[190]\tvalid_0's rmse: 0.237488\n",
      "[191]\tvalid_0's rmse: 0.237468\n",
      "[192]\tvalid_0's rmse: 0.237407\n",
      "[193]\tvalid_0's rmse: 0.237378\n",
      "[194]\tvalid_0's rmse: 0.237327\n",
      "[195]\tvalid_0's rmse: 0.237291\n",
      "[196]\tvalid_0's rmse: 0.237241\n",
      "[197]\tvalid_0's rmse: 0.237186\n",
      "[198]\tvalid_0's rmse: 0.237163\n",
      "[199]\tvalid_0's rmse: 0.237116\n",
      "[200]\tvalid_0's rmse: 0.237086\n",
      "[201]\tvalid_0's rmse: 0.237049\n",
      "[202]\tvalid_0's rmse: 0.236991\n",
      "[203]\tvalid_0's rmse: 0.236963\n",
      "[204]\tvalid_0's rmse: 0.236921\n",
      "[205]\tvalid_0's rmse: 0.236892\n",
      "[206]\tvalid_0's rmse: 0.236854\n",
      "[207]\tvalid_0's rmse: 0.236824\n",
      "[208]\tvalid_0's rmse: 0.236791\n",
      "[209]\tvalid_0's rmse: 0.236722\n",
      "[210]\tvalid_0's rmse: 0.236656\n",
      "[211]\tvalid_0's rmse: 0.236632\n",
      "[212]\tvalid_0's rmse: 0.236553\n",
      "[213]\tvalid_0's rmse: 0.236526\n",
      "[214]\tvalid_0's rmse: 0.236502\n",
      "[215]\tvalid_0's rmse: 0.236463\n",
      "[216]\tvalid_0's rmse: 0.236426\n",
      "[217]\tvalid_0's rmse: 0.236379\n",
      "[218]\tvalid_0's rmse: 0.236339\n",
      "[219]\tvalid_0's rmse: 0.236285\n",
      "[220]\tvalid_0's rmse: 0.236245\n",
      "[221]\tvalid_0's rmse: 0.236161\n",
      "[222]\tvalid_0's rmse: 0.236139\n",
      "[223]\tvalid_0's rmse: 0.236109\n",
      "[224]\tvalid_0's rmse: 0.236084\n",
      "[225]\tvalid_0's rmse: 0.236033\n",
      "[226]\tvalid_0's rmse: 0.235998\n",
      "[227]\tvalid_0's rmse: 0.235973\n",
      "[228]\tvalid_0's rmse: 0.235926\n",
      "[229]\tvalid_0's rmse: 0.235886\n",
      "[230]\tvalid_0's rmse: 0.235864\n",
      "[231]\tvalid_0's rmse: 0.235838\n",
      "[232]\tvalid_0's rmse: 0.235797\n",
      "[233]\tvalid_0's rmse: 0.235776\n",
      "[234]\tvalid_0's rmse: 0.235745\n",
      "[235]\tvalid_0's rmse: 0.235711\n",
      "[236]\tvalid_0's rmse: 0.235686\n",
      "[237]\tvalid_0's rmse: 0.235636\n",
      "[238]\tvalid_0's rmse: 0.235603\n",
      "[239]\tvalid_0's rmse: 0.235547\n",
      "[240]\tvalid_0's rmse: 0.235525\n",
      "[241]\tvalid_0's rmse: 0.235495\n",
      "[242]\tvalid_0's rmse: 0.235481\n",
      "[243]\tvalid_0's rmse: 0.235458\n",
      "[244]\tvalid_0's rmse: 0.235429\n",
      "[245]\tvalid_0's rmse: 0.235376\n",
      "[246]\tvalid_0's rmse: 0.235338\n",
      "[247]\tvalid_0's rmse: 0.235306\n",
      "[248]\tvalid_0's rmse: 0.235284\n",
      "[249]\tvalid_0's rmse: 0.235237\n",
      "[250]\tvalid_0's rmse: 0.235206\n",
      "[251]\tvalid_0's rmse: 0.235176\n",
      "[252]\tvalid_0's rmse: 0.235146\n",
      "[253]\tvalid_0's rmse: 0.235128\n",
      "[254]\tvalid_0's rmse: 0.235073\n",
      "[255]\tvalid_0's rmse: 0.235051\n",
      "[256]\tvalid_0's rmse: 0.235013\n",
      "[257]\tvalid_0's rmse: 0.234964\n",
      "[258]\tvalid_0's rmse: 0.234918\n",
      "[259]\tvalid_0's rmse: 0.234872\n",
      "[260]\tvalid_0's rmse: 0.234826\n",
      "[261]\tvalid_0's rmse: 0.234795\n",
      "[262]\tvalid_0's rmse: 0.234778\n",
      "[263]\tvalid_0's rmse: 0.234754\n",
      "[264]\tvalid_0's rmse: 0.234727\n",
      "[265]\tvalid_0's rmse: 0.234703\n",
      "[266]\tvalid_0's rmse: 0.234684\n",
      "[267]\tvalid_0's rmse: 0.23467\n",
      "[268]\tvalid_0's rmse: 0.234615\n",
      "[269]\tvalid_0's rmse: 0.234577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[270]\tvalid_0's rmse: 0.234532\n",
      "[271]\tvalid_0's rmse: 0.234513\n",
      "[272]\tvalid_0's rmse: 0.234476\n",
      "[273]\tvalid_0's rmse: 0.234443\n",
      "[274]\tvalid_0's rmse: 0.234418\n",
      "[275]\tvalid_0's rmse: 0.234404\n",
      "[276]\tvalid_0's rmse: 0.23439\n",
      "[277]\tvalid_0's rmse: 0.234348\n",
      "[278]\tvalid_0's rmse: 0.234313\n",
      "[279]\tvalid_0's rmse: 0.234295\n",
      "[280]\tvalid_0's rmse: 0.234277\n",
      "[281]\tvalid_0's rmse: 0.234236\n",
      "[282]\tvalid_0's rmse: 0.234216\n",
      "[283]\tvalid_0's rmse: 0.234186\n",
      "[284]\tvalid_0's rmse: 0.234171\n",
      "[285]\tvalid_0's rmse: 0.23412\n",
      "[286]\tvalid_0's rmse: 0.234092\n",
      "[287]\tvalid_0's rmse: 0.234078\n",
      "[288]\tvalid_0's rmse: 0.234034\n",
      "[289]\tvalid_0's rmse: 0.233992\n",
      "[290]\tvalid_0's rmse: 0.233961\n",
      "[291]\tvalid_0's rmse: 0.23394\n",
      "[292]\tvalid_0's rmse: 0.233919\n",
      "[293]\tvalid_0's rmse: 0.233862\n",
      "[294]\tvalid_0's rmse: 0.233826\n",
      "[295]\tvalid_0's rmse: 0.23378\n",
      "[296]\tvalid_0's rmse: 0.233763\n",
      "[297]\tvalid_0's rmse: 0.233756\n",
      "[298]\tvalid_0's rmse: 0.233737\n",
      "[299]\tvalid_0's rmse: 0.23371\n",
      "[300]\tvalid_0's rmse: 0.233697\n",
      "[301]\tvalid_0's rmse: 0.233684\n",
      "[302]\tvalid_0's rmse: 0.233669\n",
      "[303]\tvalid_0's rmse: 0.233656\n",
      "[304]\tvalid_0's rmse: 0.233645\n",
      "[305]\tvalid_0's rmse: 0.233633\n",
      "[306]\tvalid_0's rmse: 0.23362\n",
      "[307]\tvalid_0's rmse: 0.233598\n",
      "[308]\tvalid_0's rmse: 0.23356\n",
      "[309]\tvalid_0's rmse: 0.233528\n",
      "[310]\tvalid_0's rmse: 0.233514\n",
      "[311]\tvalid_0's rmse: 0.233481\n",
      "[312]\tvalid_0's rmse: 0.233445\n",
      "[313]\tvalid_0's rmse: 0.233431\n",
      "[314]\tvalid_0's rmse: 0.233403\n",
      "[315]\tvalid_0's rmse: 0.23338\n",
      "[316]\tvalid_0's rmse: 0.233371\n",
      "[317]\tvalid_0's rmse: 0.233342\n",
      "[318]\tvalid_0's rmse: 0.233324\n",
      "[319]\tvalid_0's rmse: 0.233304\n",
      "[320]\tvalid_0's rmse: 0.233295\n",
      "[321]\tvalid_0's rmse: 0.233282\n",
      "[322]\tvalid_0's rmse: 0.233246\n",
      "[323]\tvalid_0's rmse: 0.23319\n",
      "[324]\tvalid_0's rmse: 0.233152\n",
      "[325]\tvalid_0's rmse: 0.233133\n",
      "[326]\tvalid_0's rmse: 0.233109\n",
      "[327]\tvalid_0's rmse: 0.233069\n",
      "[328]\tvalid_0's rmse: 0.233047\n",
      "[329]\tvalid_0's rmse: 0.233022\n",
      "[330]\tvalid_0's rmse: 0.233012\n",
      "[331]\tvalid_0's rmse: 0.233002\n",
      "[332]\tvalid_0's rmse: 0.232981\n",
      "[333]\tvalid_0's rmse: 0.232961\n",
      "[334]\tvalid_0's rmse: 0.232941\n",
      "[335]\tvalid_0's rmse: 0.232914\n",
      "[336]\tvalid_0's rmse: 0.232845\n",
      "[337]\tvalid_0's rmse: 0.232836\n",
      "[338]\tvalid_0's rmse: 0.232804\n",
      "[339]\tvalid_0's rmse: 0.232794\n",
      "[340]\tvalid_0's rmse: 0.232781\n",
      "[341]\tvalid_0's rmse: 0.232769\n",
      "[342]\tvalid_0's rmse: 0.23276\n",
      "[343]\tvalid_0's rmse: 0.232749\n",
      "[344]\tvalid_0's rmse: 0.232734\n",
      "[345]\tvalid_0's rmse: 0.232685\n",
      "[346]\tvalid_0's rmse: 0.232664\n",
      "[347]\tvalid_0's rmse: 0.232645\n",
      "[348]\tvalid_0's rmse: 0.232623\n",
      "[349]\tvalid_0's rmse: 0.23261\n",
      "[350]\tvalid_0's rmse: 0.232591\n",
      "[351]\tvalid_0's rmse: 0.232567\n",
      "[352]\tvalid_0's rmse: 0.232556\n",
      "[353]\tvalid_0's rmse: 0.232544\n",
      "[354]\tvalid_0's rmse: 0.232504\n",
      "[355]\tvalid_0's rmse: 0.232469\n",
      "[356]\tvalid_0's rmse: 0.23241\n",
      "[357]\tvalid_0's rmse: 0.232383\n",
      "[358]\tvalid_0's rmse: 0.232363\n",
      "[359]\tvalid_0's rmse: 0.232325\n",
      "[360]\tvalid_0's rmse: 0.232271\n",
      "[361]\tvalid_0's rmse: 0.23224\n",
      "[362]\tvalid_0's rmse: 0.23222\n",
      "[363]\tvalid_0's rmse: 0.23217\n",
      "[364]\tvalid_0's rmse: 0.232149\n",
      "[365]\tvalid_0's rmse: 0.232095\n",
      "[366]\tvalid_0's rmse: 0.232069\n",
      "[367]\tvalid_0's rmse: 0.232036\n",
      "[368]\tvalid_0's rmse: 0.232016\n",
      "[369]\tvalid_0's rmse: 0.231993\n",
      "[370]\tvalid_0's rmse: 0.231975\n",
      "[371]\tvalid_0's rmse: 0.231971\n",
      "[372]\tvalid_0's rmse: 0.231948\n",
      "[373]\tvalid_0's rmse: 0.231936\n",
      "[374]\tvalid_0's rmse: 0.231914\n",
      "[375]\tvalid_0's rmse: 0.231865\n",
      "[376]\tvalid_0's rmse: 0.231846\n",
      "[377]\tvalid_0's rmse: 0.231828\n",
      "[378]\tvalid_0's rmse: 0.231816\n",
      "[379]\tvalid_0's rmse: 0.231804\n",
      "[380]\tvalid_0's rmse: 0.231778\n",
      "[381]\tvalid_0's rmse: 0.231761\n",
      "[382]\tvalid_0's rmse: 0.231739\n",
      "[383]\tvalid_0's rmse: 0.231731\n",
      "[384]\tvalid_0's rmse: 0.231721\n",
      "[385]\tvalid_0's rmse: 0.23169\n",
      "[386]\tvalid_0's rmse: 0.231677\n",
      "[387]\tvalid_0's rmse: 0.231637\n",
      "[388]\tvalid_0's rmse: 0.231626\n",
      "[389]\tvalid_0's rmse: 0.231595\n",
      "[390]\tvalid_0's rmse: 0.231546\n",
      "[391]\tvalid_0's rmse: 0.231496\n",
      "[392]\tvalid_0's rmse: 0.231466\n",
      "[393]\tvalid_0's rmse: 0.231457\n",
      "[394]\tvalid_0's rmse: 0.23145\n",
      "[395]\tvalid_0's rmse: 0.231436\n",
      "[396]\tvalid_0's rmse: 0.231404\n",
      "[397]\tvalid_0's rmse: 0.231383\n",
      "[398]\tvalid_0's rmse: 0.231375\n",
      "[399]\tvalid_0's rmse: 0.23137\n",
      "[400]\tvalid_0's rmse: 0.231354\n",
      "[401]\tvalid_0's rmse: 0.23135\n",
      "[402]\tvalid_0's rmse: 0.231305\n",
      "[403]\tvalid_0's rmse: 0.231274\n",
      "[404]\tvalid_0's rmse: 0.231268\n",
      "[405]\tvalid_0's rmse: 0.23125\n",
      "[406]\tvalid_0's rmse: 0.231238\n",
      "[407]\tvalid_0's rmse: 0.231212\n",
      "[408]\tvalid_0's rmse: 0.231186\n",
      "[409]\tvalid_0's rmse: 0.231148\n",
      "[410]\tvalid_0's rmse: 0.231126\n",
      "[411]\tvalid_0's rmse: 0.231117\n",
      "[412]\tvalid_0's rmse: 0.231099\n",
      "[413]\tvalid_0's rmse: 0.231087\n",
      "[414]\tvalid_0's rmse: 0.231069\n",
      "[415]\tvalid_0's rmse: 0.23103\n",
      "[416]\tvalid_0's rmse: 0.231008\n",
      "[417]\tvalid_0's rmse: 0.230986\n",
      "[418]\tvalid_0's rmse: 0.230976\n",
      "[419]\tvalid_0's rmse: 0.230964\n",
      "[420]\tvalid_0's rmse: 0.230956\n",
      "[421]\tvalid_0's rmse: 0.230949\n",
      "[422]\tvalid_0's rmse: 0.230937\n",
      "[423]\tvalid_0's rmse: 0.230933\n",
      "[424]\tvalid_0's rmse: 0.230922\n",
      "[425]\tvalid_0's rmse: 0.230917\n",
      "[426]\tvalid_0's rmse: 0.230906\n",
      "[427]\tvalid_0's rmse: 0.230899\n",
      "[428]\tvalid_0's rmse: 0.23089\n",
      "[429]\tvalid_0's rmse: 0.230868\n",
      "[430]\tvalid_0's rmse: 0.230841\n",
      "[431]\tvalid_0's rmse: 0.230829\n",
      "[432]\tvalid_0's rmse: 0.230792\n",
      "[433]\tvalid_0's rmse: 0.230777\n",
      "[434]\tvalid_0's rmse: 0.230749\n",
      "[435]\tvalid_0's rmse: 0.230732\n",
      "[436]\tvalid_0's rmse: 0.230716\n",
      "[437]\tvalid_0's rmse: 0.230712\n",
      "[438]\tvalid_0's rmse: 0.23069\n",
      "[439]\tvalid_0's rmse: 0.230669\n",
      "[440]\tvalid_0's rmse: 0.23066\n",
      "[441]\tvalid_0's rmse: 0.230649\n",
      "[442]\tvalid_0's rmse: 0.230646\n",
      "[443]\tvalid_0's rmse: 0.230639\n",
      "[444]\tvalid_0's rmse: 0.230609\n",
      "[445]\tvalid_0's rmse: 0.230595\n",
      "[446]\tvalid_0's rmse: 0.230567\n",
      "[447]\tvalid_0's rmse: 0.230566\n",
      "[448]\tvalid_0's rmse: 0.230556\n",
      "[449]\tvalid_0's rmse: 0.230536\n",
      "[450]\tvalid_0's rmse: 0.230509\n",
      "[451]\tvalid_0's rmse: 0.230479\n",
      "[452]\tvalid_0's rmse: 0.230471\n",
      "[453]\tvalid_0's rmse: 0.230459\n",
      "[454]\tvalid_0's rmse: 0.230448\n",
      "[455]\tvalid_0's rmse: 0.230444\n",
      "[456]\tvalid_0's rmse: 0.230401\n",
      "[457]\tvalid_0's rmse: 0.230369\n",
      "[458]\tvalid_0's rmse: 0.230339\n",
      "[459]\tvalid_0's rmse: 0.230321\n",
      "[460]\tvalid_0's rmse: 0.230305\n",
      "[461]\tvalid_0's rmse: 0.230288\n",
      "[462]\tvalid_0's rmse: 0.230263\n",
      "[463]\tvalid_0's rmse: 0.230248\n",
      "[464]\tvalid_0's rmse: 0.230245\n",
      "[465]\tvalid_0's rmse: 0.230239\n",
      "[466]\tvalid_0's rmse: 0.230228\n",
      "[467]\tvalid_0's rmse: 0.230219\n",
      "[468]\tvalid_0's rmse: 0.230199\n",
      "[469]\tvalid_0's rmse: 0.230197\n",
      "[470]\tvalid_0's rmse: 0.230179\n",
      "[471]\tvalid_0's rmse: 0.230164\n",
      "[472]\tvalid_0's rmse: 0.230145\n",
      "[473]\tvalid_0's rmse: 0.230129\n",
      "[474]\tvalid_0's rmse: 0.23008\n",
      "[475]\tvalid_0's rmse: 0.230074\n",
      "[476]\tvalid_0's rmse: 0.230043\n",
      "[477]\tvalid_0's rmse: 0.230033\n",
      "[478]\tvalid_0's rmse: 0.230015\n",
      "[479]\tvalid_0's rmse: 0.229981\n",
      "[480]\tvalid_0's rmse: 0.229944\n",
      "[481]\tvalid_0's rmse: 0.229921\n",
      "[482]\tvalid_0's rmse: 0.229908\n",
      "[483]\tvalid_0's rmse: 0.229885\n",
      "[484]\tvalid_0's rmse: 0.229877\n",
      "[485]\tvalid_0's rmse: 0.229862\n",
      "[486]\tvalid_0's rmse: 0.229848\n",
      "[487]\tvalid_0's rmse: 0.229829\n",
      "[488]\tvalid_0's rmse: 0.229813\n",
      "[489]\tvalid_0's rmse: 0.229808\n",
      "[490]\tvalid_0's rmse: 0.229799\n",
      "[491]\tvalid_0's rmse: 0.229787\n",
      "[492]\tvalid_0's rmse: 0.229785\n",
      "[493]\tvalid_0's rmse: 0.229748\n",
      "[494]\tvalid_0's rmse: 0.229738\n",
      "[495]\tvalid_0's rmse: 0.229703\n",
      "[496]\tvalid_0's rmse: 0.229673\n",
      "[497]\tvalid_0's rmse: 0.229658\n",
      "[498]\tvalid_0's rmse: 0.229623\n",
      "[499]\tvalid_0's rmse: 0.2296\n",
      "[500]\tvalid_0's rmse: 0.229585\n",
      "[501]\tvalid_0's rmse: 0.229565\n",
      "[502]\tvalid_0's rmse: 0.229546\n",
      "[503]\tvalid_0's rmse: 0.229522\n",
      "[504]\tvalid_0's rmse: 0.229508\n",
      "[505]\tvalid_0's rmse: 0.229496\n",
      "[506]\tvalid_0's rmse: 0.229486\n",
      "[507]\tvalid_0's rmse: 0.229479\n",
      "[508]\tvalid_0's rmse: 0.229442\n",
      "[509]\tvalid_0's rmse: 0.229407\n",
      "[510]\tvalid_0's rmse: 0.229401\n",
      "[511]\tvalid_0's rmse: 0.229385\n",
      "[512]\tvalid_0's rmse: 0.229379\n",
      "[513]\tvalid_0's rmse: 0.229372\n",
      "[514]\tvalid_0's rmse: 0.229366\n",
      "[515]\tvalid_0's rmse: 0.229341\n",
      "[516]\tvalid_0's rmse: 0.229328\n",
      "[517]\tvalid_0's rmse: 0.229314\n",
      "[518]\tvalid_0's rmse: 0.229299\n",
      "[519]\tvalid_0's rmse: 0.229294\n",
      "[520]\tvalid_0's rmse: 0.229271\n",
      "[521]\tvalid_0's rmse: 0.229259\n",
      "[522]\tvalid_0's rmse: 0.229249\n",
      "[523]\tvalid_0's rmse: 0.229244\n",
      "[524]\tvalid_0's rmse: 0.229242\n",
      "[525]\tvalid_0's rmse: 0.229223\n",
      "[526]\tvalid_0's rmse: 0.229198\n",
      "[527]\tvalid_0's rmse: 0.229163\n",
      "[528]\tvalid_0's rmse: 0.229132\n",
      "[529]\tvalid_0's rmse: 0.229103\n",
      "[530]\tvalid_0's rmse: 0.229086\n",
      "[531]\tvalid_0's rmse: 0.229072\n",
      "[532]\tvalid_0's rmse: 0.229052\n",
      "[533]\tvalid_0's rmse: 0.229027\n",
      "[534]\tvalid_0's rmse: 0.229024\n",
      "[535]\tvalid_0's rmse: 0.229009\n",
      "[536]\tvalid_0's rmse: 0.229003\n",
      "[537]\tvalid_0's rmse: 0.228998\n",
      "[538]\tvalid_0's rmse: 0.228995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[539]\tvalid_0's rmse: 0.228987\n",
      "[540]\tvalid_0's rmse: 0.228953\n",
      "[541]\tvalid_0's rmse: 0.228936\n",
      "[542]\tvalid_0's rmse: 0.228931\n",
      "[543]\tvalid_0's rmse: 0.228908\n",
      "[544]\tvalid_0's rmse: 0.228903\n",
      "[545]\tvalid_0's rmse: 0.228892\n",
      "[546]\tvalid_0's rmse: 0.228873\n",
      "[547]\tvalid_0's rmse: 0.228861\n",
      "[548]\tvalid_0's rmse: 0.228855\n",
      "[549]\tvalid_0's rmse: 0.228847\n",
      "[550]\tvalid_0's rmse: 0.228833\n",
      "[551]\tvalid_0's rmse: 0.228824\n",
      "[552]\tvalid_0's rmse: 0.228817\n",
      "[553]\tvalid_0's rmse: 0.22879\n",
      "[554]\tvalid_0's rmse: 0.228754\n",
      "[555]\tvalid_0's rmse: 0.228743\n",
      "[556]\tvalid_0's rmse: 0.228706\n",
      "[557]\tvalid_0's rmse: 0.228691\n",
      "[558]\tvalid_0's rmse: 0.228672\n",
      "[559]\tvalid_0's rmse: 0.228644\n",
      "[560]\tvalid_0's rmse: 0.228629\n",
      "[561]\tvalid_0's rmse: 0.228624\n",
      "[562]\tvalid_0's rmse: 0.228622\n",
      "[563]\tvalid_0's rmse: 0.228616\n",
      "[564]\tvalid_0's rmse: 0.228612\n",
      "[565]\tvalid_0's rmse: 0.228578\n",
      "[566]\tvalid_0's rmse: 0.228547\n",
      "[567]\tvalid_0's rmse: 0.228537\n",
      "[568]\tvalid_0's rmse: 0.228518\n",
      "[569]\tvalid_0's rmse: 0.228505\n",
      "[570]\tvalid_0's rmse: 0.228491\n",
      "[571]\tvalid_0's rmse: 0.228476\n",
      "[572]\tvalid_0's rmse: 0.228472\n",
      "[573]\tvalid_0's rmse: 0.22845\n",
      "[574]\tvalid_0's rmse: 0.228435\n",
      "[575]\tvalid_0's rmse: 0.228412\n",
      "[576]\tvalid_0's rmse: 0.228406\n",
      "[577]\tvalid_0's rmse: 0.228385\n",
      "[578]\tvalid_0's rmse: 0.22837\n",
      "[579]\tvalid_0's rmse: 0.228349\n",
      "[580]\tvalid_0's rmse: 0.228343\n",
      "[581]\tvalid_0's rmse: 0.228336\n",
      "[582]\tvalid_0's rmse: 0.228306\n",
      "[583]\tvalid_0's rmse: 0.228286\n",
      "[584]\tvalid_0's rmse: 0.228277\n",
      "[585]\tvalid_0's rmse: 0.228268\n",
      "[586]\tvalid_0's rmse: 0.228261\n",
      "[587]\tvalid_0's rmse: 0.22826\n",
      "[588]\tvalid_0's rmse: 0.228251\n",
      "[589]\tvalid_0's rmse: 0.22824\n",
      "[590]\tvalid_0's rmse: 0.228229\n",
      "[591]\tvalid_0's rmse: 0.228221\n",
      "[592]\tvalid_0's rmse: 0.228213\n",
      "[593]\tvalid_0's rmse: 0.228189\n",
      "[594]\tvalid_0's rmse: 0.228186\n",
      "[595]\tvalid_0's rmse: 0.22817\n",
      "[596]\tvalid_0's rmse: 0.228168\n",
      "[597]\tvalid_0's rmse: 0.228165\n",
      "[598]\tvalid_0's rmse: 0.22815\n",
      "[599]\tvalid_0's rmse: 0.228145\n",
      "[600]\tvalid_0's rmse: 0.228124\n",
      "[601]\tvalid_0's rmse: 0.228108\n",
      "[602]\tvalid_0's rmse: 0.228105\n",
      "[603]\tvalid_0's rmse: 0.228061\n",
      "[604]\tvalid_0's rmse: 0.22805\n",
      "[605]\tvalid_0's rmse: 0.228046\n",
      "[606]\tvalid_0's rmse: 0.228045\n",
      "[607]\tvalid_0's rmse: 0.228028\n",
      "[608]\tvalid_0's rmse: 0.228006\n",
      "[609]\tvalid_0's rmse: 0.227995\n",
      "[610]\tvalid_0's rmse: 0.227992\n",
      "[611]\tvalid_0's rmse: 0.227985\n",
      "[612]\tvalid_0's rmse: 0.227981\n",
      "[613]\tvalid_0's rmse: 0.227973\n",
      "[614]\tvalid_0's rmse: 0.227962\n",
      "[615]\tvalid_0's rmse: 0.227943\n",
      "[616]\tvalid_0's rmse: 0.227927\n",
      "[617]\tvalid_0's rmse: 0.227919\n",
      "[618]\tvalid_0's rmse: 0.2279\n",
      "[619]\tvalid_0's rmse: 0.227899\n",
      "[620]\tvalid_0's rmse: 0.227897\n",
      "[621]\tvalid_0's rmse: 0.227884\n",
      "[622]\tvalid_0's rmse: 0.227876\n",
      "[623]\tvalid_0's rmse: 0.227841\n",
      "[624]\tvalid_0's rmse: 0.227834\n",
      "[625]\tvalid_0's rmse: 0.227819\n",
      "[626]\tvalid_0's rmse: 0.227803\n",
      "[627]\tvalid_0's rmse: 0.227787\n",
      "[628]\tvalid_0's rmse: 0.227771\n",
      "[629]\tvalid_0's rmse: 0.227752\n",
      "[630]\tvalid_0's rmse: 0.227745\n",
      "[631]\tvalid_0's rmse: 0.227729\n",
      "[632]\tvalid_0's rmse: 0.227714\n",
      "[633]\tvalid_0's rmse: 0.227691\n",
      "[634]\tvalid_0's rmse: 0.227661\n",
      "[635]\tvalid_0's rmse: 0.227641\n",
      "[636]\tvalid_0's rmse: 0.227631\n",
      "[637]\tvalid_0's rmse: 0.227623\n",
      "[638]\tvalid_0's rmse: 0.227607\n",
      "[639]\tvalid_0's rmse: 0.227607\n",
      "[640]\tvalid_0's rmse: 0.22759\n",
      "[641]\tvalid_0's rmse: 0.22758\n",
      "[642]\tvalid_0's rmse: 0.227576\n",
      "[643]\tvalid_0's rmse: 0.227559\n",
      "[644]\tvalid_0's rmse: 0.227524\n",
      "[645]\tvalid_0's rmse: 0.227508\n",
      "[646]\tvalid_0's rmse: 0.227502\n",
      "[647]\tvalid_0's rmse: 0.227491\n",
      "[648]\tvalid_0's rmse: 0.227474\n",
      "[649]\tvalid_0's rmse: 0.227467\n",
      "[650]\tvalid_0's rmse: 0.227464\n",
      "[651]\tvalid_0's rmse: 0.22746\n",
      "[652]\tvalid_0's rmse: 0.22746\n",
      "[653]\tvalid_0's rmse: 0.227446\n",
      "[654]\tvalid_0's rmse: 0.22742\n",
      "[655]\tvalid_0's rmse: 0.227413\n",
      "[656]\tvalid_0's rmse: 0.227402\n",
      "[657]\tvalid_0's rmse: 0.227385\n",
      "[658]\tvalid_0's rmse: 0.227365\n",
      "[659]\tvalid_0's rmse: 0.227358\n",
      "[660]\tvalid_0's rmse: 0.227356\n",
      "[661]\tvalid_0's rmse: 0.227346\n",
      "[662]\tvalid_0's rmse: 0.227346\n",
      "[663]\tvalid_0's rmse: 0.227339\n",
      "[664]\tvalid_0's rmse: 0.227317\n",
      "[665]\tvalid_0's rmse: 0.227299\n",
      "[666]\tvalid_0's rmse: 0.227292\n",
      "[667]\tvalid_0's rmse: 0.227278\n",
      "[668]\tvalid_0's rmse: 0.227269\n",
      "[669]\tvalid_0's rmse: 0.227266\n",
      "[670]\tvalid_0's rmse: 0.227262\n",
      "[671]\tvalid_0's rmse: 0.227253\n",
      "[672]\tvalid_0's rmse: 0.227249\n",
      "[673]\tvalid_0's rmse: 0.22724\n",
      "[674]\tvalid_0's rmse: 0.227227\n",
      "[675]\tvalid_0's rmse: 0.227212\n",
      "[676]\tvalid_0's rmse: 0.227212\n",
      "[677]\tvalid_0's rmse: 0.227207\n",
      "[678]\tvalid_0's rmse: 0.227182\n",
      "[679]\tvalid_0's rmse: 0.227175\n",
      "[680]\tvalid_0's rmse: 0.227161\n",
      "[681]\tvalid_0's rmse: 0.227135\n",
      "[682]\tvalid_0's rmse: 0.22712\n",
      "[683]\tvalid_0's rmse: 0.227114\n",
      "[684]\tvalid_0's rmse: 0.227104\n",
      "[685]\tvalid_0's rmse: 0.227097\n",
      "[686]\tvalid_0's rmse: 0.227097\n",
      "[687]\tvalid_0's rmse: 0.227088\n",
      "[688]\tvalid_0's rmse: 0.227078\n",
      "[689]\tvalid_0's rmse: 0.227077\n",
      "[690]\tvalid_0's rmse: 0.227065\n",
      "[691]\tvalid_0's rmse: 0.227057\n",
      "[692]\tvalid_0's rmse: 0.227045\n",
      "[693]\tvalid_0's rmse: 0.227022\n",
      "[694]\tvalid_0's rmse: 0.227007\n",
      "[695]\tvalid_0's rmse: 0.226991\n",
      "[696]\tvalid_0's rmse: 0.226973\n",
      "[697]\tvalid_0's rmse: 0.226951\n",
      "[698]\tvalid_0's rmse: 0.226934\n",
      "[699]\tvalid_0's rmse: 0.226908\n",
      "[700]\tvalid_0's rmse: 0.226902\n",
      "[701]\tvalid_0's rmse: 0.226897\n",
      "[702]\tvalid_0's rmse: 0.226887\n",
      "[703]\tvalid_0's rmse: 0.226881\n",
      "[704]\tvalid_0's rmse: 0.226859\n",
      "[705]\tvalid_0's rmse: 0.226849\n",
      "[706]\tvalid_0's rmse: 0.226839\n",
      "[707]\tvalid_0's rmse: 0.226832\n",
      "[708]\tvalid_0's rmse: 0.226816\n",
      "[709]\tvalid_0's rmse: 0.226809\n",
      "[710]\tvalid_0's rmse: 0.226801\n",
      "[711]\tvalid_0's rmse: 0.226794\n",
      "[712]\tvalid_0's rmse: 0.226789\n",
      "[713]\tvalid_0's rmse: 0.226786\n",
      "[714]\tvalid_0's rmse: 0.226755\n",
      "[715]\tvalid_0's rmse: 0.226744\n",
      "[716]\tvalid_0's rmse: 0.226731\n",
      "[717]\tvalid_0's rmse: 0.22672\n",
      "[718]\tvalid_0's rmse: 0.226705\n",
      "[719]\tvalid_0's rmse: 0.226699\n",
      "[720]\tvalid_0's rmse: 0.226686\n",
      "[721]\tvalid_0's rmse: 0.22667\n",
      "[722]\tvalid_0's rmse: 0.226666\n",
      "[723]\tvalid_0's rmse: 0.226666\n",
      "[724]\tvalid_0's rmse: 0.226662\n",
      "[725]\tvalid_0's rmse: 0.226652\n",
      "[726]\tvalid_0's rmse: 0.226647\n",
      "[727]\tvalid_0's rmse: 0.226628\n",
      "[728]\tvalid_0's rmse: 0.226608\n",
      "[729]\tvalid_0's rmse: 0.226603\n",
      "[730]\tvalid_0's rmse: 0.2266\n",
      "[731]\tvalid_0's rmse: 0.226599\n",
      "[732]\tvalid_0's rmse: 0.226597\n",
      "[733]\tvalid_0's rmse: 0.226596\n",
      "[734]\tvalid_0's rmse: 0.226593\n",
      "[735]\tvalid_0's rmse: 0.22659\n",
      "[736]\tvalid_0's rmse: 0.226585\n",
      "[737]\tvalid_0's rmse: 0.226563\n",
      "[738]\tvalid_0's rmse: 0.226547\n",
      "[739]\tvalid_0's rmse: 0.226546\n",
      "[740]\tvalid_0's rmse: 0.226536\n",
      "[741]\tvalid_0's rmse: 0.226532\n",
      "[742]\tvalid_0's rmse: 0.226519\n",
      "[743]\tvalid_0's rmse: 0.226516\n",
      "[744]\tvalid_0's rmse: 0.226509\n",
      "[745]\tvalid_0's rmse: 0.226496\n",
      "[746]\tvalid_0's rmse: 0.226491\n",
      "[747]\tvalid_0's rmse: 0.226465\n",
      "[748]\tvalid_0's rmse: 0.226461\n",
      "[749]\tvalid_0's rmse: 0.226443\n",
      "[750]\tvalid_0's rmse: 0.226426\n",
      "[751]\tvalid_0's rmse: 0.226406\n",
      "[752]\tvalid_0's rmse: 0.226396\n",
      "[753]\tvalid_0's rmse: 0.226391\n",
      "[754]\tvalid_0's rmse: 0.226383\n",
      "[755]\tvalid_0's rmse: 0.226377\n",
      "[756]\tvalid_0's rmse: 0.226373\n",
      "[757]\tvalid_0's rmse: 0.226361\n",
      "[758]\tvalid_0's rmse: 0.226357\n",
      "[759]\tvalid_0's rmse: 0.226351\n",
      "[760]\tvalid_0's rmse: 0.226345\n",
      "[761]\tvalid_0's rmse: 0.226319\n",
      "[762]\tvalid_0's rmse: 0.226309\n",
      "[763]\tvalid_0's rmse: 0.226292\n",
      "[764]\tvalid_0's rmse: 0.226286\n",
      "[765]\tvalid_0's rmse: 0.226285\n",
      "[766]\tvalid_0's rmse: 0.226279\n",
      "[767]\tvalid_0's rmse: 0.226267\n",
      "[768]\tvalid_0's rmse: 0.226262\n",
      "[769]\tvalid_0's rmse: 0.226252\n",
      "[770]\tvalid_0's rmse: 0.226233\n",
      "[771]\tvalid_0's rmse: 0.226224\n",
      "[772]\tvalid_0's rmse: 0.226222\n",
      "[773]\tvalid_0's rmse: 0.226218\n",
      "[774]\tvalid_0's rmse: 0.226215\n",
      "[775]\tvalid_0's rmse: 0.226215\n",
      "[776]\tvalid_0's rmse: 0.226199\n",
      "[777]\tvalid_0's rmse: 0.226193\n",
      "[778]\tvalid_0's rmse: 0.226182\n",
      "[779]\tvalid_0's rmse: 0.226177\n",
      "[780]\tvalid_0's rmse: 0.226177\n",
      "[781]\tvalid_0's rmse: 0.226152\n",
      "[782]\tvalid_0's rmse: 0.226148\n",
      "[783]\tvalid_0's rmse: 0.226129\n",
      "[784]\tvalid_0's rmse: 0.226117\n",
      "[785]\tvalid_0's rmse: 0.226112\n",
      "[786]\tvalid_0's rmse: 0.22611\n",
      "[787]\tvalid_0's rmse: 0.226092\n",
      "[788]\tvalid_0's rmse: 0.226082\n",
      "[789]\tvalid_0's rmse: 0.226075\n",
      "[790]\tvalid_0's rmse: 0.226068\n",
      "[791]\tvalid_0's rmse: 0.22606\n",
      "[792]\tvalid_0's rmse: 0.226048\n",
      "[793]\tvalid_0's rmse: 0.226041\n",
      "[794]\tvalid_0's rmse: 0.226035\n",
      "[795]\tvalid_0's rmse: 0.226024\n",
      "[796]\tvalid_0's rmse: 0.226009\n",
      "[797]\tvalid_0's rmse: 0.225995\n",
      "[798]\tvalid_0's rmse: 0.22598\n",
      "[799]\tvalid_0's rmse: 0.225978\n",
      "[800]\tvalid_0's rmse: 0.225963\n",
      "[801]\tvalid_0's rmse: 0.225944\n",
      "[802]\tvalid_0's rmse: 0.225928\n",
      "[803]\tvalid_0's rmse: 0.225921\n",
      "[804]\tvalid_0's rmse: 0.225912\n",
      "[805]\tvalid_0's rmse: 0.225909\n",
      "[806]\tvalid_0's rmse: 0.225908\n",
      "[807]\tvalid_0's rmse: 0.225901\n",
      "[808]\tvalid_0's rmse: 0.225888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[809]\tvalid_0's rmse: 0.225882\n",
      "[810]\tvalid_0's rmse: 0.22588\n",
      "[811]\tvalid_0's rmse: 0.225879\n",
      "[812]\tvalid_0's rmse: 0.225869\n",
      "[813]\tvalid_0's rmse: 0.225867\n",
      "[814]\tvalid_0's rmse: 0.225864\n",
      "[815]\tvalid_0's rmse: 0.225856\n",
      "[816]\tvalid_0's rmse: 0.22584\n",
      "[817]\tvalid_0's rmse: 0.225839\n",
      "[818]\tvalid_0's rmse: 0.22583\n",
      "[819]\tvalid_0's rmse: 0.225819\n",
      "[820]\tvalid_0's rmse: 0.225806\n",
      "[821]\tvalid_0's rmse: 0.225792\n",
      "[822]\tvalid_0's rmse: 0.225783\n",
      "[823]\tvalid_0's rmse: 0.225777\n",
      "[824]\tvalid_0's rmse: 0.225776\n",
      "[825]\tvalid_0's rmse: 0.225776\n",
      "[826]\tvalid_0's rmse: 0.225767\n",
      "[827]\tvalid_0's rmse: 0.225756\n",
      "[828]\tvalid_0's rmse: 0.225739\n",
      "[829]\tvalid_0's rmse: 0.225727\n",
      "[830]\tvalid_0's rmse: 0.225715\n",
      "[831]\tvalid_0's rmse: 0.2257\n",
      "[832]\tvalid_0's rmse: 0.225692\n",
      "[833]\tvalid_0's rmse: 0.225688\n",
      "[834]\tvalid_0's rmse: 0.225687\n",
      "[835]\tvalid_0's rmse: 0.225682\n",
      "[836]\tvalid_0's rmse: 0.22568\n",
      "[837]\tvalid_0's rmse: 0.225676\n",
      "[838]\tvalid_0's rmse: 0.225666\n",
      "[839]\tvalid_0's rmse: 0.225667\n",
      "[840]\tvalid_0's rmse: 0.225659\n",
      "[841]\tvalid_0's rmse: 0.225658\n",
      "[842]\tvalid_0's rmse: 0.225647\n",
      "[843]\tvalid_0's rmse: 0.225644\n",
      "[844]\tvalid_0's rmse: 0.225639\n",
      "[845]\tvalid_0's rmse: 0.225631\n",
      "[846]\tvalid_0's rmse: 0.225623\n",
      "[847]\tvalid_0's rmse: 0.225606\n",
      "[848]\tvalid_0's rmse: 0.225583\n",
      "[849]\tvalid_0's rmse: 0.225581\n",
      "[850]\tvalid_0's rmse: 0.22558\n",
      "[851]\tvalid_0's rmse: 0.225574\n",
      "[852]\tvalid_0's rmse: 0.225567\n",
      "[853]\tvalid_0's rmse: 0.225549\n",
      "[854]\tvalid_0's rmse: 0.225539\n",
      "[855]\tvalid_0's rmse: 0.225536\n",
      "[856]\tvalid_0's rmse: 0.225527\n",
      "[857]\tvalid_0's rmse: 0.225511\n",
      "[858]\tvalid_0's rmse: 0.225499\n",
      "[859]\tvalid_0's rmse: 0.225496\n",
      "[860]\tvalid_0's rmse: 0.225486\n",
      "[861]\tvalid_0's rmse: 0.225472\n",
      "[862]\tvalid_0's rmse: 0.225466\n",
      "[863]\tvalid_0's rmse: 0.225451\n",
      "[864]\tvalid_0's rmse: 0.225428\n",
      "[865]\tvalid_0's rmse: 0.225425\n",
      "[866]\tvalid_0's rmse: 0.225424\n",
      "[867]\tvalid_0's rmse: 0.225419\n",
      "[868]\tvalid_0's rmse: 0.225417\n",
      "[869]\tvalid_0's rmse: 0.225412\n",
      "[870]\tvalid_0's rmse: 0.225393\n",
      "[871]\tvalid_0's rmse: 0.225375\n",
      "[872]\tvalid_0's rmse: 0.225365\n",
      "[873]\tvalid_0's rmse: 0.225362\n",
      "[874]\tvalid_0's rmse: 0.225357\n",
      "[875]\tvalid_0's rmse: 0.225356\n",
      "[876]\tvalid_0's rmse: 0.225346\n",
      "[877]\tvalid_0's rmse: 0.225339\n",
      "[878]\tvalid_0's rmse: 0.225336\n",
      "[879]\tvalid_0's rmse: 0.225332\n",
      "[880]\tvalid_0's rmse: 0.225323\n",
      "[881]\tvalid_0's rmse: 0.225317\n",
      "[882]\tvalid_0's rmse: 0.225302\n",
      "[883]\tvalid_0's rmse: 0.225303\n",
      "[884]\tvalid_0's rmse: 0.225295\n",
      "[885]\tvalid_0's rmse: 0.22529\n",
      "[886]\tvalid_0's rmse: 0.225287\n",
      "[887]\tvalid_0's rmse: 0.22528\n",
      "[888]\tvalid_0's rmse: 0.225269\n",
      "[889]\tvalid_0's rmse: 0.225266\n",
      "[890]\tvalid_0's rmse: 0.225261\n",
      "[891]\tvalid_0's rmse: 0.225246\n",
      "[892]\tvalid_0's rmse: 0.225238\n",
      "[893]\tvalid_0's rmse: 0.225229\n",
      "[894]\tvalid_0's rmse: 0.225227\n",
      "[895]\tvalid_0's rmse: 0.225216\n",
      "[896]\tvalid_0's rmse: 0.225214\n",
      "[897]\tvalid_0's rmse: 0.225211\n",
      "[898]\tvalid_0's rmse: 0.22521\n",
      "[899]\tvalid_0's rmse: 0.225209\n",
      "[900]\tvalid_0's rmse: 0.225206\n",
      "[901]\tvalid_0's rmse: 0.225203\n",
      "[902]\tvalid_0's rmse: 0.225196\n",
      "[903]\tvalid_0's rmse: 0.225194\n",
      "[904]\tvalid_0's rmse: 0.225191\n",
      "[905]\tvalid_0's rmse: 0.225183\n",
      "[906]\tvalid_0's rmse: 0.225172\n",
      "[907]\tvalid_0's rmse: 0.225169\n",
      "[908]\tvalid_0's rmse: 0.225166\n",
      "[909]\tvalid_0's rmse: 0.225163\n",
      "[910]\tvalid_0's rmse: 0.225151\n",
      "[911]\tvalid_0's rmse: 0.225135\n",
      "[912]\tvalid_0's rmse: 0.225134\n",
      "[913]\tvalid_0's rmse: 0.225124\n",
      "[914]\tvalid_0's rmse: 0.225113\n",
      "[915]\tvalid_0's rmse: 0.225111\n",
      "[916]\tvalid_0's rmse: 0.225112\n",
      "[917]\tvalid_0's rmse: 0.225111\n",
      "[918]\tvalid_0's rmse: 0.225103\n",
      "[919]\tvalid_0's rmse: 0.225101\n",
      "[920]\tvalid_0's rmse: 0.225092\n",
      "[921]\tvalid_0's rmse: 0.225089\n",
      "[922]\tvalid_0's rmse: 0.22507\n",
      "[923]\tvalid_0's rmse: 0.225064\n",
      "[924]\tvalid_0's rmse: 0.225059\n",
      "[925]\tvalid_0's rmse: 0.225056\n",
      "[926]\tvalid_0's rmse: 0.225037\n",
      "[927]\tvalid_0's rmse: 0.225026\n",
      "[928]\tvalid_0's rmse: 0.225017\n",
      "[929]\tvalid_0's rmse: 0.225009\n",
      "[930]\tvalid_0's rmse: 0.225003\n",
      "[931]\tvalid_0's rmse: 0.225002\n",
      "[932]\tvalid_0's rmse: 0.224988\n",
      "[933]\tvalid_0's rmse: 0.224987\n",
      "[934]\tvalid_0's rmse: 0.224971\n",
      "[935]\tvalid_0's rmse: 0.224963\n",
      "[936]\tvalid_0's rmse: 0.224955\n",
      "[937]\tvalid_0's rmse: 0.224949\n",
      "[938]\tvalid_0's rmse: 0.224935\n",
      "[939]\tvalid_0's rmse: 0.224925\n",
      "[940]\tvalid_0's rmse: 0.224918\n",
      "[941]\tvalid_0's rmse: 0.224898\n",
      "[942]\tvalid_0's rmse: 0.224899\n",
      "[943]\tvalid_0's rmse: 0.224885\n",
      "[944]\tvalid_0's rmse: 0.224873\n",
      "[945]\tvalid_0's rmse: 0.224867\n",
      "[946]\tvalid_0's rmse: 0.224862\n",
      "[947]\tvalid_0's rmse: 0.224853\n",
      "[948]\tvalid_0's rmse: 0.224845\n",
      "[949]\tvalid_0's rmse: 0.22484\n",
      "[950]\tvalid_0's rmse: 0.224832\n",
      "[951]\tvalid_0's rmse: 0.22483\n",
      "[952]\tvalid_0's rmse: 0.22481\n",
      "[953]\tvalid_0's rmse: 0.224805\n",
      "[954]\tvalid_0's rmse: 0.224792\n",
      "[955]\tvalid_0's rmse: 0.224788\n",
      "[956]\tvalid_0's rmse: 0.224771\n",
      "[957]\tvalid_0's rmse: 0.224764\n",
      "[958]\tvalid_0's rmse: 0.224759\n",
      "[959]\tvalid_0's rmse: 0.224754\n",
      "[960]\tvalid_0's rmse: 0.224747\n",
      "[961]\tvalid_0's rmse: 0.224729\n",
      "[962]\tvalid_0's rmse: 0.224724\n",
      "[963]\tvalid_0's rmse: 0.224723\n",
      "[964]\tvalid_0's rmse: 0.224721\n",
      "[965]\tvalid_0's rmse: 0.22472\n",
      "[966]\tvalid_0's rmse: 0.22472\n",
      "[967]\tvalid_0's rmse: 0.224716\n",
      "[968]\tvalid_0's rmse: 0.224709\n",
      "[969]\tvalid_0's rmse: 0.224693\n",
      "[970]\tvalid_0's rmse: 0.224681\n",
      "[971]\tvalid_0's rmse: 0.224668\n",
      "[972]\tvalid_0's rmse: 0.224656\n",
      "[973]\tvalid_0's rmse: 0.224644\n",
      "[974]\tvalid_0's rmse: 0.224633\n",
      "[975]\tvalid_0's rmse: 0.224621\n",
      "[976]\tvalid_0's rmse: 0.224618\n",
      "[977]\tvalid_0's rmse: 0.224614\n",
      "[978]\tvalid_0's rmse: 0.224608\n",
      "[979]\tvalid_0's rmse: 0.224595\n",
      "[980]\tvalid_0's rmse: 0.224588\n",
      "[981]\tvalid_0's rmse: 0.224579\n",
      "[982]\tvalid_0's rmse: 0.224575\n",
      "[983]\tvalid_0's rmse: 0.224565\n",
      "[984]\tvalid_0's rmse: 0.22456\n",
      "[985]\tvalid_0's rmse: 0.224555\n",
      "[986]\tvalid_0's rmse: 0.224544\n",
      "[987]\tvalid_0's rmse: 0.22454\n",
      "[988]\tvalid_0's rmse: 0.224538\n",
      "[989]\tvalid_0's rmse: 0.224536\n",
      "[990]\tvalid_0's rmse: 0.22452\n",
      "[991]\tvalid_0's rmse: 0.224512\n",
      "[992]\tvalid_0's rmse: 0.224499\n",
      "[993]\tvalid_0's rmse: 0.224493\n",
      "[994]\tvalid_0's rmse: 0.224482\n",
      "[995]\tvalid_0's rmse: 0.224481\n",
      "[996]\tvalid_0's rmse: 0.224472\n",
      "[997]\tvalid_0's rmse: 0.224462\n",
      "[998]\tvalid_0's rmse: 0.224451\n",
      "[999]\tvalid_0's rmse: 0.22444\n",
      "[1000]\tvalid_0's rmse: 0.224431\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.224431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25)\n",
    "model1 = lgb.LGBMRegressor(n_estimators=1000)\n",
    "model1.fit(X_train,y_train,\n",
    "    eval_set = [(X_eval,y_eval)],\n",
    "    early_stopping_rounds=5,\n",
    "    eval_metric=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model1.predict(X_valid)\n",
    "df_preds['interest'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021764365943766\n"
     ]
    }
   ],
   "source": [
    "df_ranked = df_preds.sort_values(['user_id_hash', 'interest'], ascending=[False, False])\n",
    "df_ranked = (df_ranked\n",
    "    .groupby('user_id_hash')['coupon_id_hash']\n",
    "    .apply(list)\n",
    "    .reset_index())\n",
    "recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "    index=df_ranked.user_id_hash).to_dict()\n",
    "\n",
    "actual = []\n",
    "pred = []\n",
    "for k,_ in recomendations_dict.items():\n",
    "    actual.append(list(interactions_valid_dict[k]))\n",
    "    pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "print(mapk(actual,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not amazing, let's see what happens with optimization..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WITH OPTIMIZATION\n",
    "\n",
    "Here we will use hyperopt as in the previous Chapter to optimise `lightGBM`\n",
    "\n",
    "It is worth mentioning that here features are numerical. This normally makes things slightly simpler. In this scenario you might want to try libraries like [tpot](https://epistasislab.github.io/tpot/) for automatic ML with genetic programming (if you have the time and the memory) or [ml-lens](http://ml-ensemble.com/info/start/ensembles.html) to build ensemble algorithms. \n",
    "\n",
    "Let's start with the usual objective function, optimising using the `MAP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective_map(params):\n",
    "    \"\"\"\n",
    "    objective function for lightgbm.\n",
    "    \"\"\"\n",
    "\n",
    "    # hyperopt casts as float\n",
    "    params['num_boost_round'] = int(params['num_boost_round'])\n",
    "    params['num_leaves'] = int(params['num_leaves'])\n",
    "\n",
    "    # need to be passed as parameter\n",
    "    params['verbose'] = -1\n",
    "    params['seed'] = 1\n",
    "\n",
    "    cv_result = lgb.cv(\n",
    "    params,\n",
    "    lgtrain,\n",
    "    nfold=3,\n",
    "    metrics='rmse',\n",
    "    num_boost_round=params['num_boost_round'],\n",
    "    early_stopping_rounds=20,\n",
    "    stratified=False,\n",
    "    )\n",
    "    early_stop_dict[lgb_objective_map.i] = len(cv_result['rmse-mean'])\n",
    "    params['num_boost_round'] = len(cv_result['rmse-mean'])\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X,y)\n",
    "    preds = model.predict(X_valid)\n",
    "\n",
    "    df_preds['interest'] = preds\n",
    "    df_ranked = df_preds.sort_values(['user_id_hash', 'interest'], ascending=[False, False])\n",
    "    df_ranked = (df_ranked\n",
    "        .groupby('user_id_hash')['coupon_id_hash']\n",
    "        .apply(list)\n",
    "        .reset_index())\n",
    "    recomendations_dict = pd.Series(df_ranked.coupon_id_hash.values,\n",
    "        index=df_ranked.user_id_hash).to_dict()\n",
    "\n",
    "    actual = []\n",
    "    pred = []\n",
    "    for k,_ in recomendations_dict.items():\n",
    "        actual.append(list(interactions_valid_dict[k]))\n",
    "        pred.append(list(recomendations_dict[k]))\n",
    "\n",
    "    result = mapk(actual,pred)\n",
    "    print(\"INFO: iteration {} MAP {:.3f}\".format(lgb_objective_map.i, result))\n",
    "\n",
    "    lgb_objective_map.i+=1\n",
    "\n",
    "    return 1-result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to `lightGBM` data format and defining the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb dataset object\n",
    "lgtrain = lgb.Dataset(X,\n",
    "    label=y,\n",
    "    free_raw_data=False)\n",
    "\n",
    "# defining the parameter space\n",
    "lgb_parameter_space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.5),\n",
    "    'num_boost_round': hp.quniform('num_boost_round', 100, 500, 50),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30,1024,5),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 50, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.01, 1.),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 1.),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not run the cell below here. It takes 98 min on a c5.4xlarge EC2 instance (30GB, 16 cores), so I used `screen` in the terminal and went for a run myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_dict = {}\n",
    "trials = Trials()\n",
    "start = time()\n",
    "lgb_objective_map.i = 0\n",
    "best = fmin(fn=lgb_objective_map,\n",
    "            space=lgb_parameter_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "best['num_boost_round'] = early_stop_dict[trials.best_trial['tid']]\n",
    "best['num_leaves'] = int(best['num_leaves'])\n",
    "best['verbose'] = -1\n",
    "print(1-trials.best_trial['result']['loss'])\n",
    "print(time()-start)\n",
    "print(best)\n",
    "pickle.dump(best,open(\"../datasets/Ponpare/data_processed/models/gbm_nmf_optimal_parameters.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result is MAP: 0.021808\n",
    "\n",
    "and the corresponding best parameters are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.70026944963067,\n",
       " 'learning_rate': 0.13477552502641502,\n",
       " 'min_child_weight': 40.0,\n",
       " 'num_boost_round': 200,\n",
       " 'num_leaves': 355,\n",
       " 'reg_alpha': 0.4739150442922858,\n",
       " 'reg_lambda': 0.7609758831113889,\n",
       " 'subsample': 0.796699692621813,\n",
       " 'verbose': -1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.load(open(\"../datasets/Ponpare/data_processed/models/gbm_nmf_optimal_parameters.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Totally **not** worth it. Furthermore, using the so called \"Simple Solution\" (i.e. no optimization) and `n_comp=100` you obtain MAP=0.0226255 and \"in no time\". Nonetheless, this is still significantly smaller than using directly `lightGBM` on the features themselves (see Chapter 10). \n",
    "\n",
    "However, if you face a problem where this technique performs well, it is indeed a very useful technique. This is because the latent factors can be used for a number of things other than recommending. They have been learned based on users' behaviour. Therefore, you might want to use them for campaign targeting instead of demographic-based features (such as age, location, etc) for example. In this scenario, you will be targeting your users based on their behaviour instead of some \"human-readable\" features, which is possibly more adequate. \n",
    "\n",
    "Before we leave this notebook make sure you are familiar with the concept of latent factors, since similar principles with a different formulation will be applied when using our next technique: Factorization Machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
