{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Preparing the data\n",
    "\n",
    "In this notebook I will describe how one designs the experiment and prepares the data to be passed to the algorithm(s)\n",
    "\n",
    "Before going any further let me acknowledge the authors of the paper that I will be implementing here as well as the code that inspire most of the code in this repo. \n",
    "\n",
    "This repo is based on paper: [`Variational Autoencoders for Collaborative Filtering`](https://arxiv.org/pdf/1802.05814.pdf). The paper has a companion [repo](https://github.com/dawenl/vae_cf) where you can find the `tensorflow` implementation of the algorithm. As always, I strongly recommend having a look to both the repo and of course the paper. \n",
    "\n",
    "On the other hand the `Pytorch` and `Mxnet` implementations of the algorithm in this repo are greatly inspired by the code in this [repo](https://github.com/younggyoseo/vae-cf-pytorch). I have adapted the code to my coding preferences and added some options and flexibility to run multiple experiments. \n",
    "\n",
    "Once all that clever people are acknowledged for their contributions, let's have a look to the data. Throught this exercise I will use two dataset. The [Amazon Movies and TV](http://jmcauley.ucsd.edu/data/amazon/) dataset and the [Movilens](https://grouplens.org/datasets/movielens/20m/) dataset. The later is mainly use so I can make sure I am obtaining consistent results to those obtained in the paper. \n",
    "\n",
    "As we will see through the notebook, the Amazon dataset is significantly more challenging that the Movielens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from fire import Fire\n",
    "from typing import Tuple, Dict, Union\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a few constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "new_colnames = [\"user\", \"item\", \"rating\", \"timestamp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me focus on the `Amazon` data here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = DATA_DIR / \"amazon-movies\"\n",
    "filename = \"reviews_Movies_and_TV_5.json.gz\"\n",
    "raw_data = pd.read_json(inp_path / filename, lines=True)\n",
    "keep_cols = [\"reviewerID\", \"asin\", \"overall\", \"unixReviewTime\"]\n",
    "raw_data = raw_data[keep_cols]\n",
    "raw_data.columns = new_colnames\n",
    "\n",
    "# # Replace those lines with the ones below for the movielens dataset\n",
    "# inp_path = DATA_DIR / \"ml-20m\"\n",
    "# filename = \"ratings.csv\"\n",
    "# raw_data = pd.read_csv(inp_path / filename, header=0)\n",
    "# raw_data.columns = new_colnames\n",
    "# raw_data = raw_data[raw_data[\"rating\"] > 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697533, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1203984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>5</td>\n",
       "      <td>1202860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1387670400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0   ADZPIG9QOCDG5  0005019281       4  1203984000\n",
       "1  A35947ZP82G7JH  0005019281       3  1388361600\n",
       "2  A3UORV8A9D5L2E  0005019281       3  1388361600\n",
       "3  A1VKW06X1O2X7V  0005019281       5  1202860800\n",
       "4  A3R27T4HADWFFJ  0005019281       4  1387670400"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that the we do is to \"*filter triples*\" (hereafter refereed as `tp`) based on the number of times a user interacted with items (`min_user_click`) or items that where \"*interacted with*\" by a user a given number of times (`min_item_click`). \n",
    "\n",
    "We do this with the following two functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp: pd.DataFrame, id: str) -> pd.Index:\n",
    "    \"\"\"\n",
    "    Returns `tp` groupby+count by `id`\n",
    "    \"\"\"\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "\n",
    "def filter_triplets(\n",
    "    tp: pd.DataFrame, min_user_click, min_item_click\n",
    ") -> Tuple[pd.DataFrame, pd.Index, pd.Index]:\n",
    "    \"\"\"\n",
    "    Returns triplets (`tp`) of user-item-rating for users/items with \n",
    "    more than min_user_click/min_item_click counts\n",
    "    \"\"\"\n",
    "    if min_item_click > 0:\n",
    "        itemcount = get_count(tp, \"item\")\n",
    "        tp = tp[tp[\"item\"].isin(itemcount.index[itemcount >= min_item_click])]\n",
    "\n",
    "    if min_user_click > 0:\n",
    "        usercount = get_count(tp, \"user\")\n",
    "        tp = tp[tp[\"user\"].isin(usercount.index[usercount >= min_user_click])]\n",
    "\n",
    "    usercount, itemcount = get_count(tp, \"user\"), get_count(tp, \"item\")\n",
    "\n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw_data, user_activity, item_popularity = filter_triplets(\n",
    "    raw_data, min_user_click=5, min_item_click=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697533, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADZPIG9QOCDG5</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1203984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A35947ZP82G7JH</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3UORV8A9D5L2E</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>3</td>\n",
       "      <td>1388361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1VKW06X1O2X7V</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>5</td>\n",
       "      <td>1202860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R27T4HADWFFJ</td>\n",
       "      <td>0005019281</td>\n",
       "      <td>4</td>\n",
       "      <td>1387670400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating   timestamp\n",
       "0   ADZPIG9QOCDG5  0005019281       4  1203984000\n",
       "1  A35947ZP82G7JH  0005019281       3  1388361600\n",
       "2  A3UORV8A9D5L2E  0005019281       3  1388361600\n",
       "3  A1VKW06X1O2X7V  0005019281       5  1202860800\n",
       "4  A3R27T4HADWFFJ  0005019281       4  1387670400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "A00295401U6S2UG3RAQSZ     6\n",
       "A00348066Q1WEW5BMESN      5\n",
       "A0040548BPHKXMHH3NTI     10\n",
       "A00438023NNXSDBGXK56L     5\n",
       "A0048168OBFNFN7WW8XC      9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_activity.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since I am using the `\"reviews_Movies_and_TV_5.json.gz\"` (i.e. the 5-core dataset, where users and items have k reviews each) `filtered_raw_data` has no effect on the `Amazon` dataset. It does however filter some users/items in the case of the `Movilens` dataset.   \n",
    "\n",
    "Let's now have a look to the sparsity of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 1697533 watching events from 123960 users and 50052 movies (sparsity: 0.027%)\n"
     ]
    }
   ],
   "source": [
    "sparsity = (\n",
    "    1.0\n",
    "    * filtered_raw_data.shape[0]\n",
    "    / (user_activity.shape[0] * item_popularity.shape[0])\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\"\n",
    "    % (\n",
    "        filtered_raw_data.shape[0],\n",
    "        user_activity.shape[0],\n",
    "        item_popularity.shape[0],\n",
    "        sparsity * 100,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these numbers to those of the `Movilens` dataset (9990682 watching events from 136677 users and 20720 movies: sparsity: 0.353%. see the [notebook](https://github.com/dawenl/vae_cf/blob/master/VAE_ML20M_WWW2018.ipynb) corresponding to the original publication, or the [original publication](https://arxiv.org/pdf/1802.05814.pdf) itself) one can see that the `Amazon` dataset is $\\sim$13 times more sparse than the `Movielens` dataset. In consequence, I expect that the algorithm finds it more challenging, resulting in lower ranking metrics.\n",
    "\n",
    "Once the raw data is filtered, we follow the same procedure than that of the original authors to split the users into training, validation and test users. This happens within the next function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_users(\n",
    "    unique_uid: pd.Index, test_users_size: Union[float, int]\n",
    ") -> Tuple[pd.Index, pd.Index, pd.Index]:\n",
    "\n",
    "    n_users = unique_uid.size\n",
    "\n",
    "    if isinstance(test_users_size, int):\n",
    "        n_heldout_users = test_users_size\n",
    "    else:\n",
    "        n_heldout_users = int(test_users_size * n_users)\n",
    "\n",
    "    tr_users = unique_uid[: (n_users - n_heldout_users * 2)]\n",
    "    vd_users = unique_uid[(n_users - n_heldout_users * 2) : (n_users - n_heldout_users)]\n",
    "    te_users = unique_uid[(n_users - n_heldout_users) :]\n",
    "\n",
    "    return tr_users, vd_users, te_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "tr_users, vd_users, te_users = split_users(\n",
    "    unique_uid, test_users_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99168,) (12396,) (12396,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_users.shape, vd_users.shape, te_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A2AA6XJ6ZPU52I', 'A2D6VDR54FDOK1', 'A1GOCS6P9ZJLDJ', 'AD3IEMGOL22CZ',\n",
       "       'A1O0YYQ587UV5X', 'AJ13O1EERMG98', 'A36ZCBPPL2MSRG', 'A1FA82C5JQAC2H',\n",
       "       'A2Z2XRM3TNKUS', 'AWN86EEALSBNR'],\n",
       "      dtype='object', name='user')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_users[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training observations raw data \n",
    "tr_obsrv = filtered_raw_data.loc[filtered_raw_data[\"user\"].isin(tr_users)]\n",
    "tr_items = pd.unique(tr_obsrv[\"item\"])\n",
    "\n",
    "# Save index dictionaries to \"numerise\" later one\n",
    "item2id = dict((sid, i) for (i, sid) in enumerate(tr_items))\n",
    "user2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how the  authors design the experiment. For validation and test they consider \"*only*\" items that have been seen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd_obsrv = filtered_raw_data[\n",
    "    filtered_raw_data[\"user\"].isin(vd_users)\n",
    "    & filtered_raw_data[\"item\"].isin(tr_items)\n",
    "]\n",
    "\n",
    "te_obsrv = filtered_raw_data[\n",
    "    filtered_raw_data[\"user\"].isin(te_users)\n",
    "    & filtered_raw_data[\"item\"].isin(tr_items)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in reality, this is not really an aggresive filtering since the total number of items was 50052 and the number train items is  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50049,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_items.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the validation and test users and their interactions, we will split such interactions into so-called \"*validation and test train and test sets*\". \n",
    "\n",
    "I know that this sounds convoluted, but stay with me, is not that complex. The \"*validation_train and test_train sets*\" will be used to build what we could think as an input binary *\"image\"* to be \"*encoded -> decoded*\" by the trained auto-encoder, while the \"*validation_test and test_test sets*\" set will be used to compute the ranking metrics at validation/test time. \n",
    "\n",
    "For example, let's assume that we have already trained a VAE and we are at validation time. Let's say that a validation user has interacted with 10 items, and that we use 8 of these 10 as `validation_train` set and the remaining 2 as `validation_test` set. Let's also assume that the total number of items in our entire database is 20. \n",
    "\n",
    "Let's say that, once indexed, those 10 items that the user has interacted with are: *{0, 1, 3, 4, 5, 7, 9, 12, 13, 19}*\n",
    "\n",
    "validation train items: *{0, 1, 3, 5, 7, 9, 12, 19}*\n",
    "\n",
    "validation test items:  *{4, 13}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_tr = np.zeros(20)\n",
    "x_val_te = np.zeros(20)\n",
    "\n",
    "# validation items that will be passed as inputs to the trained AE and will be used\n",
    "# to compute a \"reconstruction\" loss\n",
    "x_val_tr[[0, 1, 3, 5, 7, 9, 12, 19]] = 1\n",
    "\n",
    "# reconstructed ratings by the AE\n",
    "x_val_out = np.random.uniform(0, 1, 20)\n",
    "\n",
    "# validation items that will be used to compute ranking metrics\n",
    "x_val_te[[4, 13]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this, when using batches, can be thought as a binary image to be encoded-decoded by the auto-encoder\n",
    "x_val_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30278161, 0.14136984, 0.06735148, 0.49820737, 0.66620596,\n",
       "       0.89161954, 0.20605658, 0.86947657, 0.33678987, 0.59325109,\n",
       "       0.92272292, 0.17465857, 0.55970304, 0.18423661, 0.57690288,\n",
       "       0.51976802, 0.35363432, 0.52543602, 0.01105844, 0.946705  ])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at validation time, we would compute the loss between `loss(x_val_out, x_val_tr)`. \n",
    "\n",
    "We would then set to a very low number those items in `x_val_tr` (we do not want to consider them when computing the ranking metrics), and compute the ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_out[x_val_tr.nonzero()] = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      -inf,       -inf, 0.06735148,       -inf, 0.66620596,\n",
       "             -inf, 0.20605658,       -inf, 0.33678987,       -inf,\n",
       "       0.92272292, 0.17465857,       -inf, 0.18423661, 0.57690288,\n",
       "       0.51976802, 0.35363432, 0.52543602, 0.01105844,       -inf])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then `ranking_metric(x_val_out, x_val_te)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation and test train/test split is accomplised by these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(\n",
    "    data: pd.DataFrame, test_size: float\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    data_grouped_by_user = data.groupby(\"user\")\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (nm, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype=\"bool\")\n",
    "            idx[\n",
    "                np.random.choice(\n",
    "                    n_items_u, size=int(test_size * n_items_u), replace=False\n",
    "                ).astype(\"int64\")\n",
    "            ] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "\n",
    "def numerize(tp: pd.DataFrame, user2id: Dict, item2id: Dict) -> pd.DataFrame:\n",
    "    user = [user2id[x] for x in tp[\"user\"]]\n",
    "    item = [item2id[x] for x in tp[\"item\"]]\n",
    "    return pd.DataFrame(data={\"user\": user, \"item\": item}, columns=[\"user\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n",
      "10000 users sampled\n",
      "11000 users sampled\n",
      "12000 users sampled\n",
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n",
      "10000 users sampled\n",
      "11000 users sampled\n",
      "12000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vd_items_tr, vd_items_te = split_train_test(vd_obsrv, test_size=0.2)\n",
    "te_items_tr, te_items_te = split_train_test(te_obsrv, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it regarding the data preparation. \n",
    "\n",
    "Now let's have a look to the models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
