{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Matrix Factorization\n",
    "\n",
    "This notebook would correspond to section 3.4 (Fusion of GMF and MLP) in [Xiangnan He, et al 2016](https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf) paper. Here we combine the models describled in Chapters 2 and 3, GMF and MLP respectively\n",
    "\n",
    "As always, let's start by loading the require packages and define a series of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import heapq\n",
    "\n",
    "from time import time\n",
    "from scipy.sparse import load_npz\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import get_train_instances, get_scores\n",
    "from gmf import GMF, train, evaluate, checkpoint\n",
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../datasets/Amazon\"\n",
    "dataname = \"neuralcf_split.npz\"\n",
    "train_matrix = \"neuralcf_train_sparse.npz\"\n",
    "modeldir = \"../datasets/Amazon/models\"\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 512\n",
    "lr = 0.01\n",
    "learner = \"Adam\"\n",
    "lr_scheduler = None\n",
    "\n",
    "n_emb = 8\n",
    "\n",
    "layers = [128, 64, 32]\n",
    "dropouts = [0., 0.]\n",
    "\n",
    "freeze = True\n",
    "\n",
    "# I have run a number of experiments and I know which models to combine...keep reading for more information\n",
    "mf_pretrain = os.path.join(modeldir, \"GMF_bs_1024_lr_001_n_emb_8_lrnr_adam_lrs_wolrs_BCELoss.pt\")\n",
    "mlp_pretrain = os.path.join(modeldir, \"MLP_bs_1024_reg_00_lr_003_n_emb_64_ll_32_dp_wodp_lrnr_adam_lrs_wlrs_loss_BCE.pt\")\n",
    "\n",
    "l2reg = 0.\n",
    "\n",
    "validate_every = 1\n",
    "save_model = True\n",
    "n_neg = 4\n",
    "topk = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that I am using a parameter called `freeze`, which is set to `True`. This indicates that I will use pretrained models and I will freeze all but the last linear layer of the model. The pretrained models will be\n",
    "\n",
    "    GMF_bs_1024_lr_001_n_emb_8_lrnr_adam_lrs_wolrs_BCELoss.pt\n",
    " \n",
    "and \n",
    "\n",
    "    MLP_bs_1024_reg_00_lr_003_n_emb_64_ll_32_dp_wodp_lrnr_adam_lrs_wlrs_loss_BCE.pt\n",
    "    \n",
    "These names can be read as follow: GMF model, for that experiment I used a batch size of 1024, learning rate of 0.01, embedding dimension 8, learner is Adam and withour scheduler. Or in the case of the MLP: MLP model with batch size 1024, no regularization, learning rate 0.03, 64dim embeddings, last layer (`ll`) of 32 neurons (this means that layers is [128, 64, 32]), without dropout, using Adam and learning rate scheduler.   \n",
    "  \n",
    "Let's see how the overal Model looks\n",
    "\n",
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_user, n_item, n_emb, layers, dropouts):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        self.layers = layers\n",
    "        self.n_layers = len(layers)\n",
    "        self.dropouts = dropouts\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "\n",
    "        self.mf_embeddings_user = nn.Embedding(n_user, n_emb)\n",
    "        self.mf_embeddings_item = nn.Embedding(n_item, n_emb)\n",
    "\n",
    "        self.mlp_embeddings_user = nn.Embedding(n_user, layers[0]//2)\n",
    "        self.mlp_embeddings_item = nn.Embedding(n_item, layers[0]//2)\n",
    "        self.mlp = nn.Sequential()\n",
    "        for i in range(1,self.n_layers):\n",
    "            self.mlp.add_module(\"linear%d\" %i, nn.Linear(layers[i-1],layers[i]))\n",
    "            self.mlp.add_module(\"relu%d\" %i, torch.nn.ReLU())\n",
    "            self.mlp.add_module(\"dropout%d\" %i , torch.nn.Dropout(p=dropouts[i-1]))\n",
    "\n",
    "        self.out = nn.Linear(in_features=n_emb+layers[-1], out_features=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "\n",
    "        mf_user_emb = self.mf_embeddings_user(users)\n",
    "        mf_item_emb = self.mf_embeddings_item(items)\n",
    "\n",
    "        mlp_user_emb = self.mlp_embeddings_user(users)\n",
    "        mlp_item_emb = self.mlp_embeddings_item(items)\n",
    "\n",
    "        mf_emb_vector = mf_user_emb*mf_item_emb\n",
    "        mlp_emb_vector = torch.cat([mlp_user_emb,mlp_item_emb], dim=1)\n",
    "        mlp_emb_vector = self.mlp(mlp_emb_vector)\n",
    "\n",
    "        emb_vector = torch.cat([mf_emb_vector,mlp_emb_vector], dim=1)\n",
    "        preds = torch.sigmoid(self.out(emb_vector))\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"388pt\" height=\"772pt\"\n",
       " viewBox=\"0.00 0.00 388.00 772.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 736)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-736 316,-736 316,36 -72,36\"/>\n",
       "<!-- NeuMF/Embedding[mf_embeddings_user]/outputs/12 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>NeuMF/Embedding[mf_embeddings_user]/outputs/12</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-368 0,-368 0,-332 54,-332 54,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"13\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/16 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>NeuMF/outputs/16</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"126,-285 72,-285 72,-249 126,-249 126,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"90\" y=\"-264\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Mul</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mf_embeddings_user]/outputs/12&#45;&gt;NeuMF/outputs/16 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>NeuMF/Embedding[mf_embeddings_user]/outputs/12&#45;&gt;NeuMF/outputs/16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M40.1372,-331.704C46.734,-322.8205 55.0071,-312.1221 63,-303 66.0308,-299.541 69.3168,-296.0009 72.6289,-292.5556\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.3148,-294.8162 79.8328,-285.233 70.3247,-289.9071 75.3148,-294.8162\"/>\n",
       "<text text-anchor=\"middle\" x=\"79\" y=\"-306\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x32</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mf_embeddings_item]/outputs/13 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>NeuMF/Embedding[mf_embeddings_item]/outputs/13</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"126,-368 72,-368 72,-332 126,-332 126,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"85\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mf_embeddings_item]/outputs/13&#45;&gt;NeuMF/outputs/16 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>NeuMF/Embedding[mf_embeddings_item]/outputs/13&#45;&gt;NeuMF/outputs/16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M99,-331.9902C99,-321.2963 99,-307.4994 99,-295.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.5001,-295.2612 99,-285.2612 95.5001,-295.2613 102.5001,-295.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-306\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x32</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mlp_embeddings_user]/outputs/14 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>NeuMF/Embedding[mlp_embeddings_user]/outputs/14</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"172,-700 118,-700 118,-664 172,-664 172,-700\"/>\n",
       "<text text-anchor=\"start\" x=\"131\" y=\"-679\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/17 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>NeuMF/outputs/17</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"208,-617 154,-617 154,-581 208,-581 208,-617\"/>\n",
       "<text text-anchor=\"start\" x=\"166\" y=\"-596\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mlp_embeddings_user]/outputs/14&#45;&gt;NeuMF/outputs/17 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>NeuMF/Embedding[mlp_embeddings_user]/outputs/14&#45;&gt;NeuMF/outputs/17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M151.431,-663.9781C154.6969,-655.1595 158.8458,-644.4365 163,-635 164.2546,-632.15 165.6179,-629.2014 167.0139,-626.2749\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"170.2287,-627.6686 171.4923,-617.1494 163.9446,-624.5847 170.2287,-627.6686\"/>\n",
       "<text text-anchor=\"middle\" x=\"179\" y=\"-638\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x64</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mlp_embeddings_item]/outputs/15 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>NeuMF/Embedding[mlp_embeddings_item]/outputs/15</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"244,-700 190,-700 190,-664 244,-664 244,-700\"/>\n",
       "<text text-anchor=\"start\" x=\"203\" y=\"-679\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- NeuMF/Embedding[mlp_embeddings_item]/outputs/15&#45;&gt;NeuMF/outputs/17 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>NeuMF/Embedding[mlp_embeddings_item]/outputs/15&#45;&gt;NeuMF/outputs/17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M209.1885,-663.9902C204.4565,-653.0802 198.3237,-638.9407 192.9874,-626.6376\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"196.1107,-625.0427 188.9205,-617.2612 189.6888,-627.8282 196.1107,-625.0427\"/>\n",
       "<text text-anchor=\"middle\" x=\"217\" y=\"-638\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x64</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/26 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>NeuMF/outputs/26</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"161,-202 107,-202 107,-166 161,-166 161,-202\"/>\n",
       "<text text-anchor=\"start\" x=\"119\" y=\"-181\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/16&#45;&gt;NeuMF/outputs/26 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>NeuMF/outputs/16&#45;&gt;NeuMF/outputs/26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M102.7951,-248.7416C104.9527,-239.867 108.0252,-229.1652 112,-220 113.3114,-216.976 114.8416,-213.9028 116.4731,-210.8911\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"119.5539,-212.5555 121.554,-202.1512 113.5022,-209.0374 119.5539,-212.5555\"/>\n",
       "<text text-anchor=\"middle\" x=\"128\" y=\"-223\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x32</text>\n",
       "</g>\n",
       "<!-- 2135986877833314787 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>2135986877833314787</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"217.5,-534 144.5,-534 144.5,-498 217.5,-498 217.5,-534\"/>\n",
       "<text text-anchor=\"start\" x=\"153\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/17&#45;&gt;2135986877833314787 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>NeuMF/outputs/17&#45;&gt;2135986877833314787</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-580.9902C181,-570.2963 181,-556.4994 181,-544.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-544.2612 181,-534.2612 177.5001,-544.2613 184.5001,-544.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"199.5\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x128</text>\n",
       "</g>\n",
       "<!-- NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"208,-451 154,-451 154,-415 208,-415 208,-451\"/>\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-430\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Dropout</text>\n",
       "</g>\n",
       "<!-- 10344261258802070980 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>10344261258802070980</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"217.5,-368 144.5,-368 144.5,-332 217.5,-332 217.5,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"153\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n",
       "</g>\n",
       "<!-- NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21&#45;&gt;10344261258802070980 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21&#45;&gt;10344261258802070980</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-414.9902C181,-404.2963 181,-390.4994 181,-378.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-378.2612 181,-368.2612 177.5001,-378.2613 184.5001,-378.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-389\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x64</text>\n",
       "</g>\n",
       "<!-- NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"200,-285 146,-285 146,-249 200,-249 200,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"156\" y=\"-264\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Dropout</text>\n",
       "</g>\n",
       "<!-- NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25&#45;&gt;NeuMF/outputs/26 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25&#45;&gt;NeuMF/outputs/26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M164.5376,-248.9902C159.4112,-238.0802 152.7673,-223.9407 146.9863,-211.6376\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"150.0011,-209.8234 142.5806,-202.2612 143.6656,-212.8004 150.0011,-209.8234\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-223\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x32</text>\n",
       "</g>\n",
       "<!-- NeuMF/Linear[out]/outputs/27 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>NeuMF/Linear[out]/outputs/27</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"161,-119 107,-119 107,-83 161,-83 161,-119\"/>\n",
       "<text text-anchor=\"start\" x=\"121\" y=\"-98\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/26&#45;&gt;NeuMF/Linear[out]/outputs/27 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>NeuMF/outputs/26&#45;&gt;NeuMF/Linear[out]/outputs/27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-165.9902C134,-155.2963 134,-141.4994 134,-129.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-129.2612 134,-119.2612 130.5001,-129.2613 137.5001,-129.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"150\" y=\"-140\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x64</text>\n",
       "</g>\n",
       "<!-- NeuMF/outputs/28 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>NeuMF/outputs/28</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"161,-36 107,-36 107,0 161,0 161,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"117\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Sigmoid</text>\n",
       "</g>\n",
       "<!-- NeuMF/Linear[out]/outputs/27&#45;&gt;NeuMF/outputs/28 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>NeuMF/Linear[out]/outputs/27&#45;&gt;NeuMF/outputs/28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M134,-82.9902C134,-72.2963 134,-58.4994 134,-46.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.5001,-46.2612 134,-36.2612 130.5001,-46.2613 137.5001,-46.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-57\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x1</text>\n",
       "</g>\n",
       "<!-- 2135986877833314787&#45;&gt;NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>2135986877833314787&#45;&gt;NeuMF/Sequential[mlp]/Dropout[dropout1]/outputs/20/21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-497.9902C181,-487.2963 181,-473.4994 181,-461.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-461.2612 181,-451.2612 177.5001,-461.2613 184.5001,-461.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"197\" y=\"-472\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x64</text>\n",
       "</g>\n",
       "<!-- 10344261258802070980&#45;&gt;NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10344261258802070980&#45;&gt;NeuMF/Sequential[mlp]/Dropout[dropout2]/outputs/24/25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M179.2641,-331.9902C178.2334,-321.2963 176.9036,-307.4994 175.7345,-295.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"179.2035,-294.8793 174.7601,-285.2612 172.2358,-295.5509 179.2035,-294.8793\"/>\n",
       "<text text-anchor=\"middle\" x=\"193\" y=\"-306\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">512x32</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x7ff0859169b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_model = NeuMF(n_user=10, n_item=10, n_emb=32, layers=layers, dropouts=dropouts)\n",
    "hl.build_graph(toy_model, (torch.zeros([batch_size]).long(),  torch.zeros([batch_size]).long()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy! :) \n",
    "\n",
    "### Load Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = np.load(os.path.join(datadir, dataname))\n",
    "train_ratings = load_npz(os.path.join(datadir, train_matrix)).todok()\n",
    "test_ratings, negatives = dataset['test_negative'], dataset['negatives']\n",
    "n_users, n_items = dataset['n_users'].item(), dataset['n_items'].item()\n",
    "\n",
    "test_loader = DataLoader(dataset=test_ratings,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model structures\n",
    "gmf_model = GMF(n_users, n_items, n_emb)\n",
    "gmf_model.load_state_dict(torch.load(mf_pretrain))\n",
    "mlp_model = MLP(n_users, n_items, layers, dropouts)\n",
    "mlp_model.load_state_dict(torch.load(mlp_pretrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look and check all went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMF(\n",
       "  (embeddings_user): Embedding(123960, 8)\n",
       "  (embeddings_item): Embedding(50052, 8)\n",
       "  (out): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embeddings_user): Embedding(123960, 64)\n",
       "  (embeddings_item): Embedding(50052, 64)\n",
       "  (mlp): Sequential(\n",
       "    (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0)\n",
       "    (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.0)\n",
       "  )\n",
       "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (mf_embeddings_user): Embedding(123960, 8)\n",
       "  (mf_embeddings_item): Embedding(50052, 8)\n",
       "  (mlp_embeddings_user): Embedding(123960, 64)\n",
       "  (mlp_embeddings_item): Embedding(50052, 64)\n",
       "  (mlp): Sequential(\n",
       "    (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.0)\n",
       "    (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.0)\n",
       "  )\n",
       "  (out): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF(n_users, n_items, n_emb, layers, dropouts)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load layer by layer to the NeuMF model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMF embeddings\n",
    "model.mf_embeddings_item.weight = gmf_model.embeddings_item.weight\n",
    "model.mf_embeddings_user.weight = gmf_model.embeddings_user.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP embeddings\n",
    "model.mlp_embeddings_item.weight = mlp_model.embeddings_item.weight\n",
    "model.mlp_embeddings_user.weight = mlp_model.embeddings_user.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP layers\n",
    "model_dict = model.state_dict()\n",
    "mlp_layers_dict = mlp_model.state_dict()\n",
    "mlp_layers_dict = {k: v for k, v in mlp_layers_dict.items() if 'linear' in k}\n",
    "model_dict.update(mlp_layers_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction weights\n",
    "mf_prediction_weight, mf_prediction_bias = gmf_model.out.weight, gmf_model.out.bias\n",
    "mlp_prediction_weight, mlp_prediction_bias = mlp_model.out.weight, mlp_model.out.bias\n",
    "\n",
    "new_weight = torch.cat([mf_prediction_weight, mlp_prediction_weight], dim=1)\n",
    "new_bias = mf_prediction_bias + mlp_prediction_bias\n",
    "model.out.weight = torch.nn.Parameter(0.5*new_weight)\n",
    "model.out.bias = torch.nn.Parameter(0.5*new_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, Now our model is fully loaded with pretrained weights. In case you are wondering why do I multiply by 0.5 the contribution from each model, the answer is pretty straightforward, but just in case, let me explain. Let's stay that the outputs from GMF and MLP are identical, for example 0.7. Therefore, when the two models are combined one would expect \"full agreement\", meaning that the output of the combined model (NeuMF) is also 0.7. \n",
    "\n",
    "The fact that the GMF output 0.7 means that the summation of the weights in the output layer is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8472978603872034\n"
     ]
    }
   ],
   "source": [
    "p = 0.7\n",
    "logit_p = np.log(p/(1-p))\n",
    "print(logit_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same applies to the MLP model. Therefore, since we need the output of the NeuMF to also be `0.8473`, we need to add the (GMF_out/2 + MLP_out/2)\n",
    "\n",
    "### Freeze all up to Last (output) Layer\n",
    "\n",
    "This is rather easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "if freeze:\n",
    "    for name, layer in model.named_parameters():\n",
    "        if not (\"out\" in name):\n",
    "            layer.requires_grad = False\n",
    "# or this and pass train_parametes to the optimizer\n",
    "# train_parametes = model.out.parameters() if freeze else model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2reg)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "scheduler = None\n",
    "\n",
    "# let's make sure all is ok\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "trainable_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ok, 40 (32+8) weights + a bias is all that we will be training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 90.97s, LOSS = 0.1615, HR = 0.6960, NDCG = 0.4759, validated in 105.08s\n"
     ]
    }
   ],
   "source": [
    "best_hr, best_ndcgm, best_iter=0,0,0\n",
    "for epoch in range(1,epochs+1):\n",
    "    t1 = time()\n",
    "    loss = train(model, criterion, optimizer, scheduler, epoch, batch_size,\n",
    "        use_cuda, train_ratings, negatives, n_items, n_neg)\n",
    "    t2 = time()\n",
    "    if epoch % validate_every == 0:\n",
    "        (hr, ndcg) = evaluate(model, test_loader, use_cuda, topk)\n",
    "        print(\"Epoch: {} {:.2f}s, LOSS = {:.4f}, HR = {:.4f}, NDCG = {:.4f}, validated in {:.2f}s\".\n",
    "            format(epoch, t2-t1, loss, hr, ndcg, time()-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice resulst! For a full summary of the results, go to Chapter05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jrz)",
   "language": "python",
   "name": "conda_jrz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
